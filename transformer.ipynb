{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_qNSzzyaCbD"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "jmjh290raIky"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Transformer model for language understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AOpGoE2T-YXS"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/transformer\">\n",
    "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
    "    View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/transformer.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-f8TnGpE_ex"
   },
   "source": [
    "This tutorial trains a <a href=\"https://arxiv.org/abs/1706.03762\" class=\"external\">Transformer model</a> to translate Portuguese to English. This is an advanced example that assumes knowledge of [text generation](text_generation.ipynb) and [attention](nmt_with_attention.ipynb).\n",
    "\n",
    "The core idea behind the Transformer model is *self-attention*—the ability to attend to different positions of the input sequence to compute a representation of that sequence. Transformer creates stacks of self-attention layers and is explained below in the sections *Scaled dot product attention* and *Multi-head attention*.\n",
    "\n",
    "A transformer model handles variable-sized input using stacks of self-attention layers instead of [RNNs](text_classification_rnn.ipynb) or [CNNs](../images/intro_to_cnns.ipynb). This general architecture has a number of advantages:\n",
    "\n",
    "* It make no assumptions about the temporal/spatial relationships across the data. This is ideal for processing a set of objects (for example, [StarCraft units](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/#block-8)).\n",
    "* Layer outputs can be calculated in parallel, instead of a series like an RNN.\n",
    "* Distant items can affect each other's output without passing through many RNN-steps, or convolution layers (see [Scene Memory Transformer](https://arxiv.org/pdf/1903.03878.pdf) for example).\n",
    "* It can learn long-range dependencies. This is a challenge in many sequence tasks.\n",
    "\n",
    "The downsides of this architecture are:\n",
    "\n",
    "* For a time-series, the output for a time-step is calculated from the *entire history* instead of only the inputs and current hidden-state. This _may_ be less efficient.   \n",
    "* If the input *does* have a  temporal/spatial relationship, like text, some positional encoding must be added or the model will effectively see a bag of words. \n",
    "\n",
    "After training the model in this notebook, you will be able to input a Portuguese sentence and return the English translation.\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/attention_map_portuguese.png\" width=\"800\" alt=\"Attention heatmap\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjJJyJTZYebt"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# try:\n",
    "#   !pip install -q tf-nightly\n",
    "# except Exception:\n",
    "#   pass\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fd1NWMxjfsDd"
   },
   "source": [
    "## Setup input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4_Qt8W1hJE_"
   },
   "source": [
    "Use [TFDS](https://www.tensorflow.org/datasets) to load the [Portugese-English translation dataset](https://github.com/neulab/word-embeddings-for-nmt) from the [TED Talks Open Translation Project](https://www.ted.com/participate/translate).\n",
    "\n",
    "This dataset contains approximately 50000 training examples, 1100 validation examples, and 2000 test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8q9t4FmN96eN"
   },
   "outputs": [],
   "source": [
    "# examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "#                                as_supervised=True)\n",
    "# train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 2673\n",
    "train_size = int(0.8 * DATASET_SIZE)\n",
    "full_dataset = tf.data.experimental.CsvDataset('data/iswoc-treebank.tsv', [tf.string] * 2, field_delim='\\t')\n",
    "full_dataset = full_dataset.shuffle(buffer_size=10)\n",
    "train_examples = full_dataset.take(train_size)\n",
    "val_examples = full_dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Þa wearð hyre mod mycclum onbryrd þuruh þa halgen lare þeah ðe heo þa gyt hæðen wære\n",
      "þa weorþan hire mod micel onbryrdan þurh se halig lar þeah þe heo þa git hæðen wesan\n"
     ]
    }
   ],
   "source": [
    "for a, b in train_examples.take(1):\n",
    "    tf.print(a)\n",
    "    tf.print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RCEKotqosGfq"
   },
   "source": [
    "Create a custom subwords tokenizer from the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVBg5Q8tBk5z"
   },
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DYWukNFkGQN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [100, 5, 11, 327, 649, 150, 101, 4, 1070, 3456, 3387, 8, 4, 3472, 3550, 3531, 3474, 3476, 3471, 3456, 3458, 3472, 3465, 315]\n",
      "The original string: Eugenia þa þæt æðele mæden wel þeah on wisdome and on uðwytegunge\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Eugenia þa þæt æðele mæden wel þeah on wisdome and on uðwytegunge'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9KJWJjrsZ4Y"
   },
   "source": [
    "The tokenizer encodes the string by breaking it into subwords if the word is not in its dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bf2ntBxjkqK6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ----> Eugenia \n",
      "5 ----> þa \n",
      "11 ----> þæt \n",
      "327 ----> æðele \n",
      "649 ----> mæden \n",
      "150 ----> wel \n",
      "101 ----> þeah \n",
      "4 ----> on \n",
      "1070 ----> wisdom\n",
      "3456 ----> e\n",
      "3387 ---->  \n",
      "8 ----> and \n",
      "4 ----> on \n",
      "3472 ----> u\n",
      "3550 ----> �\n",
      "3531 ----> �\n",
      "3474 ----> w\n",
      "3476 ----> y\n",
      "3471 ----> t\n",
      "3456 ----> e\n",
      "3458 ----> g\n",
      "3472 ----> u\n",
      "3465 ----> n\n",
      "315 ----> ge\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcRp7VcQ5m6g"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGi4PoVakxdc"
   },
   "source": [
    "Add a start and end token to the input and target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZwnPr4R055s"
   },
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "  \n",
    "  return lang1, lang2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tx1sFbR-9fRs"
   },
   "source": [
    "You want to use `Dataset.map` to apply this function to each element of the dataset.  `Dataset.map` runs in graph mode.\n",
    "\n",
    "* Graph tensors do not have a value. \n",
    "* In graph mode you can only use TensorFlow Ops and functions. \n",
    "\n",
    "So you can't `.map` this function directly: You need to wrap it in a `tf.py_function`. The `tf.py_function` will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mah1cS-P70Iz"
   },
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "  result_pt.set_shape([None])\n",
    "  result_en.set_shape([None])\n",
    "\n",
    "  return result_pt, result_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6JrGp5Gek6Ql"
   },
   "source": [
    "Note: To keep this example small and relatively fast, drop examples with a length of over 40 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QEgbjntk6Yf"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c081xPGv1CPI"
   },
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mk9AZdZ5bcS"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fXvfYVfQr2n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 40), dtype=int64, numpy=\n",
       " array([[6182,  154,  114, ...,    0,    0,    0],\n",
       "        [6182, 5338,   19, ...,    0,    0,    0],\n",
       "        [6182,  201, 4601, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [6182,  220,   97, ...,    0,    0,    0],\n",
       "        [6182, 1317,    4, ...,    0,    0,    0],\n",
       "        [6182,   18,   33, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: shape=(64, 34), dtype=int64, numpy=\n",
       " array([[3611,    7,   24, ...,    0,    0,    0],\n",
       "        [3611, 3452, 3458, ...,    0,    0,    0],\n",
       "        [3611,  178, 1377, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [3611,   12,   44, ...,    0,    0,    0],\n",
       "        [3611,  620,   11, ...,    0,    0,    0],\n",
       "        [3611,    5,   27, ...,    0,    0,    0]])>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBQuibYA4n0n"
   },
   "source": [
    "## Positional encoding\n",
    "\n",
    "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence. \n",
    "\n",
    "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n",
    "\n",
    "See the notebook on [positional encoding](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) to learn more about it. The formula for calculating the positional encoding is as follows:\n",
    "\n",
    "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
    "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhIOZjMNKujn"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Rz82wEs5biZ"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kLCla68EloE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_b4ou4TYqUN"
   },
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s42Uydjkv0hF"
   },
   "source": [
    "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value `0` is present: it outputs a `1` at those locations, and a `0` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2i8-e1s8ti9"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7BYeBCNvi7n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0hzukDBgVom"
   },
   "source": [
    "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
    "\n",
    "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVxS8OPI9uI0"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxKGuXxaBeeE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xluDl5cXYy4y"
   },
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vsxEE_-Wa1gF"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n",
    "\n",
    "The attention function used by the transformer takes three inputs: Q (query), K (key), V (value). The equation used to calculate the attention weights is:\n",
    "\n",
    "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n",
    "\n",
    "The dot-product attention is scaled by a factor of square root of the depth. This is done because for large values of depth, the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax. \n",
    "\n",
    "For example, consider that `Q` and `K` have a mean of 0 and variance of 1. Their matrix multiplication will have a mean of 0 and variance of `dk`. Hence, *square root of `dk`* is used for scaling (and not any other number) because the matmul of `Q` and `K` should have a mean of 0 and variance of 1, and you get a gentler softmax.\n",
    "\n",
    "The mask is multiplied with -1e9 (close to negative infinity). This is done because the mask is summed with the scaled matrix multiplication of Q and K and is applied immediately before a softmax. The goal is to zero out these cells, and large negative inputs to softmax are near zero in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LazzUq3bJ5SH"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiqETnhCkoXh"
   },
   "source": [
    "As the softmax normalization is done on K, its values decide the amount of importance given to Q.\n",
    "\n",
    "The output represents the multiplication of the attention weights and the V (value) vector. This ensures that the words you want to focus on are kept as-is and the irrelevant words are flushed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n90YjClyInFy"
   },
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAzUAf2DPlNt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zg6k-fGhgXra"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAq3YOzUgXhb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aOz-4_XIhaTP"
   },
   "source": [
    "Pass all the queries together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dlU8Tm-hYrF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmzGPEy64qmA"
   },
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fz5BMC8Kaoqo"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n",
    "\n",
    "\n",
    "Multi-head attention consists of four parts:\n",
    "*    Linear layers and split into heads.\n",
    "*    Scaled dot-product attention.\n",
    "*    Concatenation of heads.\n",
    "*    Final linear layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPmbr6F1C-v_"
   },
   "source": [
    "Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads. \n",
    "\n",
    "The `scaled_dot_product_attention` defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step.  The attention output for each head is then concatenated (using `tf.transpose`, and `tf.reshape`) and put through a final `Dense` layer.\n",
    "\n",
    "Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSV3PPKsYecw"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0D8FJue5lDyZ"
   },
   "source": [
    "Create a `MultiHeadAttention` layer to try out. At each location in the sequence, `y`, the `MultiHeadAttention` runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hu94p-_-2_BX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RdDqGayx67vv"
   },
   "source": [
    "## Point wise feed forward network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBqzJXGfHK3X"
   },
   "source": [
    "Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ET7xLt0yCT6Z"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mytb1lPyOHLB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7e7hKcxn6-zd"
   },
   "source": [
    "## Encoder and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yScbC0MUH8dS"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MfYJG-Kvgwy2"
   },
   "source": [
    "The transformer model follows the same general pattern as a standard [sequence to sequence with attention model](nmt_with_attention.ipynb). \n",
    "\n",
    "* The input sentence is passed through `N` encoder layers that generates an output for each word/token in the sequence.\n",
    "* The decoder attends on the encoder's output and its own input (self-attention) to predict the next word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFv-FNYUmvpn"
   },
   "source": [
    "### Encoder layer\n",
    "\n",
    "Each encoder layer consists of sublayers:\n",
    "\n",
    "1.   Multi-head attention (with padding mask) \n",
    "2.    Point wise feed forward networks. \n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
    "\n",
    "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncyS-Ms3i2x_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzZRXdO0mI48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LO_48Owmx_o"
   },
   "source": [
    "### Decoder layer\n",
    "\n",
    "Each decoder layer consists of sublayers:\n",
    "\n",
    "1.   Masked multi-head attention (with look ahead mask and padding mask)\n",
    "2.   Multi-head attention (with padding mask). V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
    "3.   Point wise feed forward networks\n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
    "\n",
    "There are N decoder layers in the transformer.\n",
    "\n",
    "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ne2Bqx8k71l0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SE1H51Ajm0q1"
   },
   "source": [
    "### Encoder\n",
    "\n",
    "The `Encoder` consists of:\n",
    "1.   Input Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N encoder layers\n",
    "\n",
    "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8QG9nueFQKXx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-uO6ls8m2O5"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZtT7PKzrXkNr"
   },
   "source": [
    " The `Decoder` consists of:\n",
    "1.   Output Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N decoder layers\n",
    "\n",
    "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1jXoAMRZyvu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y54xnJnuYgJ7"
   },
   "source": [
    "## Create the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uERO1y54cOKq"
   },
   "source": [
    "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJ4fbQcIkHW1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsINyf1VEQLC"
   },
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zVjWCxFNcgbt"
   },
   "source": [
    "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced. \n",
    "\n",
    "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
    "\n",
    "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lnJn5SLA2ahP"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xYEGhEOtzn5W"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOmWW--yP3zx"
   },
   "source": [
    "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYQdOO1axwEI"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7r4scdulztRx"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f33ZCgvHpPdG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgkDE7hzo8r5"
   },
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxGJtoDuYIHL"
   },
   "source": [
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlhsJMm0TW_B"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "67oqVHiT0Eiu"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phlyxMnm-Tpx"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeHumfr7zmMa"
   },
   "source": [
    "## Training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiysUa--4tOU"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOJUSB1T8GjM"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fzuf06YZp66w"
   },
   "source": [
    "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNhuYfllndLZ"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Di_Yaa1gf9r"
   },
   "source": [
    "The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the  next token that should be predicted.\n",
    "\n",
    "For example, `sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next. \n",
    "\n",
    "During training this example uses teacher-forcing (like in the [text generation tutorial](./text_generation.ipynb)). Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n",
    "\n",
    "As the transformer predicts each word, *self-attention* allows it to look at the previous words in the input sequence to better predict the next word.\n",
    "\n",
    "To prevent the model from peaking at the expected output the model uses a look-ahead mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKpoA6q1sJFj"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJwmp9OE29oj"
   },
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qM2PDWGDJ_8V"
   },
   "source": [
    "Portuguese is used as the input language and English is the target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bbvmaKNiznHZ",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.6824 Accuracy 0.0811\n",
      "Epoch 1 Loss 1.6999 Accuracy 0.0912\n",
      "Time taken for 1 epoch: 21.087100982666016 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.7153 Accuracy 0.0871\n",
      "Epoch 2 Loss 1.6601 Accuracy 0.0955\n",
      "Time taken for 1 epoch: 14.35629153251648 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.6482 Accuracy 0.0946\n",
      "Epoch 3 Loss 1.6299 Accuracy 0.0993\n",
      "Time taken for 1 epoch: 14.35907530784607 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.6100 Accuracy 0.1018\n",
      "Epoch 4 Loss 1.5709 Accuracy 0.1029\n",
      "Time taken for 1 epoch: 14.980272054672241 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.6517 Accuracy 0.1099\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-5\n",
      "Epoch 5 Loss 1.5624 Accuracy 0.1081\n",
      "Time taken for 1 epoch: 15.55318832397461 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.6961 Accuracy 0.1315\n",
      "Epoch 6 Loss 1.4959 Accuracy 0.1098\n",
      "Time taken for 1 epoch: 15.88049602508545 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.2955 Accuracy 0.0960\n",
      "Epoch 7 Loss 1.4918 Accuracy 0.1165\n",
      "Time taken for 1 epoch: 17.86279010772705 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.5825 Accuracy 0.1316\n",
      "Epoch 8 Loss 1.4365 Accuracy 0.1190\n",
      "Time taken for 1 epoch: 15.222042322158813 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.3435 Accuracy 0.1316\n",
      "Epoch 9 Loss 1.3864 Accuracy 0.1219\n",
      "Time taken for 1 epoch: 15.042813062667847 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.1825 Accuracy 0.1265\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-6\n",
      "Epoch 10 Loss 1.3771 Accuracy 0.1270\n",
      "Time taken for 1 epoch: 14.85629415512085 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.1445 Accuracy 0.1286\n",
      "Epoch 11 Loss 1.3558 Accuracy 0.1324\n",
      "Time taken for 1 epoch: 15.428864002227783 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.5540 Accuracy 0.1502\n",
      "Epoch 12 Loss 1.2825 Accuracy 0.1338\n",
      "Time taken for 1 epoch: 16.131415605545044 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.3604 Accuracy 0.1691\n",
      "Epoch 13 Loss 1.2761 Accuracy 0.1383\n",
      "Time taken for 1 epoch: 17.046265125274658 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.1916 Accuracy 0.1393\n",
      "Epoch 14 Loss 1.2368 Accuracy 0.1433\n",
      "Time taken for 1 epoch: 17.309561014175415 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.9235 Accuracy 0.1186\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-7\n",
      "Epoch 15 Loss 1.2058 Accuracy 0.1467\n",
      "Time taken for 1 epoch: 16.566569805145264 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 1.2743 Accuracy 0.1762\n",
      "Epoch 16 Loss 1.1841 Accuracy 0.1553\n",
      "Time taken for 1 epoch: 15.89320182800293 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 1.1313 Accuracy 0.1799\n",
      "Epoch 17 Loss 1.1038 Accuracy 0.1554\n",
      "Time taken for 1 epoch: 15.268284797668457 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.9395 Accuracy 0.1562\n",
      "Epoch 18 Loss 1.0884 Accuracy 0.1624\n",
      "Time taken for 1 epoch: 15.210675716400146 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 1.0046 Accuracy 0.1880\n",
      "Epoch 19 Loss 1.0372 Accuracy 0.1664\n",
      "Time taken for 1 epoch: 16.33146858215332 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 1.0039 Accuracy 0.1699\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-8\n",
      "Epoch 20 Loss 0.9819 Accuracy 0.1712\n",
      "Time taken for 1 epoch: 16.78957438468933 secs\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.8734 Accuracy 0.1575\n",
      "Epoch 21 Loss 0.9655 Accuracy 0.1799\n",
      "Time taken for 1 epoch: 15.855883121490479 secs\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.9297 Accuracy 0.2021\n",
      "Epoch 22 Loss 0.9140 Accuracy 0.1837\n",
      "Time taken for 1 epoch: 16.265791654586792 secs\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.8665 Accuracy 0.2031\n",
      "Epoch 23 Loss 0.8505 Accuracy 0.1917\n",
      "Time taken for 1 epoch: 16.38720965385437 secs\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.9397 Accuracy 0.2173\n",
      "Epoch 24 Loss 0.8274 Accuracy 0.2005\n",
      "Time taken for 1 epoch: 14.320594072341919 secs\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.8095 Accuracy 0.2288\n",
      "Saving checkpoint for epoch 25 at ./checkpoints/train/ckpt-9\n",
      "Epoch 25 Loss 0.7811 Accuracy 0.2086\n",
      "Time taken for 1 epoch: 15.120929479598999 secs\n",
      "\n",
      "Epoch 26 Batch 0 Loss 1.0283 Accuracy 0.3467\n",
      "Epoch 26 Loss 0.7526 Accuracy 0.2170\n",
      "Time taken for 1 epoch: 14.18932557106018 secs\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.5592 Accuracy 0.1875\n",
      "Epoch 27 Loss 0.6797 Accuracy 0.2184\n",
      "Time taken for 1 epoch: 14.953986883163452 secs\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.7549 Accuracy 0.2458\n",
      "Epoch 28 Loss 0.6461 Accuracy 0.2331\n",
      "Time taken for 1 epoch: 14.386563539505005 secs\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.5576 Accuracy 0.2235\n",
      "Epoch 29 Loss 0.6102 Accuracy 0.2389\n",
      "Time taken for 1 epoch: 14.359721899032593 secs\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.5936 Accuracy 0.2426\n",
      "Saving checkpoint for epoch 30 at ./checkpoints/train/ckpt-10\n",
      "Epoch 30 Loss 0.5538 Accuracy 0.2478\n",
      "Time taken for 1 epoch: 15.247392177581787 secs\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.5180 Accuracy 0.2465\n",
      "Epoch 31 Loss 0.5261 Accuracy 0.2596\n",
      "Time taken for 1 epoch: 14.305935859680176 secs\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.4733 Accuracy 0.2618\n",
      "Epoch 32 Loss 0.4725 Accuracy 0.2629\n",
      "Time taken for 1 epoch: 14.78776240348816 secs\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.5506 Accuracy 0.3151\n",
      "Epoch 33 Loss 0.4459 Accuracy 0.2726\n",
      "Time taken for 1 epoch: 14.29697561264038 secs\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.3933 Accuracy 0.2504\n",
      "Epoch 34 Loss 0.3999 Accuracy 0.2840\n",
      "Time taken for 1 epoch: 14.453781604766846 secs\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.2803 Accuracy 0.2874\n",
      "Saving checkpoint for epoch 35 at ./checkpoints/train/ckpt-11\n",
      "Epoch 35 Loss 0.3584 Accuracy 0.2940\n",
      "Time taken for 1 epoch: 14.747193574905396 secs\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.3050 Accuracy 0.3024\n",
      "Epoch 36 Loss 0.3235 Accuracy 0.3033\n",
      "Time taken for 1 epoch: 14.921931982040405 secs\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.2610 Accuracy 0.2756\n",
      "Epoch 37 Loss 0.2891 Accuracy 0.3078\n",
      "Time taken for 1 epoch: 14.544454336166382 secs\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.2110 Accuracy 0.3063\n",
      "Epoch 38 Loss 0.2504 Accuracy 0.3095\n",
      "Time taken for 1 epoch: 15.062107563018799 secs\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.2752 Accuracy 0.3646\n",
      "Epoch 39 Loss 0.2368 Accuracy 0.3203\n",
      "Time taken for 1 epoch: 14.77550745010376 secs\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.1860 Accuracy 0.3210\n",
      "Saving checkpoint for epoch 40 at ./checkpoints/train/ckpt-12\n",
      "Epoch 40 Loss 0.2027 Accuracy 0.3241\n",
      "Time taken for 1 epoch: 15.014028549194336 secs\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.1797 Accuracy 0.3785\n",
      "Epoch 41 Loss 0.1771 Accuracy 0.3365\n",
      "Time taken for 1 epoch: 14.574400663375854 secs\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.1446 Accuracy 0.3281\n",
      "Epoch 42 Loss 0.1542 Accuracy 0.3384\n",
      "Time taken for 1 epoch: 14.440306186676025 secs\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.1538 Accuracy 0.3896\n",
      "Epoch 43 Loss 0.1308 Accuracy 0.3431\n",
      "Time taken for 1 epoch: 14.382262468338013 secs\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.1322 Accuracy 0.3807\n",
      "Epoch 44 Loss 0.1167 Accuracy 0.3422\n",
      "Time taken for 1 epoch: 15.256726503372192 secs\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.0874 Accuracy 0.2885\n",
      "Saving checkpoint for epoch 45 at ./checkpoints/train/ckpt-13\n",
      "Epoch 45 Loss 0.1076 Accuracy 0.3400\n",
      "Time taken for 1 epoch: 15.285084009170532 secs\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.0854 Accuracy 0.2897\n",
      "Epoch 46 Loss 0.0896 Accuracy 0.3425\n",
      "Time taken for 1 epoch: 14.830666303634644 secs\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.0665 Accuracy 0.2941\n",
      "Epoch 47 Loss 0.0785 Accuracy 0.3512\n",
      "Time taken for 1 epoch: 14.517210960388184 secs\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.0625 Accuracy 0.3210\n",
      "Epoch 48 Loss 0.0701 Accuracy 0.3484\n",
      "Time taken for 1 epoch: 14.662414312362671 secs\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.0565 Accuracy 0.3125\n",
      "Epoch 49 Loss 0.0618 Accuracy 0.3484\n",
      "Time taken for 1 epoch: 14.813308715820312 secs\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.0559 Accuracy 0.3560\n",
      "Saving checkpoint for epoch 50 at ./checkpoints/train/ckpt-14\n",
      "Epoch 50 Loss 0.0634 Accuracy 0.3468\n",
      "Time taken for 1 epoch: 14.882756233215332 secs\n",
      "\n",
      "Epoch 51 Batch 0 Loss 0.0450 Accuracy 0.3241\n",
      "Epoch 51 Loss 0.0547 Accuracy 0.3426\n",
      "Time taken for 1 epoch: 14.81711745262146 secs\n",
      "\n",
      "Epoch 52 Batch 0 Loss 0.0360 Accuracy 0.3117\n",
      "Epoch 52 Loss 0.0488 Accuracy 0.3506\n",
      "Time taken for 1 epoch: 14.876574277877808 secs\n",
      "\n",
      "Epoch 53 Batch 0 Loss 0.0448 Accuracy 0.3529\n",
      "Epoch 53 Loss 0.0464 Accuracy 0.3490\n",
      "Time taken for 1 epoch: 14.644968509674072 secs\n",
      "\n",
      "Epoch 54 Batch 0 Loss 0.0483 Accuracy 0.4202\n",
      "Epoch 54 Loss 0.0443 Accuracy 0.3478\n",
      "Time taken for 1 epoch: 14.998648881912231 secs\n",
      "\n",
      "Epoch 55 Batch 0 Loss 0.0477 Accuracy 0.3896\n",
      "Saving checkpoint for epoch 55 at ./checkpoints/train/ckpt-15\n",
      "Epoch 55 Loss 0.0409 Accuracy 0.3459\n",
      "Time taken for 1 epoch: 15.314650297164917 secs\n",
      "\n",
      "Epoch 56 Batch 0 Loss 0.0439 Accuracy 0.3677\n",
      "Epoch 56 Loss 0.0360 Accuracy 0.3502\n",
      "Time taken for 1 epoch: 14.61260199546814 secs\n",
      "\n",
      "Epoch 57 Batch 0 Loss 0.0392 Accuracy 0.3351\n",
      "Epoch 57 Loss 0.0432 Accuracy 0.3501\n",
      "Time taken for 1 epoch: 15.051805257797241 secs\n",
      "\n",
      "Epoch 58 Batch 0 Loss 0.0504 Accuracy 0.3566\n",
      "Epoch 58 Loss 0.0384 Accuracy 0.3485\n",
      "Time taken for 1 epoch: 14.929625988006592 secs\n",
      "\n",
      "Epoch 59 Batch 0 Loss 0.0346 Accuracy 0.3695\n",
      "Epoch 59 Loss 0.0303 Accuracy 0.3468\n",
      "Time taken for 1 epoch: 15.20450210571289 secs\n",
      "\n",
      "Epoch 60 Batch 0 Loss 0.0341 Accuracy 0.3159\n",
      "Saving checkpoint for epoch 60 at ./checkpoints/train/ckpt-16\n",
      "Epoch 60 Loss 0.0358 Accuracy 0.3482\n",
      "Time taken for 1 epoch: 15.355625629425049 secs\n",
      "\n",
      "Epoch 61 Batch 0 Loss 0.0306 Accuracy 0.3374\n",
      "Epoch 61 Loss 0.0331 Accuracy 0.3506\n",
      "Time taken for 1 epoch: 14.539968013763428 secs\n",
      "\n",
      "Epoch 62 Batch 0 Loss 0.0323 Accuracy 0.3216\n",
      "Epoch 62 Loss 0.0320 Accuracy 0.3452\n",
      "Time taken for 1 epoch: 15.04527735710144 secs\n",
      "\n",
      "Epoch 63 Batch 0 Loss 0.0282 Accuracy 0.3666\n",
      "Epoch 63 Loss 0.0332 Accuracy 0.3525\n",
      "Time taken for 1 epoch: 15.561124563217163 secs\n",
      "\n",
      "Epoch 64 Batch 0 Loss 0.0336 Accuracy 0.3841\n",
      "Epoch 64 Loss 0.0359 Accuracy 0.3545\n",
      "Time taken for 1 epoch: 14.32405400276184 secs\n",
      "\n",
      "Epoch 65 Batch 0 Loss 0.0415 Accuracy 0.3562\n",
      "Saving checkpoint for epoch 65 at ./checkpoints/train/ckpt-17\n",
      "Epoch 65 Loss 0.0345 Accuracy 0.3565\n",
      "Time taken for 1 epoch: 15.2350914478302 secs\n",
      "\n",
      "Epoch 66 Batch 0 Loss 0.0243 Accuracy 0.2973\n",
      "Epoch 66 Loss 0.0293 Accuracy 0.3514\n",
      "Time taken for 1 epoch: 14.607591152191162 secs\n",
      "\n",
      "Epoch 67 Batch 0 Loss 0.0245 Accuracy 0.3438\n",
      "Epoch 67 Loss 0.0283 Accuracy 0.3589\n",
      "Time taken for 1 epoch: 14.360811710357666 secs\n",
      "\n",
      "Epoch 68 Batch 0 Loss 0.0453 Accuracy 0.4057\n",
      "Epoch 68 Loss 0.0296 Accuracy 0.3511\n",
      "Time taken for 1 epoch: 14.75017499923706 secs\n",
      "\n",
      "Epoch 69 Batch 0 Loss 0.0261 Accuracy 0.3730\n",
      "Epoch 69 Loss 0.0289 Accuracy 0.3502\n",
      "Time taken for 1 epoch: 14.599088430404663 secs\n",
      "\n",
      "Epoch 70 Batch 0 Loss 0.0167 Accuracy 0.3490\n",
      "Saving checkpoint for epoch 70 at ./checkpoints/train/ckpt-18\n",
      "Epoch 70 Loss 0.0285 Accuracy 0.3500\n",
      "Time taken for 1 epoch: 15.26119089126587 secs\n",
      "\n",
      "Epoch 71 Batch 0 Loss 0.0421 Accuracy 0.4526\n",
      "Epoch 71 Loss 0.0258 Accuracy 0.3509\n",
      "Time taken for 1 epoch: 14.906942129135132 secs\n",
      "\n",
      "Epoch 72 Batch 0 Loss 0.0288 Accuracy 0.3684\n",
      "Epoch 72 Loss 0.0274 Accuracy 0.3485\n",
      "Time taken for 1 epoch: 15.24405574798584 secs\n",
      "\n",
      "Epoch 73 Batch 0 Loss 0.0211 Accuracy 0.3552\n",
      "Epoch 73 Loss 0.0252 Accuracy 0.3481\n",
      "Time taken for 1 epoch: 14.696627378463745 secs\n",
      "\n",
      "Epoch 74 Batch 0 Loss 0.0242 Accuracy 0.3529\n",
      "Epoch 74 Loss 0.0237 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 14.686600685119629 secs\n",
      "\n",
      "Epoch 75 Batch 0 Loss 0.0270 Accuracy 0.3672\n",
      "Saving checkpoint for epoch 75 at ./checkpoints/train/ckpt-19\n",
      "Epoch 75 Loss 0.0266 Accuracy 0.3497\n",
      "Time taken for 1 epoch: 15.068031549453735 secs\n",
      "\n",
      "Epoch 76 Batch 0 Loss 0.0186 Accuracy 0.3259\n",
      "Epoch 76 Loss 0.0281 Accuracy 0.3523\n",
      "Time taken for 1 epoch: 14.355399131774902 secs\n",
      "\n",
      "Epoch 77 Batch 0 Loss 0.0297 Accuracy 0.3063\n",
      "Epoch 77 Loss 0.0265 Accuracy 0.3506\n",
      "Time taken for 1 epoch: 15.014415264129639 secs\n",
      "\n",
      "Epoch 78 Batch 0 Loss 0.0198 Accuracy 0.3646\n",
      "Epoch 78 Loss 0.0222 Accuracy 0.3486\n",
      "Time taken for 1 epoch: 14.562449932098389 secs\n",
      "\n",
      "Epoch 79 Batch 0 Loss 0.0234 Accuracy 0.3088\n",
      "Epoch 79 Loss 0.0271 Accuracy 0.3416\n",
      "Time taken for 1 epoch: 15.379944324493408 secs\n",
      "\n",
      "Epoch 80 Batch 0 Loss 0.0168 Accuracy 0.2921\n",
      "Saving checkpoint for epoch 80 at ./checkpoints/train/ckpt-20\n",
      "Epoch 80 Loss 0.0211 Accuracy 0.3468\n",
      "Time taken for 1 epoch: 15.230103731155396 secs\n",
      "\n",
      "Epoch 81 Batch 0 Loss 0.0226 Accuracy 0.3087\n",
      "Epoch 81 Loss 0.0209 Accuracy 0.3546\n",
      "Time taken for 1 epoch: 14.565812349319458 secs\n",
      "\n",
      "Epoch 82 Batch 0 Loss 0.0117 Accuracy 0.3496\n",
      "Epoch 82 Loss 0.0250 Accuracy 0.3557\n",
      "Time taken for 1 epoch: 14.386929035186768 secs\n",
      "\n",
      "Epoch 83 Batch 0 Loss 0.0130 Accuracy 0.3129\n",
      "Epoch 83 Loss 0.0251 Accuracy 0.3514\n",
      "Time taken for 1 epoch: 14.97472333908081 secs\n",
      "\n",
      "Epoch 84 Batch 0 Loss 0.0300 Accuracy 0.3963\n",
      "Epoch 84 Loss 0.0227 Accuracy 0.3524\n",
      "Time taken for 1 epoch: 14.580516576766968 secs\n",
      "\n",
      "Epoch 85 Batch 0 Loss 0.0142 Accuracy 0.4028\n",
      "Saving checkpoint for epoch 85 at ./checkpoints/train/ckpt-21\n",
      "Epoch 85 Loss 0.0225 Accuracy 0.3562\n",
      "Time taken for 1 epoch: 15.556257486343384 secs\n",
      "\n",
      "Epoch 86 Batch 0 Loss 0.0273 Accuracy 0.3491\n",
      "Epoch 86 Loss 0.0237 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 14.345421075820923 secs\n",
      "\n",
      "Epoch 87 Batch 0 Loss 0.0271 Accuracy 0.3902\n",
      "Epoch 87 Loss 0.0225 Accuracy 0.3532\n",
      "Time taken for 1 epoch: 14.90886926651001 secs\n",
      "\n",
      "Epoch 88 Batch 0 Loss 0.0215 Accuracy 0.3371\n",
      "Epoch 88 Loss 0.0222 Accuracy 0.3501\n",
      "Time taken for 1 epoch: 14.646564245223999 secs\n",
      "\n",
      "Epoch 89 Batch 0 Loss 0.0399 Accuracy 0.4097\n",
      "Epoch 89 Loss 0.0256 Accuracy 0.3610\n",
      "Time taken for 1 epoch: 14.483052015304565 secs\n",
      "\n",
      "Epoch 90 Batch 0 Loss 0.0132 Accuracy 0.4258\n",
      "Saving checkpoint for epoch 90 at ./checkpoints/train/ckpt-22\n",
      "Epoch 90 Loss 0.0243 Accuracy 0.3534\n",
      "Time taken for 1 epoch: 15.182907104492188 secs\n",
      "\n",
      "Epoch 91 Batch 0 Loss 0.0219 Accuracy 0.3498\n",
      "Epoch 91 Loss 0.0246 Accuracy 0.3559\n",
      "Time taken for 1 epoch: 14.319519281387329 secs\n",
      "\n",
      "Epoch 92 Batch 0 Loss 0.0215 Accuracy 0.3740\n",
      "Epoch 92 Loss 0.0192 Accuracy 0.3541\n",
      "Time taken for 1 epoch: 14.591975927352905 secs\n",
      "\n",
      "Epoch 93 Batch 0 Loss 0.0136 Accuracy 0.3183\n",
      "Epoch 93 Loss 0.0169 Accuracy 0.3465\n",
      "Time taken for 1 epoch: 15.017880916595459 secs\n",
      "\n",
      "Epoch 94 Batch 0 Loss 0.0193 Accuracy 0.3133\n",
      "Epoch 94 Loss 0.0234 Accuracy 0.3547\n",
      "Time taken for 1 epoch: 14.530192613601685 secs\n",
      "\n",
      "Epoch 95 Batch 0 Loss 0.0140 Accuracy 0.3516\n",
      "Saving checkpoint for epoch 95 at ./checkpoints/train/ckpt-23\n",
      "Epoch 95 Loss 0.0242 Accuracy 0.3528\n",
      "Time taken for 1 epoch: 15.376303911209106 secs\n",
      "\n",
      "Epoch 96 Batch 0 Loss 0.0281 Accuracy 0.3160\n",
      "Epoch 96 Loss 0.0213 Accuracy 0.3536\n",
      "Time taken for 1 epoch: 14.424175262451172 secs\n",
      "\n",
      "Epoch 97 Batch 0 Loss 0.0274 Accuracy 0.3772\n",
      "Epoch 97 Loss 0.0191 Accuracy 0.3570\n",
      "Time taken for 1 epoch: 14.691869497299194 secs\n",
      "\n",
      "Epoch 98 Batch 0 Loss 0.0130 Accuracy 0.2973\n",
      "Epoch 98 Loss 0.0186 Accuracy 0.3531\n",
      "Time taken for 1 epoch: 14.64866042137146 secs\n",
      "\n",
      "Epoch 99 Batch 0 Loss 0.0181 Accuracy 0.3418\n",
      "Epoch 99 Loss 0.0237 Accuracy 0.3528\n",
      "Time taken for 1 epoch: 14.847469091415405 secs\n",
      "\n",
      "Epoch 100 Batch 0 Loss 0.0153 Accuracy 0.3237\n",
      "Saving checkpoint for epoch 100 at ./checkpoints/train/ckpt-24\n",
      "Epoch 100 Loss 0.0187 Accuracy 0.3557\n",
      "Time taken for 1 epoch: 14.797021389007568 secs\n",
      "\n",
      "Epoch 101 Batch 0 Loss 0.0275 Accuracy 0.4912\n",
      "Epoch 101 Loss 0.0171 Accuracy 0.3544\n",
      "Time taken for 1 epoch: 14.491694450378418 secs\n",
      "\n",
      "Epoch 102 Batch 0 Loss 0.0123 Accuracy 0.3281\n",
      "Epoch 102 Loss 0.0215 Accuracy 0.3460\n",
      "Time taken for 1 epoch: 15.18472933769226 secs\n",
      "\n",
      "Epoch 103 Batch 0 Loss 0.0134 Accuracy 0.4154\n",
      "Epoch 103 Loss 0.0197 Accuracy 0.3510\n",
      "Time taken for 1 epoch: 15.566195487976074 secs\n",
      "\n",
      "Epoch 104 Batch 0 Loss 0.0182 Accuracy 0.2961\n",
      "Epoch 104 Loss 0.0211 Accuracy 0.3538\n",
      "Time taken for 1 epoch: 16.15317964553833 secs\n",
      "\n",
      "Epoch 105 Batch 0 Loss 0.0174 Accuracy 0.3429\n",
      "Saving checkpoint for epoch 105 at ./checkpoints/train/ckpt-25\n",
      "Epoch 105 Loss 0.0174 Accuracy 0.3576\n",
      "Time taken for 1 epoch: 15.16231107711792 secs\n",
      "\n",
      "Epoch 106 Batch 0 Loss 0.0100 Accuracy 0.3300\n",
      "Epoch 106 Loss 0.0175 Accuracy 0.3506\n",
      "Time taken for 1 epoch: 14.807017087936401 secs\n",
      "\n",
      "Epoch 107 Batch 0 Loss 0.0148 Accuracy 0.3253\n",
      "Epoch 107 Loss 0.0163 Accuracy 0.3535\n",
      "Time taken for 1 epoch: 14.63974404335022 secs\n",
      "\n",
      "Epoch 108 Batch 0 Loss 0.0090 Accuracy 0.3656\n",
      "Epoch 108 Loss 0.0171 Accuracy 0.3548\n",
      "Time taken for 1 epoch: 14.588964462280273 secs\n",
      "\n",
      "Epoch 109 Batch 0 Loss 0.0040 Accuracy 0.3042\n",
      "Epoch 109 Loss 0.0171 Accuracy 0.3534\n",
      "Time taken for 1 epoch: 14.638254880905151 secs\n",
      "\n",
      "Epoch 110 Batch 0 Loss 0.0135 Accuracy 0.3745\n",
      "Saving checkpoint for epoch 110 at ./checkpoints/train/ckpt-26\n",
      "Epoch 110 Loss 0.0148 Accuracy 0.3571\n",
      "Time taken for 1 epoch: 15.049414873123169 secs\n",
      "\n",
      "Epoch 111 Batch 0 Loss 0.0069 Accuracy 0.3508\n",
      "Epoch 111 Loss 0.0107 Accuracy 0.3543\n",
      "Time taken for 1 epoch: 14.593030214309692 secs\n",
      "\n",
      "Epoch 112 Batch 0 Loss 0.0147 Accuracy 0.3146\n",
      "Epoch 112 Loss 0.0125 Accuracy 0.3564\n",
      "Time taken for 1 epoch: 14.929909944534302 secs\n",
      "\n",
      "Epoch 113 Batch 0 Loss 0.0176 Accuracy 0.4606\n",
      "Epoch 113 Loss 0.0137 Accuracy 0.3524\n",
      "Time taken for 1 epoch: 14.740007400512695 secs\n",
      "\n",
      "Epoch 114 Batch 0 Loss 0.0102 Accuracy 0.3482\n",
      "Epoch 114 Loss 0.0130 Accuracy 0.3518\n",
      "Time taken for 1 epoch: 14.945748090744019 secs\n",
      "\n",
      "Epoch 115 Batch 0 Loss 0.0205 Accuracy 0.3194\n",
      "Saving checkpoint for epoch 115 at ./checkpoints/train/ckpt-27\n",
      "Epoch 115 Loss 0.0130 Accuracy 0.3524\n",
      "Time taken for 1 epoch: 15.329188823699951 secs\n",
      "\n",
      "Epoch 116 Batch 0 Loss 0.0092 Accuracy 0.3480\n",
      "Epoch 116 Loss 0.0134 Accuracy 0.3548\n",
      "Time taken for 1 epoch: 14.605071306228638 secs\n",
      "\n",
      "Epoch 117 Batch 0 Loss 0.0104 Accuracy 0.3203\n",
      "Epoch 117 Loss 0.0107 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 14.793297529220581 secs\n",
      "\n",
      "Epoch 118 Batch 0 Loss 0.0166 Accuracy 0.3438\n",
      "Epoch 118 Loss 0.0145 Accuracy 0.3534\n",
      "Time taken for 1 epoch: 14.630559921264648 secs\n",
      "\n",
      "Epoch 119 Batch 0 Loss 0.0081 Accuracy 0.3483\n",
      "Epoch 119 Loss 0.0146 Accuracy 0.3549\n",
      "Time taken for 1 epoch: 14.575197696685791 secs\n",
      "\n",
      "Epoch 120 Batch 0 Loss 0.0077 Accuracy 0.3456\n",
      "Saving checkpoint for epoch 120 at ./checkpoints/train/ckpt-28\n",
      "Epoch 120 Loss 0.0130 Accuracy 0.3489\n",
      "Time taken for 1 epoch: 15.597119569778442 secs\n",
      "\n",
      "Epoch 121 Batch 0 Loss 0.0062 Accuracy 0.3170\n",
      "Epoch 121 Loss 0.0121 Accuracy 0.3571\n",
      "Time taken for 1 epoch: 14.468667984008789 secs\n",
      "\n",
      "Epoch 122 Batch 0 Loss 0.0125 Accuracy 0.4010\n",
      "Epoch 122 Loss 0.0107 Accuracy 0.3588\n",
      "Time taken for 1 epoch: 14.550277948379517 secs\n",
      "\n",
      "Epoch 123 Batch 0 Loss 0.0077 Accuracy 0.3740\n",
      "Epoch 123 Loss 0.0116 Accuracy 0.3583\n",
      "Time taken for 1 epoch: 14.718891620635986 secs\n",
      "\n",
      "Epoch 124 Batch 0 Loss 0.0160 Accuracy 0.4020\n",
      "Epoch 124 Loss 0.0128 Accuracy 0.3568\n",
      "Time taken for 1 epoch: 14.446846008300781 secs\n",
      "\n",
      "Epoch 125 Batch 0 Loss 0.0042 Accuracy 0.2889\n",
      "Saving checkpoint for epoch 125 at ./checkpoints/train/ckpt-29\n",
      "Epoch 125 Loss 0.0088 Accuracy 0.3578\n",
      "Time taken for 1 epoch: 15.290895223617554 secs\n",
      "\n",
      "Epoch 126 Batch 0 Loss 0.0059 Accuracy 0.4609\n",
      "Epoch 126 Loss 0.0141 Accuracy 0.3629\n",
      "Time taken for 1 epoch: 14.339631080627441 secs\n",
      "\n",
      "Epoch 127 Batch 0 Loss 0.0052 Accuracy 0.3286\n",
      "Epoch 127 Loss 0.0102 Accuracy 0.3558\n",
      "Time taken for 1 epoch: 14.794387102127075 secs\n",
      "\n",
      "Epoch 128 Batch 0 Loss 0.0120 Accuracy 0.3069\n",
      "Epoch 128 Loss 0.0096 Accuracy 0.3611\n",
      "Time taken for 1 epoch: 14.51216197013855 secs\n",
      "\n",
      "Epoch 129 Batch 0 Loss 0.0073 Accuracy 0.3478\n",
      "Epoch 129 Loss 0.0103 Accuracy 0.3578\n",
      "Time taken for 1 epoch: 14.466315031051636 secs\n",
      "\n",
      "Epoch 130 Batch 0 Loss 0.0068 Accuracy 0.3712\n",
      "Saving checkpoint for epoch 130 at ./checkpoints/train/ckpt-30\n",
      "Epoch 130 Loss 0.0112 Accuracy 0.3641\n",
      "Time taken for 1 epoch: 14.946075439453125 secs\n",
      "\n",
      "Epoch 131 Batch 0 Loss 0.0140 Accuracy 0.3209\n",
      "Epoch 131 Loss 0.0094 Accuracy 0.3595\n",
      "Time taken for 1 epoch: 14.388277769088745 secs\n",
      "\n",
      "Epoch 132 Batch 0 Loss 0.0029 Accuracy 0.3405\n",
      "Epoch 132 Loss 0.0104 Accuracy 0.3550\n",
      "Time taken for 1 epoch: 14.82307243347168 secs\n",
      "\n",
      "Epoch 133 Batch 0 Loss 0.0122 Accuracy 0.3668\n",
      "Epoch 133 Loss 0.0080 Accuracy 0.3556\n",
      "Time taken for 1 epoch: 14.587070226669312 secs\n",
      "\n",
      "Epoch 134 Batch 0 Loss 0.0045 Accuracy 0.3408\n",
      "Epoch 134 Loss 0.0100 Accuracy 0.3521\n",
      "Time taken for 1 epoch: 14.996338605880737 secs\n",
      "\n",
      "Epoch 135 Batch 0 Loss 0.0052 Accuracy 0.3408\n",
      "Saving checkpoint for epoch 135 at ./checkpoints/train/ckpt-31\n",
      "Epoch 135 Loss 0.0110 Accuracy 0.3512\n",
      "Time taken for 1 epoch: 15.340369939804077 secs\n",
      "\n",
      "Epoch 136 Batch 0 Loss 0.0098 Accuracy 0.3826\n",
      "Epoch 136 Loss 0.0085 Accuracy 0.3606\n",
      "Time taken for 1 epoch: 14.570038557052612 secs\n",
      "\n",
      "Epoch 137 Batch 0 Loss 0.0090 Accuracy 0.3205\n",
      "Epoch 137 Loss 0.0092 Accuracy 0.3596\n",
      "Time taken for 1 epoch: 14.795255899429321 secs\n",
      "\n",
      "Epoch 138 Batch 0 Loss 0.0073 Accuracy 0.3509\n",
      "Epoch 138 Loss 0.0086 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 14.850210905075073 secs\n",
      "\n",
      "Epoch 139 Batch 0 Loss 0.0063 Accuracy 0.3389\n",
      "Epoch 139 Loss 0.0088 Accuracy 0.3589\n",
      "Time taken for 1 epoch: 14.478284358978271 secs\n",
      "\n",
      "Epoch 140 Batch 0 Loss 0.0088 Accuracy 0.3035\n",
      "Saving checkpoint for epoch 140 at ./checkpoints/train/ckpt-32\n",
      "Epoch 140 Loss 0.0088 Accuracy 0.3495\n",
      "Time taken for 1 epoch: 15.25875186920166 secs\n",
      "\n",
      "Epoch 141 Batch 0 Loss 0.0030 Accuracy 0.3793\n",
      "Epoch 141 Loss 0.0090 Accuracy 0.3559\n",
      "Time taken for 1 epoch: 15.011216163635254 secs\n",
      "\n",
      "Epoch 142 Batch 0 Loss 0.0050 Accuracy 0.3049\n",
      "Epoch 142 Loss 0.0082 Accuracy 0.3487\n",
      "Time taken for 1 epoch: 14.958717107772827 secs\n",
      "\n",
      "Epoch 143 Batch 0 Loss 0.0113 Accuracy 0.4319\n",
      "Epoch 143 Loss 0.0079 Accuracy 0.3597\n",
      "Time taken for 1 epoch: 14.540330171585083 secs\n",
      "\n",
      "Epoch 144 Batch 0 Loss 0.0099 Accuracy 0.3616\n",
      "Epoch 144 Loss 0.0064 Accuracy 0.3538\n",
      "Time taken for 1 epoch: 15.73993992805481 secs\n",
      "\n",
      "Epoch 145 Batch 0 Loss 0.0038 Accuracy 0.4235\n",
      "Saving checkpoint for epoch 145 at ./checkpoints/train/ckpt-33\n",
      "Epoch 145 Loss 0.0071 Accuracy 0.3598\n",
      "Time taken for 1 epoch: 14.823463439941406 secs\n",
      "\n",
      "Epoch 146 Batch 0 Loss 0.0073 Accuracy 0.3509\n",
      "Epoch 146 Loss 0.0091 Accuracy 0.3592\n",
      "Time taken for 1 epoch: 14.742882013320923 secs\n",
      "\n",
      "Epoch 147 Batch 0 Loss 0.0021 Accuracy 0.4091\n",
      "Epoch 147 Loss 0.0087 Accuracy 0.3572\n",
      "Time taken for 1 epoch: 14.615465641021729 secs\n",
      "\n",
      "Epoch 148 Batch 0 Loss 0.0078 Accuracy 0.2825\n",
      "Epoch 148 Loss 0.0090 Accuracy 0.3585\n",
      "Time taken for 1 epoch: 14.648797035217285 secs\n",
      "\n",
      "Epoch 149 Batch 0 Loss 0.0065 Accuracy 0.3381\n",
      "Epoch 149 Loss 0.0106 Accuracy 0.3586\n",
      "Time taken for 1 epoch: 14.49993634223938 secs\n",
      "\n",
      "Epoch 150 Batch 0 Loss 0.0082 Accuracy 0.3290\n",
      "Saving checkpoint for epoch 150 at ./checkpoints/train/ckpt-34\n",
      "Epoch 150 Loss 0.0072 Accuracy 0.3577\n",
      "Time taken for 1 epoch: 14.956217050552368 secs\n",
      "\n",
      "Epoch 151 Batch 0 Loss 0.0034 Accuracy 0.3589\n",
      "Epoch 151 Loss 0.0075 Accuracy 0.3556\n",
      "Time taken for 1 epoch: 14.760164260864258 secs\n",
      "\n",
      "Epoch 152 Batch 0 Loss 0.0040 Accuracy 0.3277\n",
      "Epoch 152 Loss 0.0078 Accuracy 0.3520\n",
      "Time taken for 1 epoch: 14.803697109222412 secs\n",
      "\n",
      "Epoch 153 Batch 0 Loss 0.0085 Accuracy 0.2851\n",
      "Epoch 153 Loss 0.0084 Accuracy 0.3520\n",
      "Time taken for 1 epoch: 15.226103782653809 secs\n",
      "\n",
      "Epoch 154 Batch 0 Loss 0.0146 Accuracy 0.4186\n",
      "Epoch 154 Loss 0.0063 Accuracy 0.3557\n",
      "Time taken for 1 epoch: 14.601195335388184 secs\n",
      "\n",
      "Epoch 155 Batch 0 Loss 0.0063 Accuracy 0.3706\n",
      "Saving checkpoint for epoch 155 at ./checkpoints/train/ckpt-35\n",
      "Epoch 155 Loss 0.0079 Accuracy 0.3562\n",
      "Time taken for 1 epoch: 15.830615997314453 secs\n",
      "\n",
      "Epoch 156 Batch 0 Loss 0.0019 Accuracy 0.2930\n",
      "Epoch 156 Loss 0.0059 Accuracy 0.3561\n",
      "Time taken for 1 epoch: 14.81007432937622 secs\n",
      "\n",
      "Epoch 157 Batch 0 Loss 0.0044 Accuracy 0.3405\n",
      "Epoch 157 Loss 0.0068 Accuracy 0.3532\n",
      "Time taken for 1 epoch: 14.818647384643555 secs\n",
      "\n",
      "Epoch 158 Batch 0 Loss 0.0124 Accuracy 0.3013\n",
      "Epoch 158 Loss 0.0061 Accuracy 0.3573\n",
      "Time taken for 1 epoch: 14.89331316947937 secs\n",
      "\n",
      "Epoch 159 Batch 0 Loss 0.0087 Accuracy 0.3594\n",
      "Epoch 159 Loss 0.0056 Accuracy 0.3533\n",
      "Time taken for 1 epoch: 14.78722357749939 secs\n",
      "\n",
      "Epoch 160 Batch 0 Loss 0.0041 Accuracy 0.4387\n",
      "Saving checkpoint for epoch 160 at ./checkpoints/train/ckpt-36\n",
      "Epoch 160 Loss 0.0058 Accuracy 0.3577\n",
      "Time taken for 1 epoch: 15.065797090530396 secs\n",
      "\n",
      "Epoch 161 Batch 0 Loss 0.0027 Accuracy 0.3545\n",
      "Epoch 161 Loss 0.0090 Accuracy 0.3611\n",
      "Time taken for 1 epoch: 14.58893084526062 secs\n",
      "\n",
      "Epoch 162 Batch 0 Loss 0.0081 Accuracy 0.3511\n",
      "Epoch 162 Loss 0.0065 Accuracy 0.3556\n",
      "Time taken for 1 epoch: 14.695510864257812 secs\n",
      "\n",
      "Epoch 163 Batch 0 Loss 0.0111 Accuracy 0.3973\n",
      "Epoch 163 Loss 0.0059 Accuracy 0.3591\n",
      "Time taken for 1 epoch: 14.509212732315063 secs\n",
      "\n",
      "Epoch 164 Batch 0 Loss 0.0020 Accuracy 0.4365\n",
      "Epoch 164 Loss 0.0060 Accuracy 0.3567\n",
      "Time taken for 1 epoch: 14.913574457168579 secs\n",
      "\n",
      "Epoch 165 Batch 0 Loss 0.0062 Accuracy 0.4734\n",
      "Saving checkpoint for epoch 165 at ./checkpoints/train/ckpt-37\n",
      "Epoch 165 Loss 0.0060 Accuracy 0.3561\n",
      "Time taken for 1 epoch: 15.139217615127563 secs\n",
      "\n",
      "Epoch 166 Batch 0 Loss 0.0091 Accuracy 0.3764\n",
      "Epoch 166 Loss 0.0059 Accuracy 0.3526\n",
      "Time taken for 1 epoch: 15.174134254455566 secs\n",
      "\n",
      "Epoch 167 Batch 0 Loss 0.0039 Accuracy 0.3652\n",
      "Epoch 167 Loss 0.0062 Accuracy 0.3542\n",
      "Time taken for 1 epoch: 15.02258563041687 secs\n",
      "\n",
      "Epoch 168 Batch 0 Loss 0.0032 Accuracy 0.4314\n",
      "Epoch 168 Loss 0.0051 Accuracy 0.3561\n",
      "Time taken for 1 epoch: 14.728375434875488 secs\n",
      "\n",
      "Epoch 169 Batch 0 Loss 0.0035 Accuracy 0.3567\n",
      "Epoch 169 Loss 0.0067 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 14.780737161636353 secs\n",
      "\n",
      "Epoch 170 Batch 0 Loss 0.0049 Accuracy 0.4213\n",
      "Saving checkpoint for epoch 170 at ./checkpoints/train/ckpt-38\n",
      "Epoch 170 Loss 0.0069 Accuracy 0.3578\n",
      "Time taken for 1 epoch: 15.041317224502563 secs\n",
      "\n",
      "Epoch 171 Batch 0 Loss 0.0049 Accuracy 0.3146\n",
      "Epoch 171 Loss 0.0063 Accuracy 0.3596\n",
      "Time taken for 1 epoch: 14.454230546951294 secs\n",
      "\n",
      "Epoch 172 Batch 0 Loss 0.0130 Accuracy 0.3150\n",
      "Epoch 172 Loss 0.0047 Accuracy 0.3531\n",
      "Time taken for 1 epoch: 15.478944540023804 secs\n",
      "\n",
      "Epoch 173 Batch 0 Loss 0.0033 Accuracy 0.3774\n",
      "Epoch 173 Loss 0.0055 Accuracy 0.3655\n",
      "Time taken for 1 epoch: 14.270248651504517 secs\n",
      "\n",
      "Epoch 174 Batch 0 Loss 0.0032 Accuracy 0.4165\n",
      "Epoch 174 Loss 0.0062 Accuracy 0.3549\n",
      "Time taken for 1 epoch: 14.908718585968018 secs\n",
      "\n",
      "Epoch 175 Batch 0 Loss 0.0057 Accuracy 0.3818\n",
      "Saving checkpoint for epoch 175 at ./checkpoints/train/ckpt-39\n",
      "Epoch 175 Loss 0.0044 Accuracy 0.3539\n",
      "Time taken for 1 epoch: 15.433063983917236 secs\n",
      "\n",
      "Epoch 176 Batch 0 Loss 0.0009 Accuracy 0.3209\n",
      "Epoch 176 Loss 0.0049 Accuracy 0.3521\n",
      "Time taken for 1 epoch: 14.886361837387085 secs\n",
      "\n",
      "Epoch 177 Batch 0 Loss 0.0049 Accuracy 0.2878\n",
      "Epoch 177 Loss 0.0048 Accuracy 0.3589\n",
      "Time taken for 1 epoch: 14.909785509109497 secs\n",
      "\n",
      "Epoch 178 Batch 0 Loss 0.0041 Accuracy 0.3225\n",
      "Epoch 178 Loss 0.0053 Accuracy 0.3554\n",
      "Time taken for 1 epoch: 14.726413249969482 secs\n",
      "\n",
      "Epoch 179 Batch 0 Loss 0.0074 Accuracy 0.3655\n",
      "Epoch 179 Loss 0.0059 Accuracy 0.3555\n",
      "Time taken for 1 epoch: 14.80812120437622 secs\n",
      "\n",
      "Epoch 180 Batch 0 Loss 0.0029 Accuracy 0.4115\n",
      "Saving checkpoint for epoch 180 at ./checkpoints/train/ckpt-40\n",
      "Epoch 180 Loss 0.0061 Accuracy 0.3602\n",
      "Time taken for 1 epoch: 15.165578126907349 secs\n",
      "\n",
      "Epoch 181 Batch 0 Loss 0.0022 Accuracy 0.3962\n",
      "Epoch 181 Loss 0.0057 Accuracy 0.3526\n",
      "Time taken for 1 epoch: 14.756699323654175 secs\n",
      "\n",
      "Epoch 182 Batch 0 Loss 0.0018 Accuracy 0.2700\n",
      "Epoch 182 Loss 0.0059 Accuracy 0.3516\n",
      "Time taken for 1 epoch: 15.130074739456177 secs\n",
      "\n",
      "Epoch 183 Batch 0 Loss 0.0133 Accuracy 0.3043\n",
      "Epoch 183 Loss 0.0061 Accuracy 0.3603\n",
      "Time taken for 1 epoch: 14.835023880004883 secs\n",
      "\n",
      "Epoch 184 Batch 0 Loss 0.0028 Accuracy 0.3369\n",
      "Epoch 184 Loss 0.0068 Accuracy 0.3613\n",
      "Time taken for 1 epoch: 15.98868989944458 secs\n",
      "\n",
      "Epoch 185 Batch 0 Loss 0.0060 Accuracy 0.3906\n",
      "Saving checkpoint for epoch 185 at ./checkpoints/train/ckpt-41\n",
      "Epoch 185 Loss 0.0053 Accuracy 0.3577\n",
      "Time taken for 1 epoch: 16.00693917274475 secs\n",
      "\n",
      "Epoch 186 Batch 0 Loss 0.0145 Accuracy 0.4115\n",
      "Epoch 186 Loss 0.0061 Accuracy 0.3545\n",
      "Time taken for 1 epoch: 17.297911882400513 secs\n",
      "\n",
      "Epoch 187 Batch 0 Loss 0.0119 Accuracy 0.3374\n",
      "Epoch 187 Loss 0.0057 Accuracy 0.3595\n",
      "Time taken for 1 epoch: 15.845948934555054 secs\n",
      "\n",
      "Epoch 188 Batch 0 Loss 0.0033 Accuracy 0.3828\n",
      "Epoch 188 Loss 0.0053 Accuracy 0.3640\n",
      "Time taken for 1 epoch: 14.812193870544434 secs\n",
      "\n",
      "Epoch 189 Batch 0 Loss 0.0021 Accuracy 0.3770\n",
      "Epoch 189 Loss 0.0041 Accuracy 0.3572\n",
      "Time taken for 1 epoch: 14.602425813674927 secs\n",
      "\n",
      "Epoch 190 Batch 0 Loss 0.0006 Accuracy 0.2865\n",
      "Saving checkpoint for epoch 190 at ./checkpoints/train/ckpt-42\n",
      "Epoch 190 Loss 0.0049 Accuracy 0.3530\n",
      "Time taken for 1 epoch: 15.58698320388794 secs\n",
      "\n",
      "Epoch 191 Batch 0 Loss 0.0022 Accuracy 0.4464\n",
      "Epoch 191 Loss 0.0037 Accuracy 0.3589\n",
      "Time taken for 1 epoch: 14.771170616149902 secs\n",
      "\n",
      "Epoch 192 Batch 0 Loss 0.0049 Accuracy 0.4009\n",
      "Epoch 192 Loss 0.0049 Accuracy 0.3572\n",
      "Time taken for 1 epoch: 14.741683006286621 secs\n",
      "\n",
      "Epoch 193 Batch 0 Loss 0.0037 Accuracy 0.3927\n",
      "Epoch 193 Loss 0.0052 Accuracy 0.3515\n",
      "Time taken for 1 epoch: 15.335116386413574 secs\n",
      "\n",
      "Epoch 194 Batch 0 Loss 0.0028 Accuracy 0.4252\n",
      "Epoch 194 Loss 0.0033 Accuracy 0.3549\n",
      "Time taken for 1 epoch: 14.720247030258179 secs\n",
      "\n",
      "Epoch 195 Batch 0 Loss 0.0035 Accuracy 0.3696\n",
      "Saving checkpoint for epoch 195 at ./checkpoints/train/ckpt-43\n",
      "Epoch 195 Loss 0.0047 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 15.751685380935669 secs\n",
      "\n",
      "Epoch 196 Batch 0 Loss 0.0033 Accuracy 0.3218\n",
      "Epoch 196 Loss 0.0042 Accuracy 0.3472\n",
      "Time taken for 1 epoch: 15.186108350753784 secs\n",
      "\n",
      "Epoch 197 Batch 0 Loss 0.0038 Accuracy 0.3500\n",
      "Epoch 197 Loss 0.0055 Accuracy 0.3598\n",
      "Time taken for 1 epoch: 14.598324298858643 secs\n",
      "\n",
      "Epoch 198 Batch 0 Loss 0.0058 Accuracy 0.3863\n",
      "Epoch 198 Loss 0.0046 Accuracy 0.3535\n",
      "Time taken for 1 epoch: 15.183051586151123 secs\n",
      "\n",
      "Epoch 199 Batch 0 Loss 0.0068 Accuracy 0.3245\n",
      "Epoch 199 Loss 0.0056 Accuracy 0.3522\n",
      "Time taken for 1 epoch: 15.340599298477173 secs\n",
      "\n",
      "Epoch 200 Batch 0 Loss 0.0080 Accuracy 0.4088\n",
      "Saving checkpoint for epoch 200 at ./checkpoints/train/ckpt-44\n",
      "Epoch 200 Loss 0.0046 Accuracy 0.3569\n",
      "Time taken for 1 epoch: 15.190048217773438 secs\n",
      "\n",
      "Epoch 201 Batch 0 Loss 0.0014 Accuracy 0.3760\n",
      "Epoch 201 Loss 0.0052 Accuracy 0.3476\n",
      "Time taken for 1 epoch: 15.445561170578003 secs\n",
      "\n",
      "Epoch 202 Batch 0 Loss 0.0019 Accuracy 0.3472\n",
      "Epoch 202 Loss 0.0049 Accuracy 0.3622\n",
      "Time taken for 1 epoch: 14.488986015319824 secs\n",
      "\n",
      "Epoch 203 Batch 0 Loss 0.0033 Accuracy 0.3810\n",
      "Epoch 203 Loss 0.0040 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 14.871488094329834 secs\n",
      "\n",
      "Epoch 204 Batch 0 Loss 0.0028 Accuracy 0.3029\n",
      "Epoch 204 Loss 0.0035 Accuracy 0.3580\n",
      "Time taken for 1 epoch: 14.911969900131226 secs\n",
      "\n",
      "Epoch 205 Batch 0 Loss 0.0040 Accuracy 0.3892\n",
      "Saving checkpoint for epoch 205 at ./checkpoints/train/ckpt-45\n",
      "Epoch 205 Loss 0.0047 Accuracy 0.3547\n",
      "Time taken for 1 epoch: 15.353855609893799 secs\n",
      "\n",
      "Epoch 206 Batch 0 Loss 0.0025 Accuracy 0.3760\n",
      "Epoch 206 Loss 0.0035 Accuracy 0.3573\n",
      "Time taken for 1 epoch: 14.832812786102295 secs\n",
      "\n",
      "Epoch 207 Batch 0 Loss 0.0020 Accuracy 0.3931\n",
      "Epoch 207 Loss 0.0042 Accuracy 0.3586\n",
      "Time taken for 1 epoch: 14.938174486160278 secs\n",
      "\n",
      "Epoch 208 Batch 0 Loss 0.0030 Accuracy 0.3828\n",
      "Epoch 208 Loss 0.0036 Accuracy 0.3536\n",
      "Time taken for 1 epoch: 14.733621597290039 secs\n",
      "\n",
      "Epoch 209 Batch 0 Loss 0.0014 Accuracy 0.3655\n",
      "Epoch 209 Loss 0.0051 Accuracy 0.3654\n",
      "Time taken for 1 epoch: 14.567619562149048 secs\n",
      "\n",
      "Epoch 210 Batch 0 Loss 0.0043 Accuracy 0.3875\n",
      "Saving checkpoint for epoch 210 at ./checkpoints/train/ckpt-46\n",
      "Epoch 210 Loss 0.0047 Accuracy 0.3598\n",
      "Time taken for 1 epoch: 15.083978414535522 secs\n",
      "\n",
      "Epoch 211 Batch 0 Loss 0.0017 Accuracy 0.3666\n",
      "Epoch 211 Loss 0.0054 Accuracy 0.3722\n",
      "Time taken for 1 epoch: 14.221848726272583 secs\n",
      "\n",
      "Epoch 212 Batch 0 Loss 0.0087 Accuracy 0.3702\n",
      "Epoch 212 Loss 0.0044 Accuracy 0.3619\n",
      "Time taken for 1 epoch: 14.832574844360352 secs\n",
      "\n",
      "Epoch 213 Batch 0 Loss 0.0018 Accuracy 0.3225\n",
      "Epoch 213 Loss 0.0043 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 14.969673871994019 secs\n",
      "\n",
      "Epoch 214 Batch 0 Loss 0.0053 Accuracy 0.3394\n",
      "Epoch 214 Loss 0.0040 Accuracy 0.3535\n",
      "Time taken for 1 epoch: 15.35834813117981 secs\n",
      "\n",
      "Epoch 215 Batch 0 Loss 0.0040 Accuracy 0.3087\n",
      "Saving checkpoint for epoch 215 at ./checkpoints/train/ckpt-47\n",
      "Epoch 215 Loss 0.0050 Accuracy 0.3496\n",
      "Time taken for 1 epoch: 15.556949615478516 secs\n",
      "\n",
      "Epoch 216 Batch 0 Loss 0.0018 Accuracy 0.4103\n",
      "Epoch 216 Loss 0.0031 Accuracy 0.3618\n",
      "Time taken for 1 epoch: 14.791027784347534 secs\n",
      "\n",
      "Epoch 217 Batch 0 Loss 0.0094 Accuracy 0.3944\n",
      "Epoch 217 Loss 0.0050 Accuracy 0.3657\n",
      "Time taken for 1 epoch: 14.516746997833252 secs\n",
      "\n",
      "Epoch 218 Batch 0 Loss 0.0045 Accuracy 0.3117\n",
      "Epoch 218 Loss 0.0034 Accuracy 0.3547\n",
      "Time taken for 1 epoch: 15.100563526153564 secs\n",
      "\n",
      "Epoch 219 Batch 0 Loss 0.0011 Accuracy 0.3245\n",
      "Epoch 219 Loss 0.0035 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 14.816378593444824 secs\n",
      "\n",
      "Epoch 220 Batch 0 Loss 0.0046 Accuracy 0.3201\n",
      "Saving checkpoint for epoch 220 at ./checkpoints/train/ckpt-48\n",
      "Epoch 220 Loss 0.0043 Accuracy 0.3653\n",
      "Time taken for 1 epoch: 14.87474250793457 secs\n",
      "\n",
      "Epoch 221 Batch 0 Loss 0.0004 Accuracy 0.3377\n",
      "Epoch 221 Loss 0.0034 Accuracy 0.3627\n",
      "Time taken for 1 epoch: 14.625685691833496 secs\n",
      "\n",
      "Epoch 222 Batch 0 Loss 0.0006 Accuracy 0.4224\n",
      "Epoch 222 Loss 0.0031 Accuracy 0.3545\n",
      "Time taken for 1 epoch: 15.072507381439209 secs\n",
      "\n",
      "Epoch 223 Batch 0 Loss 0.0015 Accuracy 0.3190\n",
      "Epoch 223 Loss 0.0040 Accuracy 0.3551\n",
      "Time taken for 1 epoch: 15.039905309677124 secs\n",
      "\n",
      "Epoch 224 Batch 0 Loss 0.0039 Accuracy 0.3530\n",
      "Epoch 224 Loss 0.0039 Accuracy 0.3545\n",
      "Time taken for 1 epoch: 15.88262128829956 secs\n",
      "\n",
      "Epoch 225 Batch 0 Loss 0.0012 Accuracy 0.3914\n",
      "Saving checkpoint for epoch 225 at ./checkpoints/train/ckpt-49\n",
      "Epoch 225 Loss 0.0041 Accuracy 0.3559\n",
      "Time taken for 1 epoch: 15.472306728363037 secs\n",
      "\n",
      "Epoch 226 Batch 0 Loss 0.0030 Accuracy 0.4073\n",
      "Epoch 226 Loss 0.0044 Accuracy 0.3586\n",
      "Time taken for 1 epoch: 14.88597583770752 secs\n",
      "\n",
      "Epoch 227 Batch 0 Loss 0.0011 Accuracy 0.3682\n",
      "Epoch 227 Loss 0.0033 Accuracy 0.3546\n",
      "Time taken for 1 epoch: 15.162075519561768 secs\n",
      "\n",
      "Epoch 228 Batch 0 Loss 0.0011 Accuracy 0.3859\n",
      "Epoch 228 Loss 0.0033 Accuracy 0.3613\n",
      "Time taken for 1 epoch: 14.709010124206543 secs\n",
      "\n",
      "Epoch 229 Batch 0 Loss 0.0032 Accuracy 0.3878\n",
      "Epoch 229 Loss 0.0039 Accuracy 0.3595\n",
      "Time taken for 1 epoch: 14.714599609375 secs\n",
      "\n",
      "Epoch 230 Batch 0 Loss 0.0005 Accuracy 0.3622\n",
      "Saving checkpoint for epoch 230 at ./checkpoints/train/ckpt-50\n",
      "Epoch 230 Loss 0.0033 Accuracy 0.3584\n",
      "Time taken for 1 epoch: 15.207570552825928 secs\n",
      "\n",
      "Epoch 231 Batch 0 Loss 0.0013 Accuracy 0.3384\n",
      "Epoch 231 Loss 0.0044 Accuracy 0.3587\n",
      "Time taken for 1 epoch: 14.760436773300171 secs\n",
      "\n",
      "Epoch 232 Batch 0 Loss 0.0021 Accuracy 0.3615\n",
      "Epoch 232 Loss 0.0033 Accuracy 0.3615\n",
      "Time taken for 1 epoch: 14.849681377410889 secs\n",
      "\n",
      "Epoch 233 Batch 0 Loss 0.0046 Accuracy 0.3861\n",
      "Epoch 233 Loss 0.0038 Accuracy 0.3579\n",
      "Time taken for 1 epoch: 14.84360146522522 secs\n",
      "\n",
      "Epoch 234 Batch 0 Loss 0.0009 Accuracy 0.2776\n",
      "Epoch 234 Loss 0.0035 Accuracy 0.3548\n",
      "Time taken for 1 epoch: 15.128793239593506 secs\n",
      "\n",
      "Epoch 235 Batch 0 Loss 0.0016 Accuracy 0.3210\n",
      "Saving checkpoint for epoch 235 at ./checkpoints/train/ckpt-51\n",
      "Epoch 235 Loss 0.0029 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 15.473176717758179 secs\n",
      "\n",
      "Epoch 236 Batch 0 Loss 0.0011 Accuracy 0.3185\n",
      "Epoch 236 Loss 0.0024 Accuracy 0.3517\n",
      "Time taken for 1 epoch: 15.024575233459473 secs\n",
      "\n",
      "Epoch 237 Batch 0 Loss 0.0008 Accuracy 0.3359\n",
      "Epoch 237 Loss 0.0033 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 14.79829716682434 secs\n",
      "\n",
      "Epoch 238 Batch 0 Loss 0.0026 Accuracy 0.4134\n",
      "Epoch 238 Loss 0.0041 Accuracy 0.3523\n",
      "Time taken for 1 epoch: 15.073871850967407 secs\n",
      "\n",
      "Epoch 239 Batch 0 Loss 0.0076 Accuracy 0.3537\n",
      "Epoch 239 Loss 0.0046 Accuracy 0.3603\n",
      "Time taken for 1 epoch: 14.801096439361572 secs\n",
      "\n",
      "Epoch 240 Batch 0 Loss 0.0036 Accuracy 0.3133\n",
      "Saving checkpoint for epoch 240 at ./checkpoints/train/ckpt-52\n",
      "Epoch 240 Loss 0.0048 Accuracy 0.3555\n",
      "Time taken for 1 epoch: 15.255244731903076 secs\n",
      "\n",
      "Epoch 241 Batch 0 Loss 0.0051 Accuracy 0.3469\n",
      "Epoch 241 Loss 0.0053 Accuracy 0.3568\n",
      "Time taken for 1 epoch: 14.817236185073853 secs\n",
      "\n",
      "Epoch 242 Batch 0 Loss 0.0085 Accuracy 0.3446\n",
      "Epoch 242 Loss 0.0037 Accuracy 0.3579\n",
      "Time taken for 1 epoch: 14.910772323608398 secs\n",
      "\n",
      "Epoch 243 Batch 0 Loss 0.0049 Accuracy 0.3511\n",
      "Epoch 243 Loss 0.0031 Accuracy 0.3551\n",
      "Time taken for 1 epoch: 14.902299880981445 secs\n",
      "\n",
      "Epoch 244 Batch 0 Loss 0.0011 Accuracy 0.3355\n",
      "Epoch 244 Loss 0.0024 Accuracy 0.3552\n",
      "Time taken for 1 epoch: 15.209827899932861 secs\n",
      "\n",
      "Epoch 245 Batch 0 Loss 0.0005 Accuracy 0.3871\n",
      "Saving checkpoint for epoch 245 at ./checkpoints/train/ckpt-53\n",
      "Epoch 245 Loss 0.0037 Accuracy 0.3602\n",
      "Time taken for 1 epoch: 15.198061466217041 secs\n",
      "\n",
      "Epoch 246 Batch 0 Loss 0.0026 Accuracy 0.3770\n",
      "Epoch 246 Loss 0.0035 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 14.773189067840576 secs\n",
      "\n",
      "Epoch 247 Batch 0 Loss 0.0003 Accuracy 0.3628\n",
      "Epoch 247 Loss 0.0043 Accuracy 0.3571\n",
      "Time taken for 1 epoch: 15.791085004806519 secs\n",
      "\n",
      "Epoch 248 Batch 0 Loss 0.0038 Accuracy 0.3345\n",
      "Epoch 248 Loss 0.0041 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 15.043823957443237 secs\n",
      "\n",
      "Epoch 249 Batch 0 Loss 0.0007 Accuracy 0.3138\n",
      "Epoch 249 Loss 0.0039 Accuracy 0.3542\n",
      "Time taken for 1 epoch: 15.012303829193115 secs\n",
      "\n",
      "Epoch 250 Batch 0 Loss 0.0016 Accuracy 0.3487\n",
      "Saving checkpoint for epoch 250 at ./checkpoints/train/ckpt-54\n",
      "Epoch 250 Loss 0.0046 Accuracy 0.3556\n",
      "Time taken for 1 epoch: 15.3668372631073 secs\n",
      "\n",
      "Epoch 251 Batch 0 Loss 0.0008 Accuracy 0.4068\n",
      "Epoch 251 Loss 0.0042 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 14.920747518539429 secs\n",
      "\n",
      "Epoch 252 Batch 0 Loss 0.0095 Accuracy 0.3212\n",
      "Epoch 252 Loss 0.0031 Accuracy 0.3560\n",
      "Time taken for 1 epoch: 15.00436544418335 secs\n",
      "\n",
      "Epoch 253 Batch 0 Loss 0.0002 Accuracy 0.2914\n",
      "Epoch 253 Loss 0.0026 Accuracy 0.3609\n",
      "Time taken for 1 epoch: 14.814992904663086 secs\n",
      "\n",
      "Epoch 254 Batch 0 Loss 0.0013 Accuracy 0.3606\n",
      "Epoch 254 Loss 0.0027 Accuracy 0.3593\n",
      "Time taken for 1 epoch: 14.659377336502075 secs\n",
      "\n",
      "Epoch 255 Batch 0 Loss 0.0005 Accuracy 0.3203\n",
      "Saving checkpoint for epoch 255 at ./checkpoints/train/ckpt-55\n",
      "Epoch 255 Loss 0.0027 Accuracy 0.3572\n",
      "Time taken for 1 epoch: 15.497357845306396 secs\n",
      "\n",
      "Epoch 256 Batch 0 Loss 0.0004 Accuracy 0.3520\n",
      "Epoch 256 Loss 0.0028 Accuracy 0.3578\n",
      "Time taken for 1 epoch: 14.755987167358398 secs\n",
      "\n",
      "Epoch 257 Batch 0 Loss 0.0010 Accuracy 0.4282\n",
      "Epoch 257 Loss 0.0023 Accuracy 0.3579\n",
      "Time taken for 1 epoch: 14.99101209640503 secs\n",
      "\n",
      "Epoch 258 Batch 0 Loss 0.0033 Accuracy 0.4088\n",
      "Epoch 258 Loss 0.0021 Accuracy 0.3607\n",
      "Time taken for 1 epoch: 14.62481689453125 secs\n",
      "\n",
      "Epoch 259 Batch 0 Loss 0.0024 Accuracy 0.3624\n",
      "Epoch 259 Loss 0.0036 Accuracy 0.3631\n",
      "Time taken for 1 epoch: 14.673202514648438 secs\n",
      "\n",
      "Epoch 260 Batch 0 Loss 0.0006 Accuracy 0.4229\n",
      "Saving checkpoint for epoch 260 at ./checkpoints/train/ckpt-56\n",
      "Epoch 260 Loss 0.0040 Accuracy 0.3545\n",
      "Time taken for 1 epoch: 15.253720998764038 secs\n",
      "\n",
      "Epoch 261 Batch 0 Loss 0.0013 Accuracy 0.3843\n",
      "Epoch 261 Loss 0.0025 Accuracy 0.3609\n",
      "Time taken for 1 epoch: 14.698498010635376 secs\n",
      "\n",
      "Epoch 262 Batch 0 Loss 0.0009 Accuracy 0.3542\n",
      "Epoch 262 Loss 0.0027 Accuracy 0.3560\n",
      "Time taken for 1 epoch: 14.89127516746521 secs\n",
      "\n",
      "Epoch 263 Batch 0 Loss 0.0010 Accuracy 0.3032\n",
      "Epoch 263 Loss 0.0020 Accuracy 0.3595\n",
      "Time taken for 1 epoch: 14.640817880630493 secs\n",
      "\n",
      "Epoch 264 Batch 0 Loss 0.0002 Accuracy 0.3755\n",
      "Epoch 264 Loss 0.0018 Accuracy 0.3592\n",
      "Time taken for 1 epoch: 17.02394461631775 secs\n",
      "\n",
      "Epoch 265 Batch 0 Loss 0.0030 Accuracy 0.2837\n",
      "Saving checkpoint for epoch 265 at ./checkpoints/train/ckpt-57\n",
      "Epoch 265 Loss 0.0034 Accuracy 0.3535\n",
      "Time taken for 1 epoch: 15.489480018615723 secs\n",
      "\n",
      "Epoch 266 Batch 0 Loss 0.0004 Accuracy 0.3828\n",
      "Epoch 266 Loss 0.0039 Accuracy 0.3620\n",
      "Time taken for 1 epoch: 14.866361141204834 secs\n",
      "\n",
      "Epoch 267 Batch 0 Loss 0.0009 Accuracy 0.4046\n",
      "Epoch 267 Loss 0.0029 Accuracy 0.3562\n",
      "Time taken for 1 epoch: 14.747990131378174 secs\n",
      "\n",
      "Epoch 268 Batch 0 Loss 0.0015 Accuracy 0.3104\n",
      "Epoch 268 Loss 0.0030 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 14.979432106018066 secs\n",
      "\n",
      "Epoch 269 Batch 0 Loss 0.0103 Accuracy 0.3503\n",
      "Epoch 269 Loss 0.0026 Accuracy 0.3640\n",
      "Time taken for 1 epoch: 14.482071876525879 secs\n",
      "\n",
      "Epoch 270 Batch 0 Loss 0.0010 Accuracy 0.3340\n",
      "Saving checkpoint for epoch 270 at ./checkpoints/train/ckpt-58\n",
      "Epoch 270 Loss 0.0031 Accuracy 0.3588\n",
      "Time taken for 1 epoch: 15.272892951965332 secs\n",
      "\n",
      "Epoch 271 Batch 0 Loss 0.0016 Accuracy 0.2965\n",
      "Epoch 271 Loss 0.0038 Accuracy 0.3575\n",
      "Time taken for 1 epoch: 14.81814980506897 secs\n",
      "\n",
      "Epoch 272 Batch 0 Loss 0.0020 Accuracy 0.3769\n",
      "Epoch 272 Loss 0.0027 Accuracy 0.3561\n",
      "Time taken for 1 epoch: 14.668235540390015 secs\n",
      "\n",
      "Epoch 273 Batch 0 Loss 0.0003 Accuracy 0.3367\n",
      "Epoch 273 Loss 0.0030 Accuracy 0.3612\n",
      "Time taken for 1 epoch: 15.518090724945068 secs\n",
      "\n",
      "Epoch 274 Batch 0 Loss 0.0013 Accuracy 0.3800\n",
      "Epoch 274 Loss 0.0017 Accuracy 0.3598\n",
      "Time taken for 1 epoch: 14.851980447769165 secs\n",
      "\n",
      "Epoch 275 Batch 0 Loss 0.0049 Accuracy 0.4111\n",
      "Saving checkpoint for epoch 275 at ./checkpoints/train/ckpt-59\n",
      "Epoch 275 Loss 0.0027 Accuracy 0.3591\n",
      "Time taken for 1 epoch: 15.077625751495361 secs\n",
      "\n",
      "Epoch 276 Batch 0 Loss 0.0002 Accuracy 0.3464\n",
      "Epoch 276 Loss 0.0030 Accuracy 0.3585\n",
      "Time taken for 1 epoch: 15.003475904464722 secs\n",
      "\n",
      "Epoch 277 Batch 0 Loss 0.0008 Accuracy 0.3730\n",
      "Epoch 277 Loss 0.0027 Accuracy 0.3605\n",
      "Time taken for 1 epoch: 14.856742858886719 secs\n",
      "\n",
      "Epoch 278 Batch 0 Loss 0.0024 Accuracy 0.3618\n",
      "Epoch 278 Loss 0.0027 Accuracy 0.3544\n",
      "Time taken for 1 epoch: 14.750571489334106 secs\n",
      "\n",
      "Epoch 279 Batch 0 Loss 0.0078 Accuracy 0.3712\n",
      "Epoch 279 Loss 0.0029 Accuracy 0.3521\n",
      "Time taken for 1 epoch: 15.15680718421936 secs\n",
      "\n",
      "Epoch 280 Batch 0 Loss 0.0050 Accuracy 0.3618\n",
      "Saving checkpoint for epoch 280 at ./checkpoints/train/ckpt-60\n",
      "Epoch 280 Loss 0.0033 Accuracy 0.3530\n",
      "Time taken for 1 epoch: 15.405641317367554 secs\n",
      "\n",
      "Epoch 281 Batch 0 Loss 0.0019 Accuracy 0.3901\n",
      "Epoch 281 Loss 0.0030 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 14.782995700836182 secs\n",
      "\n",
      "Epoch 282 Batch 0 Loss 0.0028 Accuracy 0.3249\n",
      "Epoch 282 Loss 0.0021 Accuracy 0.3598\n",
      "Time taken for 1 epoch: 14.893460512161255 secs\n",
      "\n",
      "Epoch 283 Batch 0 Loss 0.0021 Accuracy 0.3722\n",
      "Epoch 283 Loss 0.0027 Accuracy 0.3593\n",
      "Time taken for 1 epoch: 14.799661636352539 secs\n",
      "\n",
      "Epoch 284 Batch 0 Loss 0.0009 Accuracy 0.3226\n",
      "Epoch 284 Loss 0.0030 Accuracy 0.3538\n",
      "Time taken for 1 epoch: 15.129794359207153 secs\n",
      "\n",
      "Epoch 285 Batch 0 Loss 0.0033 Accuracy 0.3045\n",
      "Saving checkpoint for epoch 285 at ./checkpoints/train/ckpt-61\n",
      "Epoch 285 Loss 0.0029 Accuracy 0.3556\n",
      "Time taken for 1 epoch: 15.6913321018219 secs\n",
      "\n",
      "Epoch 286 Batch 0 Loss 0.0004 Accuracy 0.3862\n",
      "Epoch 286 Loss 0.0029 Accuracy 0.3611\n",
      "Time taken for 1 epoch: 14.64493465423584 secs\n",
      "\n",
      "Epoch 287 Batch 0 Loss 0.0018 Accuracy 0.3497\n",
      "Epoch 287 Loss 0.0034 Accuracy 0.3554\n",
      "Time taken for 1 epoch: 15.153418779373169 secs\n",
      "\n",
      "Epoch 288 Batch 0 Loss 0.0033 Accuracy 0.3550\n",
      "Epoch 288 Loss 0.0023 Accuracy 0.3581\n",
      "Time taken for 1 epoch: 14.794797897338867 secs\n",
      "\n",
      "Epoch 289 Batch 0 Loss 0.0006 Accuracy 0.3823\n",
      "Epoch 289 Loss 0.0038 Accuracy 0.3632\n",
      "Time taken for 1 epoch: 14.907212018966675 secs\n",
      "\n",
      "Epoch 290 Batch 0 Loss 0.0008 Accuracy 0.3885\n",
      "Saving checkpoint for epoch 290 at ./checkpoints/train/ckpt-62\n",
      "Epoch 290 Loss 0.0026 Accuracy 0.3467\n",
      "Time taken for 1 epoch: 15.715514183044434 secs\n",
      "\n",
      "Epoch 291 Batch 0 Loss 0.0008 Accuracy 0.3858\n",
      "Epoch 291 Loss 0.0026 Accuracy 0.3600\n",
      "Time taken for 1 epoch: 14.846330881118774 secs\n",
      "\n",
      "Epoch 292 Batch 0 Loss 0.0005 Accuracy 0.3177\n",
      "Epoch 292 Loss 0.0036 Accuracy 0.3580\n",
      "Time taken for 1 epoch: 14.634937047958374 secs\n",
      "\n",
      "Epoch 293 Batch 0 Loss 0.0009 Accuracy 0.3989\n",
      "Epoch 293 Loss 0.0034 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 14.934346914291382 secs\n",
      "\n",
      "Epoch 294 Batch 0 Loss 0.0044 Accuracy 0.3851\n",
      "Epoch 294 Loss 0.0034 Accuracy 0.3610\n",
      "Time taken for 1 epoch: 14.459070920944214 secs\n",
      "\n",
      "Epoch 295 Batch 0 Loss 0.0013 Accuracy 0.3416\n",
      "Saving checkpoint for epoch 295 at ./checkpoints/train/ckpt-63\n",
      "Epoch 295 Loss 0.0021 Accuracy 0.3500\n",
      "Time taken for 1 epoch: 15.857574939727783 secs\n",
      "\n",
      "Epoch 296 Batch 0 Loss 0.0021 Accuracy 0.3129\n",
      "Epoch 296 Loss 0.0021 Accuracy 0.3545\n",
      "Time taken for 1 epoch: 14.829738140106201 secs\n",
      "\n",
      "Epoch 297 Batch 0 Loss 0.0011 Accuracy 0.3402\n",
      "Epoch 297 Loss 0.0033 Accuracy 0.3604\n",
      "Time taken for 1 epoch: 14.898952722549438 secs\n",
      "\n",
      "Epoch 298 Batch 0 Loss 0.0070 Accuracy 0.3795\n",
      "Epoch 298 Loss 0.0025 Accuracy 0.3512\n",
      "Time taken for 1 epoch: 15.066172361373901 secs\n",
      "\n",
      "Epoch 299 Batch 0 Loss 0.0010 Accuracy 0.4346\n",
      "Epoch 299 Loss 0.0024 Accuracy 0.3585\n",
      "Time taken for 1 epoch: 14.935829639434814 secs\n",
      "\n",
      "Epoch 300 Batch 0 Loss 0.0081 Accuracy 0.3421\n",
      "Saving checkpoint for epoch 300 at ./checkpoints/train/ckpt-64\n",
      "Epoch 300 Loss 0.0023 Accuracy 0.3636\n",
      "Time taken for 1 epoch: 15.029683589935303 secs\n",
      "\n",
      "Epoch 301 Batch 0 Loss 0.0005 Accuracy 0.3863\n",
      "Epoch 301 Loss 0.0021 Accuracy 0.3601\n",
      "Time taken for 1 epoch: 14.706042766571045 secs\n",
      "\n",
      "Epoch 302 Batch 0 Loss 0.0016 Accuracy 0.3138\n",
      "Epoch 302 Loss 0.0036 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 14.989458084106445 secs\n",
      "\n",
      "Epoch 303 Batch 0 Loss 0.0030 Accuracy 0.3594\n",
      "Epoch 303 Loss 0.0026 Accuracy 0.3570\n",
      "Time taken for 1 epoch: 14.585600852966309 secs\n",
      "\n",
      "Epoch 304 Batch 0 Loss 0.0117 Accuracy 0.4133\n",
      "Epoch 304 Loss 0.0033 Accuracy 0.3552\n",
      "Time taken for 1 epoch: 15.905319452285767 secs\n",
      "\n",
      "Epoch 305 Batch 0 Loss 0.0042 Accuracy 0.3221\n",
      "Saving checkpoint for epoch 305 at ./checkpoints/train/ckpt-65\n",
      "Epoch 305 Loss 0.0020 Accuracy 0.3608\n",
      "Time taken for 1 epoch: 15.148743629455566 secs\n",
      "\n",
      "Epoch 306 Batch 0 Loss 0.0014 Accuracy 0.4271\n",
      "Epoch 306 Loss 0.0030 Accuracy 0.3603\n",
      "Time taken for 1 epoch: 15.07987117767334 secs\n",
      "\n",
      "Epoch 307 Batch 0 Loss 0.0004 Accuracy 0.3740\n",
      "Epoch 307 Loss 0.0021 Accuracy 0.3592\n",
      "Time taken for 1 epoch: 15.049927473068237 secs\n",
      "\n",
      "Epoch 308 Batch 0 Loss 0.0007 Accuracy 0.4456\n",
      "Epoch 308 Loss 0.0019 Accuracy 0.3543\n",
      "Time taken for 1 epoch: 14.88656234741211 secs\n",
      "\n",
      "Epoch 309 Batch 0 Loss 0.0002 Accuracy 0.3442\n",
      "Epoch 309 Loss 0.0023 Accuracy 0.3596\n",
      "Time taken for 1 epoch: 14.814327239990234 secs\n",
      "\n",
      "Epoch 310 Batch 0 Loss 0.0040 Accuracy 0.3996\n",
      "Saving checkpoint for epoch 310 at ./checkpoints/train/ckpt-66\n",
      "Epoch 310 Loss 0.0032 Accuracy 0.3578\n",
      "Time taken for 1 epoch: 15.385955333709717 secs\n",
      "\n",
      "Epoch 311 Batch 0 Loss 0.0035 Accuracy 0.3788\n",
      "Epoch 311 Loss 0.0025 Accuracy 0.3648\n",
      "Time taken for 1 epoch: 14.381160974502563 secs\n",
      "\n",
      "Epoch 312 Batch 0 Loss 0.0011 Accuracy 0.3750\n",
      "Epoch 312 Loss 0.0022 Accuracy 0.3618\n",
      "Time taken for 1 epoch: 15.098935842514038 secs\n",
      "\n",
      "Epoch 313 Batch 0 Loss 0.0014 Accuracy 0.4353\n",
      "Epoch 313 Loss 0.0022 Accuracy 0.3561\n",
      "Time taken for 1 epoch: 15.020952701568604 secs\n",
      "\n",
      "Epoch 314 Batch 0 Loss 0.0013 Accuracy 0.3477\n",
      "Epoch 314 Loss 0.0017 Accuracy 0.3585\n",
      "Time taken for 1 epoch: 14.814387083053589 secs\n",
      "\n",
      "Epoch 315 Batch 0 Loss 0.0019 Accuracy 0.3421\n",
      "Saving checkpoint for epoch 315 at ./checkpoints/train/ckpt-67\n",
      "Epoch 315 Loss 0.0026 Accuracy 0.3585\n",
      "Time taken for 1 epoch: 15.515130996704102 secs\n",
      "\n",
      "Epoch 316 Batch 0 Loss 0.0022 Accuracy 0.4079\n",
      "Epoch 316 Loss 0.0051 Accuracy 0.3602\n",
      "Time taken for 1 epoch: 14.812639236450195 secs\n",
      "\n",
      "Epoch 317 Batch 0 Loss 0.0010 Accuracy 0.3788\n",
      "Epoch 317 Loss 0.0020 Accuracy 0.3579\n",
      "Time taken for 1 epoch: 14.781768798828125 secs\n",
      "\n",
      "Epoch 318 Batch 0 Loss 0.0004 Accuracy 0.4041\n",
      "Epoch 318 Loss 0.0018 Accuracy 0.3577\n",
      "Time taken for 1 epoch: 14.893955945968628 secs\n",
      "\n",
      "Epoch 319 Batch 0 Loss 0.0012 Accuracy 0.3326\n",
      "Epoch 319 Loss 0.0019 Accuracy 0.3526\n",
      "Time taken for 1 epoch: 15.078439950942993 secs\n",
      "\n",
      "Epoch 320 Batch 0 Loss 0.0004 Accuracy 0.3529\n",
      "Saving checkpoint for epoch 320 at ./checkpoints/train/ckpt-68\n",
      "Epoch 320 Loss 0.0020 Accuracy 0.3614\n",
      "Time taken for 1 epoch: 15.178853988647461 secs\n",
      "\n",
      "Epoch 321 Batch 0 Loss 0.0006 Accuracy 0.3312\n",
      "Epoch 321 Loss 0.0022 Accuracy 0.3637\n",
      "Time taken for 1 epoch: 14.522084474563599 secs\n",
      "\n",
      "Epoch 322 Batch 0 Loss 0.0011 Accuracy 0.3681\n",
      "Epoch 322 Loss 0.0026 Accuracy 0.3580\n",
      "Time taken for 1 epoch: 15.198143482208252 secs\n",
      "\n",
      "Epoch 323 Batch 0 Loss 0.0033 Accuracy 0.3112\n",
      "Epoch 323 Loss 0.0032 Accuracy 0.3603\n",
      "Time taken for 1 epoch: 14.655791759490967 secs\n",
      "\n",
      "Epoch 324 Batch 0 Loss 0.0003 Accuracy 0.3379\n",
      "Epoch 324 Loss 0.0030 Accuracy 0.3588\n",
      "Time taken for 1 epoch: 15.230799436569214 secs\n",
      "\n",
      "Epoch 325 Batch 0 Loss 0.0009 Accuracy 0.3585\n",
      "Saving checkpoint for epoch 325 at ./checkpoints/train/ckpt-69\n",
      "Epoch 325 Loss 0.0024 Accuracy 0.3631\n",
      "Time taken for 1 epoch: 15.174470901489258 secs\n",
      "\n",
      "Epoch 326 Batch 0 Loss 0.0007 Accuracy 0.2998\n",
      "Epoch 326 Loss 0.0026 Accuracy 0.3473\n",
      "Time taken for 1 epoch: 15.62014389038086 secs\n",
      "\n",
      "Epoch 327 Batch 0 Loss 0.0006 Accuracy 0.4468\n",
      "Epoch 327 Loss 0.0019 Accuracy 0.3572\n",
      "Time taken for 1 epoch: 15.130528450012207 secs\n",
      "\n",
      "Epoch 328 Batch 0 Loss 0.0005 Accuracy 0.4230\n",
      "Epoch 328 Loss 0.0032 Accuracy 0.3575\n",
      "Time taken for 1 epoch: 14.745294094085693 secs\n",
      "\n",
      "Epoch 329 Batch 0 Loss 0.0005 Accuracy 0.3678\n",
      "Epoch 329 Loss 0.0019 Accuracy 0.3523\n",
      "Time taken for 1 epoch: 15.135415315628052 secs\n",
      "\n",
      "Epoch 330 Batch 0 Loss 0.0030 Accuracy 0.3129\n",
      "Saving checkpoint for epoch 330 at ./checkpoints/train/ckpt-70\n",
      "Epoch 330 Loss 0.0018 Accuracy 0.3579\n",
      "Time taken for 1 epoch: 15.153731346130371 secs\n",
      "\n",
      "Epoch 331 Batch 0 Loss 0.0020 Accuracy 0.3213\n",
      "Epoch 331 Loss 0.0025 Accuracy 0.3561\n",
      "Time taken for 1 epoch: 14.985092878341675 secs\n",
      "\n",
      "Epoch 332 Batch 0 Loss 0.0009 Accuracy 0.3464\n",
      "Epoch 332 Loss 0.0027 Accuracy 0.3565\n",
      "Time taken for 1 epoch: 14.733393669128418 secs\n",
      "\n",
      "Epoch 333 Batch 0 Loss 0.0053 Accuracy 0.4170\n",
      "Epoch 333 Loss 0.0018 Accuracy 0.3546\n",
      "Time taken for 1 epoch: 15.212133884429932 secs\n",
      "\n",
      "Epoch 334 Batch 0 Loss 0.0007 Accuracy 0.4172\n",
      "Epoch 334 Loss 0.0023 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 14.693609476089478 secs\n",
      "\n",
      "Epoch 335 Batch 0 Loss 0.0021 Accuracy 0.3067\n",
      "Saving checkpoint for epoch 335 at ./checkpoints/train/ckpt-71\n",
      "Epoch 335 Loss 0.0019 Accuracy 0.3611\n",
      "Time taken for 1 epoch: 15.320700883865356 secs\n",
      "\n",
      "Epoch 336 Batch 0 Loss 0.0050 Accuracy 0.3305\n",
      "Epoch 336 Loss 0.0030 Accuracy 0.3576\n",
      "Time taken for 1 epoch: 14.603909015655518 secs\n",
      "\n",
      "Epoch 337 Batch 0 Loss 0.0020 Accuracy 0.4009\n",
      "Epoch 337 Loss 0.0023 Accuracy 0.3549\n",
      "Time taken for 1 epoch: 15.181906461715698 secs\n",
      "\n",
      "Epoch 338 Batch 0 Loss 0.0005 Accuracy 0.3105\n",
      "Epoch 338 Loss 0.0020 Accuracy 0.3585\n",
      "Time taken for 1 epoch: 14.765983819961548 secs\n",
      "\n",
      "Epoch 339 Batch 0 Loss 0.0005 Accuracy 0.3939\n",
      "Epoch 339 Loss 0.0026 Accuracy 0.3517\n",
      "Time taken for 1 epoch: 15.209681510925293 secs\n",
      "\n",
      "Epoch 340 Batch 0 Loss 0.0030 Accuracy 0.3775\n",
      "Saving checkpoint for epoch 340 at ./checkpoints/train/ckpt-72\n",
      "Epoch 340 Loss 0.0017 Accuracy 0.3531\n",
      "Time taken for 1 epoch: 15.498131275177002 secs\n",
      "\n",
      "Epoch 341 Batch 0 Loss 0.0007 Accuracy 0.4359\n",
      "Epoch 341 Loss 0.0022 Accuracy 0.3611\n",
      "Time taken for 1 epoch: 14.483075857162476 secs\n",
      "\n",
      "Epoch 342 Batch 0 Loss 0.0015 Accuracy 0.3053\n",
      "Epoch 342 Loss 0.0018 Accuracy 0.3557\n",
      "Time taken for 1 epoch: 15.006356716156006 secs\n",
      "\n",
      "Epoch 343 Batch 0 Loss 0.0002 Accuracy 0.3555\n",
      "Epoch 343 Loss 0.0015 Accuracy 0.3523\n",
      "Time taken for 1 epoch: 15.32717251777649 secs\n",
      "\n",
      "Epoch 344 Batch 0 Loss 0.0004 Accuracy 0.3217\n",
      "Epoch 344 Loss 0.0020 Accuracy 0.3511\n",
      "Time taken for 1 epoch: 17.285315990447998 secs\n",
      "\n",
      "Epoch 345 Batch 0 Loss 0.0044 Accuracy 0.3339\n",
      "Saving checkpoint for epoch 345 at ./checkpoints/train/ckpt-73\n",
      "Epoch 345 Loss 0.0024 Accuracy 0.3634\n",
      "Time taken for 1 epoch: 15.191641807556152 secs\n",
      "\n",
      "Epoch 346 Batch 0 Loss 0.0005 Accuracy 0.3550\n",
      "Epoch 346 Loss 0.0030 Accuracy 0.3572\n",
      "Time taken for 1 epoch: 15.268927097320557 secs\n",
      "\n",
      "Epoch 347 Batch 0 Loss 0.0028 Accuracy 0.3459\n",
      "Epoch 347 Loss 0.0023 Accuracy 0.3618\n",
      "Time taken for 1 epoch: 15.067626237869263 secs\n",
      "\n",
      "Epoch 348 Batch 0 Loss 0.0021 Accuracy 0.3494\n",
      "Epoch 348 Loss 0.0020 Accuracy 0.3592\n",
      "Time taken for 1 epoch: 14.91403317451477 secs\n",
      "\n",
      "Epoch 349 Batch 0 Loss 0.0025 Accuracy 0.3231\n",
      "Epoch 349 Loss 0.0023 Accuracy 0.3637\n",
      "Time taken for 1 epoch: 14.683290481567383 secs\n",
      "\n",
      "Epoch 350 Batch 0 Loss 0.0070 Accuracy 0.3173\n",
      "Saving checkpoint for epoch 350 at ./checkpoints/train/ckpt-74\n",
      "Epoch 350 Loss 0.0024 Accuracy 0.3599\n",
      "Time taken for 1 epoch: 15.337997436523438 secs\n",
      "\n",
      "Epoch 351 Batch 0 Loss 0.0002 Accuracy 0.3786\n",
      "Epoch 351 Loss 0.0016 Accuracy 0.3591\n",
      "Time taken for 1 epoch: 14.983429908752441 secs\n",
      "\n",
      "Epoch 352 Batch 0 Loss 0.0004 Accuracy 0.3416\n",
      "Epoch 352 Loss 0.0015 Accuracy 0.3587\n",
      "Time taken for 1 epoch: 14.824740886688232 secs\n",
      "\n",
      "Epoch 353 Batch 0 Loss 0.0013 Accuracy 0.3490\n",
      "Epoch 353 Loss 0.0022 Accuracy 0.3578\n",
      "Time taken for 1 epoch: 15.078735589981079 secs\n",
      "\n",
      "Epoch 354 Batch 0 Loss 0.0010 Accuracy 0.3571\n",
      "Epoch 354 Loss 0.0019 Accuracy 0.3607\n",
      "Time taken for 1 epoch: 14.799215078353882 secs\n",
      "\n",
      "Epoch 355 Batch 0 Loss 0.0027 Accuracy 0.3818\n",
      "Saving checkpoint for epoch 355 at ./checkpoints/train/ckpt-75\n",
      "Epoch 355 Loss 0.0021 Accuracy 0.3552\n",
      "Time taken for 1 epoch: 15.692594528198242 secs\n",
      "\n",
      "Epoch 356 Batch 0 Loss 0.0003 Accuracy 0.3589\n",
      "Epoch 356 Loss 0.0018 Accuracy 0.3514\n",
      "Time taken for 1 epoch: 15.034615755081177 secs\n",
      "\n",
      "Epoch 357 Batch 0 Loss 0.0003 Accuracy 0.3217\n",
      "Epoch 357 Loss 0.0025 Accuracy 0.3571\n",
      "Time taken for 1 epoch: 15.124163627624512 secs\n",
      "\n",
      "Epoch 358 Batch 0 Loss 0.0018 Accuracy 0.3555\n",
      "Epoch 358 Loss 0.0026 Accuracy 0.3580\n",
      "Time taken for 1 epoch: 14.620309352874756 secs\n",
      "\n",
      "Epoch 359 Batch 0 Loss 0.0056 Accuracy 0.4312\n",
      "Epoch 359 Loss 0.0024 Accuracy 0.3610\n",
      "Time taken for 1 epoch: 14.794895648956299 secs\n",
      "\n",
      "Epoch 360 Batch 0 Loss 0.0009 Accuracy 0.2978\n",
      "Saving checkpoint for epoch 360 at ./checkpoints/train/ckpt-76\n",
      "Epoch 360 Loss 0.0033 Accuracy 0.3565\n",
      "Time taken for 1 epoch: 15.045553207397461 secs\n",
      "\n",
      "Epoch 361 Batch 0 Loss 0.0009 Accuracy 0.3286\n",
      "Epoch 361 Loss 0.0025 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 15.162646055221558 secs\n",
      "\n",
      "Epoch 362 Batch 0 Loss 0.0013 Accuracy 0.4025\n",
      "Epoch 362 Loss 0.0018 Accuracy 0.3612\n",
      "Time taken for 1 epoch: 14.674377918243408 secs\n",
      "\n",
      "Epoch 363 Batch 0 Loss 0.0009 Accuracy 0.3917\n",
      "Epoch 363 Loss 0.0015 Accuracy 0.3540\n",
      "Time taken for 1 epoch: 15.146127462387085 secs\n",
      "\n",
      "Epoch 364 Batch 0 Loss 0.0002 Accuracy 0.3237\n",
      "Epoch 364 Loss 0.0022 Accuracy 0.3502\n",
      "Time taken for 1 epoch: 15.010408401489258 secs\n",
      "\n",
      "Epoch 365 Batch 0 Loss 0.0002 Accuracy 0.3232\n",
      "Saving checkpoint for epoch 365 at ./checkpoints/train/ckpt-77\n",
      "Epoch 365 Loss 0.0019 Accuracy 0.3603\n",
      "Time taken for 1 epoch: 15.313594102859497 secs\n",
      "\n",
      "Epoch 366 Batch 0 Loss 0.0017 Accuracy 0.3095\n",
      "Epoch 366 Loss 0.0015 Accuracy 0.3580\n",
      "Time taken for 1 epoch: 14.877581357955933 secs\n",
      "\n",
      "Epoch 367 Batch 0 Loss 0.0158 Accuracy 0.3781\n",
      "Epoch 367 Loss 0.0024 Accuracy 0.3546\n",
      "Time taken for 1 epoch: 15.008924007415771 secs\n",
      "\n",
      "Epoch 368 Batch 0 Loss 0.0008 Accuracy 0.3906\n",
      "Epoch 368 Loss 0.0015 Accuracy 0.3524\n",
      "Time taken for 1 epoch: 15.123979091644287 secs\n",
      "\n",
      "Epoch 369 Batch 0 Loss 0.0024 Accuracy 0.4208\n",
      "Epoch 369 Loss 0.0021 Accuracy 0.3624\n",
      "Time taken for 1 epoch: 14.60218858718872 secs\n",
      "\n",
      "Epoch 370 Batch 0 Loss 0.0007 Accuracy 0.3562\n",
      "Saving checkpoint for epoch 370 at ./checkpoints/train/ckpt-78\n",
      "Epoch 370 Loss 0.0017 Accuracy 0.3577\n",
      "Time taken for 1 epoch: 15.50954818725586 secs\n",
      "\n",
      "Epoch 371 Batch 0 Loss 0.0002 Accuracy 0.3560\n",
      "Epoch 371 Loss 0.0012 Accuracy 0.3550\n",
      "Time taken for 1 epoch: 15.01833438873291 secs\n",
      "\n",
      "Epoch 372 Batch 0 Loss 0.0003 Accuracy 0.4014\n",
      "Epoch 372 Loss 0.0015 Accuracy 0.3670\n",
      "Time taken for 1 epoch: 14.36464262008667 secs\n",
      "\n",
      "Epoch 373 Batch 0 Loss 0.0007 Accuracy 0.3319\n",
      "Epoch 373 Loss 0.0022 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 14.940736055374146 secs\n",
      "\n",
      "Epoch 374 Batch 0 Loss 0.0019 Accuracy 0.3268\n",
      "Epoch 374 Loss 0.0024 Accuracy 0.3588\n",
      "Time taken for 1 epoch: 14.577385663986206 secs\n",
      "\n",
      "Epoch 375 Batch 0 Loss 0.0002 Accuracy 0.4256\n",
      "Saving checkpoint for epoch 375 at ./checkpoints/train/ckpt-79\n",
      "Epoch 375 Loss 0.0011 Accuracy 0.3565\n",
      "Time taken for 1 epoch: 15.554165363311768 secs\n",
      "\n",
      "Epoch 376 Batch 0 Loss 0.0010 Accuracy 0.3117\n",
      "Epoch 376 Loss 0.0019 Accuracy 0.3529\n",
      "Time taken for 1 epoch: 15.050142288208008 secs\n",
      "\n",
      "Epoch 377 Batch 0 Loss 0.0009 Accuracy 0.3564\n",
      "Epoch 377 Loss 0.0015 Accuracy 0.3513\n",
      "Time taken for 1 epoch: 15.127493381500244 secs\n",
      "\n",
      "Epoch 378 Batch 0 Loss 0.0043 Accuracy 0.4175\n",
      "Epoch 378 Loss 0.0018 Accuracy 0.3570\n",
      "Time taken for 1 epoch: 15.043610334396362 secs\n",
      "\n",
      "Epoch 379 Batch 0 Loss 0.0002 Accuracy 0.3385\n",
      "Epoch 379 Loss 0.0016 Accuracy 0.3602\n",
      "Time taken for 1 epoch: 14.60987639427185 secs\n",
      "\n",
      "Epoch 380 Batch 0 Loss 0.0007 Accuracy 0.4116\n",
      "Saving checkpoint for epoch 380 at ./checkpoints/train/ckpt-80\n",
      "Epoch 380 Loss 0.0016 Accuracy 0.3621\n",
      "Time taken for 1 epoch: 15.26290249824524 secs\n",
      "\n",
      "Epoch 381 Batch 0 Loss 0.0010 Accuracy 0.3305\n",
      "Epoch 381 Loss 0.0020 Accuracy 0.3600\n",
      "Time taken for 1 epoch: 14.749948501586914 secs\n",
      "\n",
      "Epoch 382 Batch 0 Loss 0.0009 Accuracy 0.4027\n",
      "Epoch 382 Loss 0.0024 Accuracy 0.3648\n",
      "Time taken for 1 epoch: 14.626237392425537 secs\n",
      "\n",
      "Epoch 383 Batch 0 Loss 0.0004 Accuracy 0.3707\n",
      "Epoch 383 Loss 0.0020 Accuracy 0.3522\n",
      "Time taken for 1 epoch: 15.874384880065918 secs\n",
      "\n",
      "Epoch 384 Batch 0 Loss 0.0035 Accuracy 0.3452\n",
      "Epoch 384 Loss 0.0016 Accuracy 0.3567\n",
      "Time taken for 1 epoch: 15.030611276626587 secs\n",
      "\n",
      "Epoch 385 Batch 0 Loss 0.0001 Accuracy 0.3490\n",
      "Saving checkpoint for epoch 385 at ./checkpoints/train/ckpt-81\n",
      "Epoch 385 Loss 0.0015 Accuracy 0.3576\n",
      "Time taken for 1 epoch: 15.39803409576416 secs\n",
      "\n",
      "Epoch 386 Batch 0 Loss 0.0001 Accuracy 0.3811\n",
      "Epoch 386 Loss 0.0010 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 15.216105461120605 secs\n",
      "\n",
      "Epoch 387 Batch 0 Loss 0.0002 Accuracy 0.3387\n",
      "Epoch 387 Loss 0.0018 Accuracy 0.3574\n",
      "Time taken for 1 epoch: 14.947345733642578 secs\n",
      "\n",
      "Epoch 388 Batch 0 Loss 0.0031 Accuracy 0.3150\n",
      "Epoch 388 Loss 0.0016 Accuracy 0.3631\n",
      "Time taken for 1 epoch: 14.58216118812561 secs\n",
      "\n",
      "Epoch 389 Batch 0 Loss 0.0024 Accuracy 0.3925\n",
      "Epoch 389 Loss 0.0019 Accuracy 0.3653\n",
      "Time taken for 1 epoch: 14.55218243598938 secs\n",
      "\n",
      "Epoch 390 Batch 0 Loss 0.0034 Accuracy 0.3574\n",
      "Saving checkpoint for epoch 390 at ./checkpoints/train/ckpt-82\n",
      "Epoch 390 Loss 0.0025 Accuracy 0.3535\n",
      "Time taken for 1 epoch: 15.39411473274231 secs\n",
      "\n",
      "Epoch 391 Batch 0 Loss 0.0005 Accuracy 0.3171\n",
      "Epoch 391 Loss 0.0014 Accuracy 0.3491\n",
      "Time taken for 1 epoch: 15.276591777801514 secs\n",
      "\n",
      "Epoch 392 Batch 0 Loss 0.0005 Accuracy 0.3181\n",
      "Epoch 392 Loss 0.0015 Accuracy 0.3602\n",
      "Time taken for 1 epoch: 14.900498151779175 secs\n",
      "\n",
      "Epoch 393 Batch 0 Loss 0.0020 Accuracy 0.3249\n",
      "Epoch 393 Loss 0.0022 Accuracy 0.3612\n",
      "Time taken for 1 epoch: 14.643826961517334 secs\n",
      "\n",
      "Epoch 394 Batch 0 Loss 0.0002 Accuracy 0.3802\n",
      "Epoch 394 Loss 0.0013 Accuracy 0.3490\n",
      "Time taken for 1 epoch: 15.397861003875732 secs\n",
      "\n",
      "Epoch 395 Batch 0 Loss 0.0017 Accuracy 0.2921\n",
      "Saving checkpoint for epoch 395 at ./checkpoints/train/ckpt-83\n",
      "Epoch 395 Loss 0.0026 Accuracy 0.3603\n",
      "Time taken for 1 epoch: 16.556377172470093 secs\n",
      "\n",
      "Epoch 396 Batch 0 Loss 0.0005 Accuracy 0.3290\n",
      "Epoch 396 Loss 0.0016 Accuracy 0.3585\n",
      "Time taken for 1 epoch: 14.776625394821167 secs\n",
      "\n",
      "Epoch 397 Batch 0 Loss 0.0004 Accuracy 0.3305\n",
      "Epoch 397 Loss 0.0011 Accuracy 0.3598\n",
      "Time taken for 1 epoch: 14.812301874160767 secs\n",
      "\n",
      "Epoch 398 Batch 0 Loss 0.0008 Accuracy 0.3759\n",
      "Epoch 398 Loss 0.0016 Accuracy 0.3595\n",
      "Time taken for 1 epoch: 14.681307554244995 secs\n",
      "\n",
      "Epoch 399 Batch 0 Loss 0.0005 Accuracy 0.3366\n",
      "Epoch 399 Loss 0.0024 Accuracy 0.3527\n",
      "Time taken for 1 epoch: 15.001843214035034 secs\n",
      "\n",
      "Epoch 400 Batch 0 Loss 0.0026 Accuracy 0.3273\n",
      "Saving checkpoint for epoch 400 at ./checkpoints/train/ckpt-84\n",
      "Epoch 400 Loss 0.0020 Accuracy 0.3551\n",
      "Time taken for 1 epoch: 15.314971923828125 secs\n",
      "\n",
      "Epoch 401 Batch 0 Loss 0.0016 Accuracy 0.3936\n",
      "Epoch 401 Loss 0.0017 Accuracy 0.3550\n",
      "Time taken for 1 epoch: 14.861978769302368 secs\n",
      "\n",
      "Epoch 402 Batch 0 Loss 0.0004 Accuracy 0.3535\n",
      "Epoch 402 Loss 0.0015 Accuracy 0.3645\n",
      "Time taken for 1 epoch: 14.707355976104736 secs\n",
      "\n",
      "Epoch 403 Batch 0 Loss 0.0001 Accuracy 0.3030\n",
      "Epoch 403 Loss 0.0011 Accuracy 0.3508\n",
      "Time taken for 1 epoch: 15.721766233444214 secs\n",
      "\n",
      "Epoch 404 Batch 0 Loss 0.0003 Accuracy 0.4093\n",
      "Epoch 404 Loss 0.0017 Accuracy 0.3553\n",
      "Time taken for 1 epoch: 16.636224269866943 secs\n",
      "\n",
      "Epoch 405 Batch 0 Loss 0.0020 Accuracy 0.3417\n",
      "Saving checkpoint for epoch 405 at ./checkpoints/train/ckpt-85\n",
      "Epoch 405 Loss 0.0014 Accuracy 0.3565\n",
      "Time taken for 1 epoch: 17.940104961395264 secs\n",
      "\n",
      "Epoch 406 Batch 0 Loss 0.0011 Accuracy 0.3097\n",
      "Epoch 406 Loss 0.0027 Accuracy 0.3601\n",
      "Time taken for 1 epoch: 14.723549365997314 secs\n",
      "\n",
      "Epoch 407 Batch 0 Loss 0.0002 Accuracy 0.3532\n",
      "Epoch 407 Loss 0.0019 Accuracy 0.3555\n",
      "Time taken for 1 epoch: 14.878839492797852 secs\n",
      "\n",
      "Epoch 408 Batch 0 Loss 0.0001 Accuracy 0.4052\n",
      "Epoch 408 Loss 0.0012 Accuracy 0.3528\n",
      "Time taken for 1 epoch: 15.1303071975708 secs\n",
      "\n",
      "Epoch 409 Batch 0 Loss 0.0001 Accuracy 0.3800\n",
      "Epoch 409 Loss 0.0014 Accuracy 0.3586\n",
      "Time taken for 1 epoch: 14.917385816574097 secs\n",
      "\n",
      "Epoch 410 Batch 0 Loss 0.0009 Accuracy 0.2644\n",
      "Saving checkpoint for epoch 410 at ./checkpoints/train/ckpt-86\n",
      "Epoch 410 Loss 0.0016 Accuracy 0.3584\n",
      "Time taken for 1 epoch: 15.159694910049438 secs\n",
      "\n",
      "Epoch 411 Batch 0 Loss 0.0003 Accuracy 0.3513\n",
      "Epoch 411 Loss 0.0015 Accuracy 0.3567\n",
      "Time taken for 1 epoch: 14.985581636428833 secs\n",
      "\n",
      "Epoch 412 Batch 0 Loss 0.0003 Accuracy 0.2977\n",
      "Epoch 412 Loss 0.0011 Accuracy 0.3556\n",
      "Time taken for 1 epoch: 14.997167110443115 secs\n",
      "\n",
      "Epoch 413 Batch 0 Loss 0.0008 Accuracy 0.3310\n",
      "Epoch 413 Loss 0.0020 Accuracy 0.3587\n",
      "Time taken for 1 epoch: 14.971453189849854 secs\n",
      "\n",
      "Epoch 414 Batch 0 Loss 0.0005 Accuracy 0.3220\n",
      "Epoch 414 Loss 0.0015 Accuracy 0.3571\n",
      "Time taken for 1 epoch: 14.851497888565063 secs\n",
      "\n",
      "Epoch 415 Batch 0 Loss 0.0002 Accuracy 0.3109\n",
      "Saving checkpoint for epoch 415 at ./checkpoints/train/ckpt-87\n",
      "Epoch 415 Loss 0.0015 Accuracy 0.3573\n",
      "Time taken for 1 epoch: 15.429468154907227 secs\n",
      "\n",
      "Epoch 416 Batch 0 Loss 0.0002 Accuracy 0.3195\n",
      "Epoch 416 Loss 0.0020 Accuracy 0.3576\n",
      "Time taken for 1 epoch: 16.22245693206787 secs\n",
      "\n",
      "Epoch 417 Batch 0 Loss 0.0014 Accuracy 0.3161\n",
      "Epoch 417 Loss 0.0019 Accuracy 0.3577\n",
      "Time taken for 1 epoch: 14.875691890716553 secs\n",
      "\n",
      "Epoch 418 Batch 0 Loss 0.0004 Accuracy 0.3313\n",
      "Epoch 418 Loss 0.0015 Accuracy 0.3629\n",
      "Time taken for 1 epoch: 14.723077535629272 secs\n",
      "\n",
      "Epoch 419 Batch 0 Loss 0.0002 Accuracy 0.4195\n",
      "Epoch 419 Loss 0.0024 Accuracy 0.3599\n",
      "Time taken for 1 epoch: 14.802960395812988 secs\n",
      "\n",
      "Epoch 420 Batch 0 Loss 0.0011 Accuracy 0.3871\n",
      "Saving checkpoint for epoch 420 at ./checkpoints/train/ckpt-88\n",
      "Epoch 420 Loss 0.0024 Accuracy 0.3531\n",
      "Time taken for 1 epoch: 15.61043643951416 secs\n",
      "\n",
      "Epoch 421 Batch 0 Loss 0.0015 Accuracy 0.2756\n",
      "Epoch 421 Loss 0.0017 Accuracy 0.3537\n",
      "Time taken for 1 epoch: 15.028135299682617 secs\n",
      "\n",
      "Epoch 422 Batch 0 Loss 0.0004 Accuracy 0.3332\n",
      "Epoch 422 Loss 0.0019 Accuracy 0.3557\n",
      "Time taken for 1 epoch: 14.90625786781311 secs\n",
      "\n",
      "Epoch 423 Batch 0 Loss 0.0020 Accuracy 0.4526\n",
      "Epoch 423 Loss 0.0014 Accuracy 0.3546\n",
      "Time taken for 1 epoch: 15.163793325424194 secs\n",
      "\n",
      "Epoch 424 Batch 0 Loss 0.0004 Accuracy 0.3623\n",
      "Epoch 424 Loss 0.0020 Accuracy 0.3578\n",
      "Time taken for 1 epoch: 14.81914496421814 secs\n",
      "\n",
      "Epoch 425 Batch 0 Loss 0.0005 Accuracy 0.3402\n",
      "Saving checkpoint for epoch 425 at ./checkpoints/train/ckpt-89\n",
      "Epoch 425 Loss 0.0011 Accuracy 0.3547\n",
      "Time taken for 1 epoch: 15.668562889099121 secs\n",
      "\n",
      "Epoch 426 Batch 0 Loss 0.0001 Accuracy 0.3324\n",
      "Epoch 426 Loss 0.0013 Accuracy 0.3607\n",
      "Time taken for 1 epoch: 14.678892135620117 secs\n",
      "\n",
      "Epoch 427 Batch 0 Loss 0.0005 Accuracy 0.3450\n",
      "Epoch 427 Loss 0.0014 Accuracy 0.3649\n",
      "Time taken for 1 epoch: 14.65601372718811 secs\n",
      "\n",
      "Epoch 428 Batch 0 Loss 0.0001 Accuracy 0.3264\n",
      "Epoch 428 Loss 0.0020 Accuracy 0.3560\n",
      "Time taken for 1 epoch: 14.680886268615723 secs\n",
      "\n",
      "Epoch 429 Batch 0 Loss 0.0002 Accuracy 0.3951\n",
      "Epoch 429 Loss 0.0013 Accuracy 0.3596\n",
      "Time taken for 1 epoch: 14.77585506439209 secs\n",
      "\n",
      "Epoch 430 Batch 0 Loss 0.0025 Accuracy 0.3807\n",
      "Saving checkpoint for epoch 430 at ./checkpoints/train/ckpt-90\n",
      "Epoch 430 Loss 0.0023 Accuracy 0.3569\n",
      "Time taken for 1 epoch: 15.240757703781128 secs\n",
      "\n",
      "Epoch 431 Batch 0 Loss 0.0010 Accuracy 0.3690\n",
      "Epoch 431 Loss 0.0028 Accuracy 0.3634\n",
      "Time taken for 1 epoch: 14.5892915725708 secs\n",
      "\n",
      "Epoch 432 Batch 0 Loss 0.0027 Accuracy 0.2931\n",
      "Epoch 432 Loss 0.0016 Accuracy 0.3603\n",
      "Time taken for 1 epoch: 14.565340757369995 secs\n",
      "\n",
      "Epoch 433 Batch 0 Loss 0.0003 Accuracy 0.4015\n",
      "Epoch 433 Loss 0.0018 Accuracy 0.3629\n",
      "Time taken for 1 epoch: 14.665069341659546 secs\n",
      "\n",
      "Epoch 434 Batch 0 Loss 0.0029 Accuracy 0.4022\n",
      "Epoch 434 Loss 0.0022 Accuracy 0.3559\n",
      "Time taken for 1 epoch: 15.027175188064575 secs\n",
      "\n",
      "Epoch 435 Batch 0 Loss 0.0007 Accuracy 0.3558\n",
      "Saving checkpoint for epoch 435 at ./checkpoints/train/ckpt-91\n",
      "Epoch 435 Loss 0.0013 Accuracy 0.3539\n",
      "Time taken for 1 epoch: 15.444210052490234 secs\n",
      "\n",
      "Epoch 436 Batch 0 Loss 0.0002 Accuracy 0.3911\n",
      "Epoch 436 Loss 0.0015 Accuracy 0.3544\n",
      "Time taken for 1 epoch: 14.624024868011475 secs\n",
      "\n",
      "Epoch 437 Batch 0 Loss 0.0002 Accuracy 0.3303\n",
      "Epoch 437 Loss 0.0012 Accuracy 0.3616\n",
      "Time taken for 1 epoch: 14.634366750717163 secs\n",
      "\n",
      "Epoch 438 Batch 0 Loss 0.0003 Accuracy 0.3566\n",
      "Epoch 438 Loss 0.0014 Accuracy 0.3558\n",
      "Time taken for 1 epoch: 14.77058219909668 secs\n",
      "\n",
      "Epoch 439 Batch 0 Loss 0.0014 Accuracy 0.3257\n",
      "Epoch 439 Loss 0.0021 Accuracy 0.3546\n",
      "Time taken for 1 epoch: 15.153312683105469 secs\n",
      "\n",
      "Epoch 440 Batch 0 Loss 0.0010 Accuracy 0.3272\n",
      "Saving checkpoint for epoch 440 at ./checkpoints/train/ckpt-92\n",
      "Epoch 440 Loss 0.0033 Accuracy 0.3590\n",
      "Time taken for 1 epoch: 15.068769931793213 secs\n",
      "\n",
      "Epoch 441 Batch 0 Loss 0.0010 Accuracy 0.3085\n",
      "Epoch 441 Loss 0.0015 Accuracy 0.3524\n",
      "Time taken for 1 epoch: 15.040950775146484 secs\n",
      "\n",
      "Epoch 442 Batch 0 Loss 0.0029 Accuracy 0.2953\n",
      "Epoch 442 Loss 0.0012 Accuracy 0.3591\n",
      "Time taken for 1 epoch: 15.010393857955933 secs\n",
      "\n",
      "Epoch 443 Batch 0 Loss 0.0018 Accuracy 0.4056\n",
      "Epoch 443 Loss 0.0015 Accuracy 0.3606\n",
      "Time taken for 1 epoch: 15.725041151046753 secs\n",
      "\n",
      "Epoch 444 Batch 0 Loss 0.0010 Accuracy 0.3525\n",
      "Epoch 444 Loss 0.0020 Accuracy 0.3599\n",
      "Time taken for 1 epoch: 14.701521873474121 secs\n",
      "\n",
      "Epoch 445 Batch 0 Loss 0.0003 Accuracy 0.3142\n",
      "Saving checkpoint for epoch 445 at ./checkpoints/train/ckpt-93\n",
      "Epoch 445 Loss 0.0011 Accuracy 0.3564\n",
      "Time taken for 1 epoch: 16.145145893096924 secs\n",
      "\n",
      "Epoch 446 Batch 0 Loss 0.0021 Accuracy 0.3311\n",
      "Epoch 446 Loss 0.0015 Accuracy 0.3579\n",
      "Time taken for 1 epoch: 15.76716923713684 secs\n",
      "\n",
      "Epoch 447 Batch 0 Loss 0.0009 Accuracy 0.3823\n",
      "Epoch 447 Loss 0.0017 Accuracy 0.3624\n",
      "Time taken for 1 epoch: 14.859896421432495 secs\n",
      "\n",
      "Epoch 448 Batch 0 Loss 0.0004 Accuracy 0.3790\n",
      "Epoch 448 Loss 0.0014 Accuracy 0.3513\n",
      "Time taken for 1 epoch: 15.051613092422485 secs\n",
      "\n",
      "Epoch 449 Batch 0 Loss 0.0009 Accuracy 0.3659\n",
      "Epoch 449 Loss 0.0017 Accuracy 0.3629\n",
      "Time taken for 1 epoch: 14.552297830581665 secs\n",
      "\n",
      "Epoch 450 Batch 0 Loss 0.0045 Accuracy 0.3594\n",
      "Saving checkpoint for epoch 450 at ./checkpoints/train/ckpt-94\n",
      "Epoch 450 Loss 0.0021 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 15.368295669555664 secs\n",
      "\n",
      "Epoch 451 Batch 0 Loss 0.0003 Accuracy 0.3277\n",
      "Epoch 451 Loss 0.0018 Accuracy 0.3589\n",
      "Time taken for 1 epoch: 14.727195978164673 secs\n",
      "\n",
      "Epoch 452 Batch 0 Loss 0.0001 Accuracy 0.4224\n",
      "Epoch 452 Loss 0.0012 Accuracy 0.3557\n",
      "Time taken for 1 epoch: 14.819141864776611 secs\n",
      "\n",
      "Epoch 453 Batch 0 Loss 0.0027 Accuracy 0.3303\n",
      "Epoch 453 Loss 0.0010 Accuracy 0.3546\n",
      "Time taken for 1 epoch: 14.94350004196167 secs\n",
      "\n",
      "Epoch 454 Batch 0 Loss 0.0009 Accuracy 0.4337\n",
      "Epoch 454 Loss 0.0012 Accuracy 0.3600\n",
      "Time taken for 1 epoch: 15.001725435256958 secs\n",
      "\n",
      "Epoch 455 Batch 0 Loss 0.0006 Accuracy 0.3401\n",
      "Saving checkpoint for epoch 455 at ./checkpoints/train/ckpt-95\n",
      "Epoch 455 Loss 0.0017 Accuracy 0.3615\n",
      "Time taken for 1 epoch: 15.155311822891235 secs\n",
      "\n",
      "Epoch 456 Batch 0 Loss 0.0001 Accuracy 0.3556\n",
      "Epoch 456 Loss 0.0014 Accuracy 0.3586\n",
      "Time taken for 1 epoch: 14.702383518218994 secs\n",
      "\n",
      "Epoch 457 Batch 0 Loss 0.0020 Accuracy 0.3201\n",
      "Epoch 457 Loss 0.0009 Accuracy 0.3602\n",
      "Time taken for 1 epoch: 14.89336109161377 secs\n",
      "\n",
      "Epoch 458 Batch 0 Loss 0.0052 Accuracy 0.3247\n",
      "Epoch 458 Loss 0.0020 Accuracy 0.3649\n",
      "Time taken for 1 epoch: 14.750701904296875 secs\n",
      "\n",
      "Epoch 459 Batch 0 Loss 0.0005 Accuracy 0.3537\n",
      "Epoch 459 Loss 0.0030 Accuracy 0.3611\n",
      "Time taken for 1 epoch: 14.76994800567627 secs\n",
      "\n",
      "Epoch 460 Batch 0 Loss 0.0059 Accuracy 0.3268\n",
      "Saving checkpoint for epoch 460 at ./checkpoints/train/ckpt-96\n",
      "Epoch 460 Loss 0.0162 Accuracy 0.3588\n",
      "Time taken for 1 epoch: 15.2806236743927 secs\n",
      "\n",
      "Epoch 461 Batch 0 Loss 0.0004 Accuracy 0.3864\n",
      "Epoch 461 Loss 0.0078 Accuracy 0.3620\n",
      "Time taken for 1 epoch: 14.436627864837646 secs\n",
      "\n",
      "Epoch 462 Batch 0 Loss 0.0002 Accuracy 0.3876\n",
      "Epoch 462 Loss 0.0037 Accuracy 0.3542\n",
      "Time taken for 1 epoch: 14.933571577072144 secs\n",
      "\n",
      "Epoch 463 Batch 0 Loss 0.0002 Accuracy 0.3332\n",
      "Epoch 463 Loss 0.0030 Accuracy 0.3601\n",
      "Time taken for 1 epoch: 14.752331972122192 secs\n",
      "\n",
      "Epoch 464 Batch 0 Loss 0.0003 Accuracy 0.3340\n",
      "Epoch 464 Loss 0.0022 Accuracy 0.3672\n",
      "Time taken for 1 epoch: 14.57852578163147 secs\n",
      "\n",
      "Epoch 465 Batch 0 Loss 0.0012 Accuracy 0.4213\n",
      "Saving checkpoint for epoch 465 at ./checkpoints/train/ckpt-97\n",
      "Epoch 465 Loss 0.0018 Accuracy 0.3589\n",
      "Time taken for 1 epoch: 15.11958360671997 secs\n",
      "\n",
      "Epoch 466 Batch 0 Loss 0.0008 Accuracy 0.4208\n",
      "Epoch 466 Loss 0.0020 Accuracy 0.3643\n",
      "Time taken for 1 epoch: 14.646888494491577 secs\n",
      "\n",
      "Epoch 467 Batch 0 Loss 0.0003 Accuracy 0.3620\n",
      "Epoch 467 Loss 0.0012 Accuracy 0.3618\n",
      "Time taken for 1 epoch: 14.678224086761475 secs\n",
      "\n",
      "Epoch 468 Batch 0 Loss 0.0001 Accuracy 0.3319\n",
      "Epoch 468 Loss 0.0010 Accuracy 0.3575\n",
      "Time taken for 1 epoch: 14.919839143753052 secs\n",
      "\n",
      "Epoch 469 Batch 0 Loss 0.0080 Accuracy 0.3574\n",
      "Epoch 469 Loss 0.0012 Accuracy 0.3593\n",
      "Time taken for 1 epoch: 14.606099367141724 secs\n",
      "\n",
      "Epoch 470 Batch 0 Loss 0.0002 Accuracy 0.3112\n",
      "Saving checkpoint for epoch 470 at ./checkpoints/train/ckpt-98\n",
      "Epoch 470 Loss 0.0007 Accuracy 0.3571\n",
      "Time taken for 1 epoch: 15.318638324737549 secs\n",
      "\n",
      "Epoch 471 Batch 0 Loss 0.0002 Accuracy 0.3618\n",
      "Epoch 471 Loss 0.0009 Accuracy 0.3614\n",
      "Time taken for 1 epoch: 14.589253187179565 secs\n",
      "\n",
      "Epoch 472 Batch 0 Loss 0.0004 Accuracy 0.3088\n",
      "Epoch 472 Loss 0.0018 Accuracy 0.3552\n",
      "Time taken for 1 epoch: 14.710987567901611 secs\n",
      "\n",
      "Epoch 473 Batch 0 Loss 0.0038 Accuracy 0.3013\n",
      "Epoch 473 Loss 0.0022 Accuracy 0.3580\n",
      "Time taken for 1 epoch: 15.021023511886597 secs\n",
      "\n",
      "Epoch 474 Batch 0 Loss 0.0002 Accuracy 0.2863\n",
      "Epoch 474 Loss 0.0015 Accuracy 0.3569\n",
      "Time taken for 1 epoch: 14.916985988616943 secs\n",
      "\n",
      "Epoch 475 Batch 0 Loss 0.0003 Accuracy 0.3438\n",
      "Saving checkpoint for epoch 475 at ./checkpoints/train/ckpt-99\n",
      "Epoch 475 Loss 0.0016 Accuracy 0.3581\n",
      "Time taken for 1 epoch: 15.542928695678711 secs\n",
      "\n",
      "Epoch 476 Batch 0 Loss 0.0005 Accuracy 0.3442\n",
      "Epoch 476 Loss 0.0010 Accuracy 0.3553\n",
      "Time taken for 1 epoch: 14.833649635314941 secs\n",
      "\n",
      "Epoch 477 Batch 0 Loss 0.0055 Accuracy 0.3452\n",
      "Epoch 477 Loss 0.0013 Accuracy 0.3576\n",
      "Time taken for 1 epoch: 14.76345944404602 secs\n",
      "\n",
      "Epoch 478 Batch 0 Loss 0.0002 Accuracy 0.3545\n",
      "Epoch 478 Loss 0.0014 Accuracy 0.3590\n",
      "Time taken for 1 epoch: 15.09196400642395 secs\n",
      "\n",
      "Epoch 479 Batch 0 Loss 0.0013 Accuracy 0.3310\n",
      "Epoch 479 Loss 0.0021 Accuracy 0.3609\n",
      "Time taken for 1 epoch: 14.627061605453491 secs\n",
      "\n",
      "Epoch 480 Batch 0 Loss 0.0001 Accuracy 0.4001\n",
      "Saving checkpoint for epoch 480 at ./checkpoints/train/ckpt-100\n",
      "Epoch 480 Loss 0.0016 Accuracy 0.3507\n",
      "Time taken for 1 epoch: 15.549133062362671 secs\n",
      "\n",
      "Epoch 481 Batch 0 Loss 0.0017 Accuracy 0.3057\n",
      "Epoch 481 Loss 0.0012 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 14.87387752532959 secs\n",
      "\n",
      "Epoch 482 Batch 0 Loss 0.0007 Accuracy 0.3931\n",
      "Epoch 482 Loss 0.0014 Accuracy 0.3601\n",
      "Time taken for 1 epoch: 14.86955714225769 secs\n",
      "\n",
      "Epoch 483 Batch 0 Loss 0.0007 Accuracy 0.3298\n",
      "Epoch 483 Loss 0.0012 Accuracy 0.3557\n",
      "Time taken for 1 epoch: 16.47257399559021 secs\n",
      "\n",
      "Epoch 484 Batch 0 Loss 0.0013 Accuracy 0.3513\n",
      "Epoch 484 Loss 0.0014 Accuracy 0.3574\n",
      "Time taken for 1 epoch: 15.651468992233276 secs\n",
      "\n",
      "Epoch 485 Batch 0 Loss 0.0002 Accuracy 0.3461\n",
      "Saving checkpoint for epoch 485 at ./checkpoints/train/ckpt-101\n",
      "Epoch 485 Loss 0.0011 Accuracy 0.3643\n",
      "Time taken for 1 epoch: 15.193684339523315 secs\n",
      "\n",
      "Epoch 486 Batch 0 Loss 0.0018 Accuracy 0.4183\n",
      "Epoch 486 Loss 0.0013 Accuracy 0.3557\n",
      "Time taken for 1 epoch: 15.016382694244385 secs\n",
      "\n",
      "Epoch 487 Batch 0 Loss 0.0001 Accuracy 0.3193\n",
      "Epoch 487 Loss 0.0016 Accuracy 0.3538\n",
      "Time taken for 1 epoch: 15.07275390625 secs\n",
      "\n",
      "Epoch 488 Batch 0 Loss 0.0001 Accuracy 0.3264\n",
      "Epoch 488 Loss 0.0010 Accuracy 0.3549\n",
      "Time taken for 1 epoch: 14.911443948745728 secs\n",
      "\n",
      "Epoch 489 Batch 0 Loss 0.0002 Accuracy 0.3199\n",
      "Epoch 489 Loss 0.0011 Accuracy 0.3569\n",
      "Time taken for 1 epoch: 14.874646186828613 secs\n",
      "\n",
      "Epoch 490 Batch 0 Loss 0.0017 Accuracy 0.3150\n",
      "Saving checkpoint for epoch 490 at ./checkpoints/train/ckpt-102\n",
      "Epoch 490 Loss 0.0013 Accuracy 0.3664\n",
      "Time taken for 1 epoch: 15.126014709472656 secs\n",
      "\n",
      "Epoch 491 Batch 0 Loss 0.0005 Accuracy 0.4427\n",
      "Epoch 491 Loss 0.0012 Accuracy 0.3564\n",
      "Time taken for 1 epoch: 15.010804653167725 secs\n",
      "\n",
      "Epoch 492 Batch 0 Loss 0.0002 Accuracy 0.3335\n",
      "Epoch 492 Loss 0.0013 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 14.618692874908447 secs\n",
      "\n",
      "Epoch 493 Batch 0 Loss 0.0005 Accuracy 0.3491\n",
      "Epoch 493 Loss 0.0012 Accuracy 0.3632\n",
      "Time taken for 1 epoch: 14.645809412002563 secs\n",
      "\n",
      "Epoch 494 Batch 0 Loss 0.0012 Accuracy 0.4133\n",
      "Epoch 494 Loss 0.0015 Accuracy 0.3557\n",
      "Time taken for 1 epoch: 15.012735366821289 secs\n",
      "\n",
      "Epoch 495 Batch 0 Loss 0.0001 Accuracy 0.3994\n",
      "Saving checkpoint for epoch 495 at ./checkpoints/train/ckpt-103\n",
      "Epoch 495 Loss 0.0013 Accuracy 0.3617\n",
      "Time taken for 1 epoch: 15.055431604385376 secs\n",
      "\n",
      "Epoch 496 Batch 0 Loss 0.0002 Accuracy 0.3556\n",
      "Epoch 496 Loss 0.0007 Accuracy 0.3533\n",
      "Time taken for 1 epoch: 14.951159238815308 secs\n",
      "\n",
      "Epoch 497 Batch 0 Loss 0.0022 Accuracy 0.3746\n",
      "Epoch 497 Loss 0.0018 Accuracy 0.3526\n",
      "Time taken for 1 epoch: 15.018625259399414 secs\n",
      "\n",
      "Epoch 498 Batch 0 Loss 0.0033 Accuracy 0.3177\n",
      "Epoch 498 Loss 0.0014 Accuracy 0.3600\n",
      "Time taken for 1 epoch: 14.96277642250061 secs\n",
      "\n",
      "Epoch 499 Batch 0 Loss 0.0010 Accuracy 0.3398\n",
      "Epoch 499 Loss 0.0014 Accuracy 0.3537\n",
      "Time taken for 1 epoch: 15.033186197280884 secs\n",
      "\n",
      "Epoch 500 Batch 0 Loss 0.0002 Accuracy 0.4123\n",
      "Saving checkpoint for epoch 500 at ./checkpoints/train/ckpt-104\n",
      "Epoch 500 Loss 0.0010 Accuracy 0.3619\n",
      "Time taken for 1 epoch: 15.008063316345215 secs\n",
      "\n",
      "Epoch 501 Batch 0 Loss 0.0012 Accuracy 0.3381\n",
      "Epoch 501 Loss 0.0010 Accuracy 0.3656\n",
      "Time taken for 1 epoch: 14.531312942504883 secs\n",
      "\n",
      "Epoch 502 Batch 0 Loss 0.0011 Accuracy 0.3570\n",
      "Epoch 502 Loss 0.0024 Accuracy 0.3600\n",
      "Time taken for 1 epoch: 14.981821298599243 secs\n",
      "\n",
      "Epoch 503 Batch 0 Loss 0.0001 Accuracy 0.3745\n",
      "Epoch 503 Loss 0.0012 Accuracy 0.3527\n",
      "Time taken for 1 epoch: 15.209827184677124 secs\n",
      "\n",
      "Epoch 504 Batch 0 Loss 0.0028 Accuracy 0.3349\n",
      "Epoch 504 Loss 0.0012 Accuracy 0.3542\n",
      "Time taken for 1 epoch: 15.1623694896698 secs\n",
      "\n",
      "Epoch 505 Batch 0 Loss 0.0002 Accuracy 0.3579\n",
      "Saving checkpoint for epoch 505 at ./checkpoints/train/ckpt-105\n",
      "Epoch 505 Loss 0.0015 Accuracy 0.3533\n",
      "Time taken for 1 epoch: 15.60730266571045 secs\n",
      "\n",
      "Epoch 506 Batch 0 Loss 0.0001 Accuracy 0.3145\n",
      "Epoch 506 Loss 0.0011 Accuracy 0.3550\n",
      "Time taken for 1 epoch: 15.149154663085938 secs\n",
      "\n",
      "Epoch 507 Batch 0 Loss 0.0009 Accuracy 0.3333\n",
      "Epoch 507 Loss 0.0008 Accuracy 0.3573\n",
      "Time taken for 1 epoch: 14.819950103759766 secs\n",
      "\n",
      "Epoch 508 Batch 0 Loss 0.0000 Accuracy 0.3277\n",
      "Epoch 508 Loss 0.0016 Accuracy 0.3635\n",
      "Time taken for 1 epoch: 14.573928356170654 secs\n",
      "\n",
      "Epoch 509 Batch 0 Loss 0.0018 Accuracy 0.3189\n",
      "Epoch 509 Loss 0.0013 Accuracy 0.3610\n",
      "Time taken for 1 epoch: 14.655991315841675 secs\n",
      "\n",
      "Epoch 510 Batch 0 Loss 0.0001 Accuracy 0.3707\n",
      "Saving checkpoint for epoch 510 at ./checkpoints/train/ckpt-106\n",
      "Epoch 510 Loss 0.0018 Accuracy 0.3588\n",
      "Time taken for 1 epoch: 15.052725076675415 secs\n",
      "\n",
      "Epoch 511 Batch 0 Loss 0.0025 Accuracy 0.4631\n",
      "Epoch 511 Loss 0.0013 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 14.853039026260376 secs\n",
      "\n",
      "Epoch 512 Batch 0 Loss 0.0006 Accuracy 0.4052\n",
      "Epoch 512 Loss 0.0014 Accuracy 0.3592\n",
      "Time taken for 1 epoch: 14.982870101928711 secs\n",
      "\n",
      "Epoch 513 Batch 0 Loss 0.0044 Accuracy 0.4016\n",
      "Epoch 513 Loss 0.0014 Accuracy 0.3656\n",
      "Time taken for 1 epoch: 14.692357540130615 secs\n",
      "\n",
      "Epoch 514 Batch 0 Loss 0.0027 Accuracy 0.3329\n",
      "Epoch 514 Loss 0.0017 Accuracy 0.3596\n",
      "Time taken for 1 epoch: 14.795795917510986 secs\n",
      "\n",
      "Epoch 515 Batch 0 Loss 0.0008 Accuracy 0.3506\n",
      "Saving checkpoint for epoch 515 at ./checkpoints/train/ckpt-107\n",
      "Epoch 515 Loss 0.0015 Accuracy 0.3530\n",
      "Time taken for 1 epoch: 15.704752206802368 secs\n",
      "\n",
      "Epoch 516 Batch 0 Loss 0.0001 Accuracy 0.4177\n",
      "Epoch 516 Loss 0.0016 Accuracy 0.3613\n",
      "Time taken for 1 epoch: 14.643884420394897 secs\n",
      "\n",
      "Epoch 517 Batch 0 Loss 0.0002 Accuracy 0.3563\n",
      "Epoch 517 Loss 0.0014 Accuracy 0.3551\n",
      "Time taken for 1 epoch: 14.877747535705566 secs\n",
      "\n",
      "Epoch 518 Batch 0 Loss 0.0001 Accuracy 0.3842\n",
      "Epoch 518 Loss 0.0014 Accuracy 0.3584\n",
      "Time taken for 1 epoch: 14.86550235748291 secs\n",
      "\n",
      "Epoch 519 Batch 0 Loss 0.0001 Accuracy 0.4363\n",
      "Epoch 519 Loss 0.0015 Accuracy 0.3571\n",
      "Time taken for 1 epoch: 14.747225761413574 secs\n",
      "\n",
      "Epoch 520 Batch 0 Loss 0.0006 Accuracy 0.3231\n",
      "Saving checkpoint for epoch 520 at ./checkpoints/train/ckpt-108\n",
      "Epoch 520 Loss 0.0014 Accuracy 0.3573\n",
      "Time taken for 1 epoch: 15.074237823486328 secs\n",
      "\n",
      "Epoch 521 Batch 0 Loss 0.0053 Accuracy 0.3523\n",
      "Epoch 521 Loss 0.0021 Accuracy 0.3552\n",
      "Time taken for 1 epoch: 15.075547456741333 secs\n",
      "\n",
      "Epoch 522 Batch 0 Loss 0.0016 Accuracy 0.2998\n",
      "Epoch 522 Loss 0.0018 Accuracy 0.3597\n",
      "Time taken for 1 epoch: 14.798579216003418 secs\n",
      "\n",
      "Epoch 523 Batch 0 Loss 0.0007 Accuracy 0.3226\n",
      "Epoch 523 Loss 0.0011 Accuracy 0.3591\n",
      "Time taken for 1 epoch: 15.746026754379272 secs\n",
      "\n",
      "Epoch 524 Batch 0 Loss 0.0002 Accuracy 0.3253\n",
      "Epoch 524 Loss 0.0009 Accuracy 0.3607\n",
      "Time taken for 1 epoch: 14.749430179595947 secs\n",
      "\n",
      "Epoch 525 Batch 0 Loss 0.0034 Accuracy 0.4204\n",
      "Saving checkpoint for epoch 525 at ./checkpoints/train/ckpt-109\n",
      "Epoch 525 Loss 0.0014 Accuracy 0.3571\n",
      "Time taken for 1 epoch: 15.56050705909729 secs\n",
      "\n",
      "Epoch 526 Batch 0 Loss 0.0014 Accuracy 0.3063\n",
      "Epoch 526 Loss 0.0012 Accuracy 0.3608\n",
      "Time taken for 1 epoch: 14.789229393005371 secs\n",
      "\n",
      "Epoch 527 Batch 0 Loss 0.0032 Accuracy 0.3501\n",
      "Epoch 527 Loss 0.0014 Accuracy 0.3577\n",
      "Time taken for 1 epoch: 15.046337604522705 secs\n",
      "\n",
      "Epoch 528 Batch 0 Loss 0.0027 Accuracy 0.3740\n",
      "Epoch 528 Loss 0.0011 Accuracy 0.3570\n",
      "Time taken for 1 epoch: 14.802889347076416 secs\n",
      "\n",
      "Epoch 529 Batch 0 Loss 0.0002 Accuracy 0.3205\n",
      "Epoch 529 Loss 0.0015 Accuracy 0.3520\n",
      "Time taken for 1 epoch: 15.19284701347351 secs\n",
      "\n",
      "Epoch 530 Batch 0 Loss 0.0044 Accuracy 0.3300\n",
      "Saving checkpoint for epoch 530 at ./checkpoints/train/ckpt-110\n",
      "Epoch 530 Loss 0.0014 Accuracy 0.3542\n",
      "Time taken for 1 epoch: 15.758729457855225 secs\n",
      "\n",
      "Epoch 531 Batch 0 Loss 0.0025 Accuracy 0.3303\n",
      "Epoch 531 Loss 0.0011 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 14.65684461593628 secs\n",
      "\n",
      "Epoch 532 Batch 0 Loss 0.0001 Accuracy 0.3191\n",
      "Epoch 532 Loss 0.0009 Accuracy 0.3611\n",
      "Time taken for 1 epoch: 14.904354333877563 secs\n",
      "\n",
      "Epoch 533 Batch 0 Loss 0.0002 Accuracy 0.3876\n",
      "Epoch 533 Loss 0.0014 Accuracy 0.3590\n",
      "Time taken for 1 epoch: 14.775145053863525 secs\n",
      "\n",
      "Epoch 534 Batch 0 Loss 0.0011 Accuracy 0.3412\n",
      "Epoch 534 Loss 0.0014 Accuracy 0.3640\n",
      "Time taken for 1 epoch: 14.639891624450684 secs\n",
      "\n",
      "Epoch 535 Batch 0 Loss 0.0002 Accuracy 0.3641\n",
      "Saving checkpoint for epoch 535 at ./checkpoints/train/ckpt-111\n",
      "Epoch 535 Loss 0.0012 Accuracy 0.3599\n",
      "Time taken for 1 epoch: 15.238894939422607 secs\n",
      "\n",
      "Epoch 536 Batch 0 Loss 0.0001 Accuracy 0.4125\n",
      "Epoch 536 Loss 0.0016 Accuracy 0.3509\n",
      "Time taken for 1 epoch: 15.00302529335022 secs\n",
      "\n",
      "Epoch 537 Batch 0 Loss 0.0053 Accuracy 0.3404\n",
      "Epoch 537 Loss 0.0017 Accuracy 0.3501\n",
      "Time taken for 1 epoch: 15.465450048446655 secs\n",
      "\n",
      "Epoch 538 Batch 0 Loss 0.0023 Accuracy 0.3654\n",
      "Epoch 538 Loss 0.0013 Accuracy 0.3527\n",
      "Time taken for 1 epoch: 15.474325180053711 secs\n",
      "\n",
      "Epoch 539 Batch 0 Loss 0.0003 Accuracy 0.3856\n",
      "Epoch 539 Loss 0.0012 Accuracy 0.3592\n",
      "Time taken for 1 epoch: 14.794641971588135 secs\n",
      "\n",
      "Epoch 540 Batch 0 Loss 0.0001 Accuracy 0.3057\n",
      "Saving checkpoint for epoch 540 at ./checkpoints/train/ckpt-112\n",
      "Epoch 540 Loss 0.0012 Accuracy 0.3587\n",
      "Time taken for 1 epoch: 15.263715028762817 secs\n",
      "\n",
      "Epoch 541 Batch 0 Loss 0.0000 Accuracy 0.4265\n",
      "Epoch 541 Loss 0.0009 Accuracy 0.3560\n",
      "Time taken for 1 epoch: 14.84411883354187 secs\n",
      "\n",
      "Epoch 542 Batch 0 Loss 0.0034 Accuracy 0.3865\n",
      "Epoch 542 Loss 0.0012 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 15.426064729690552 secs\n",
      "\n",
      "Epoch 543 Batch 0 Loss 0.0003 Accuracy 0.3520\n",
      "Epoch 543 Loss 0.0014 Accuracy 0.3558\n",
      "Time taken for 1 epoch: 15.195024728775024 secs\n",
      "\n",
      "Epoch 544 Batch 0 Loss 0.0008 Accuracy 0.3863\n",
      "Epoch 544 Loss 0.0014 Accuracy 0.3580\n",
      "Time taken for 1 epoch: 14.774467468261719 secs\n",
      "\n",
      "Epoch 545 Batch 0 Loss 0.0003 Accuracy 0.3646\n",
      "Saving checkpoint for epoch 545 at ./checkpoints/train/ckpt-113\n",
      "Epoch 545 Loss 0.0010 Accuracy 0.3535\n",
      "Time taken for 1 epoch: 15.767533302307129 secs\n",
      "\n",
      "Epoch 546 Batch 0 Loss 0.0002 Accuracy 0.3788\n",
      "Epoch 546 Loss 0.0014 Accuracy 0.3494\n",
      "Time taken for 1 epoch: 15.318057537078857 secs\n",
      "\n",
      "Epoch 547 Batch 0 Loss 0.0002 Accuracy 0.4391\n",
      "Epoch 547 Loss 0.0009 Accuracy 0.3613\n",
      "Time taken for 1 epoch: 14.85208249092102 secs\n",
      "\n",
      "Epoch 548 Batch 0 Loss 0.0002 Accuracy 0.3062\n",
      "Epoch 548 Loss 0.0017 Accuracy 0.3549\n",
      "Time taken for 1 epoch: 14.947022676467896 secs\n",
      "\n",
      "Epoch 549 Batch 0 Loss 0.0023 Accuracy 0.4153\n",
      "Epoch 549 Loss 0.0022 Accuracy 0.3579\n",
      "Time taken for 1 epoch: 14.748430728912354 secs\n",
      "\n",
      "Epoch 550 Batch 0 Loss 0.0006 Accuracy 0.3451\n",
      "Saving checkpoint for epoch 550 at ./checkpoints/train/ckpt-114\n",
      "Epoch 550 Loss 0.0021 Accuracy 0.3532\n",
      "Time taken for 1 epoch: 15.458991765975952 secs\n",
      "\n",
      "Epoch 551 Batch 0 Loss 0.0007 Accuracy 0.3776\n",
      "Epoch 551 Loss 0.0011 Accuracy 0.3617\n",
      "Time taken for 1 epoch: 14.539555549621582 secs\n",
      "\n",
      "Epoch 552 Batch 0 Loss 0.0017 Accuracy 0.3368\n",
      "Epoch 552 Loss 0.0009 Accuracy 0.3600\n",
      "Time taken for 1 epoch: 14.819206953048706 secs\n",
      "\n",
      "Epoch 553 Batch 0 Loss 0.0001 Accuracy 0.3646\n",
      "Epoch 553 Loss 0.0006 Accuracy 0.3590\n",
      "Time taken for 1 epoch: 14.661474227905273 secs\n",
      "\n",
      "Epoch 554 Batch 0 Loss 0.0012 Accuracy 0.3958\n",
      "Epoch 554 Loss 0.0009 Accuracy 0.3579\n",
      "Time taken for 1 epoch: 15.361242294311523 secs\n",
      "\n",
      "Epoch 555 Batch 0 Loss 0.0011 Accuracy 0.3133\n",
      "Saving checkpoint for epoch 555 at ./checkpoints/train/ckpt-115\n",
      "Epoch 555 Loss 0.0008 Accuracy 0.3527\n",
      "Time taken for 1 epoch: 15.576243877410889 secs\n",
      "\n",
      "Epoch 556 Batch 0 Loss 0.0030 Accuracy 0.3232\n",
      "Epoch 556 Loss 0.0019 Accuracy 0.3553\n",
      "Time taken for 1 epoch: 14.872225999832153 secs\n",
      "\n",
      "Epoch 557 Batch 0 Loss 0.0033 Accuracy 0.3896\n",
      "Epoch 557 Loss 0.0013 Accuracy 0.3541\n",
      "Time taken for 1 epoch: 14.983041763305664 secs\n",
      "\n",
      "Epoch 558 Batch 0 Loss 0.0003 Accuracy 0.4141\n",
      "Epoch 558 Loss 0.0009 Accuracy 0.3527\n",
      "Time taken for 1 epoch: 15.233462810516357 secs\n",
      "\n",
      "Epoch 559 Batch 0 Loss 0.0003 Accuracy 0.3552\n",
      "Epoch 559 Loss 0.0009 Accuracy 0.3650\n",
      "Time taken for 1 epoch: 14.449817419052124 secs\n",
      "\n",
      "Epoch 560 Batch 0 Loss 0.0005 Accuracy 0.3281\n",
      "Saving checkpoint for epoch 560 at ./checkpoints/train/ckpt-116\n",
      "Epoch 560 Loss 0.0014 Accuracy 0.3609\n",
      "Time taken for 1 epoch: 14.969830989837646 secs\n",
      "\n",
      "Epoch 561 Batch 0 Loss 0.0010 Accuracy 0.3651\n",
      "Epoch 561 Loss 0.0013 Accuracy 0.3593\n",
      "Time taken for 1 epoch: 14.726673364639282 secs\n",
      "\n",
      "Epoch 562 Batch 0 Loss 0.0020 Accuracy 0.3772\n",
      "Epoch 562 Loss 0.0013 Accuracy 0.3629\n",
      "Time taken for 1 epoch: 14.478351831436157 secs\n",
      "\n",
      "Epoch 563 Batch 0 Loss 0.0010 Accuracy 0.4057\n",
      "Epoch 563 Loss 0.0018 Accuracy 0.3735\n",
      "Time taken for 1 epoch: 15.956237554550171 secs\n",
      "\n",
      "Epoch 564 Batch 0 Loss 0.0005 Accuracy 0.3935\n",
      "Epoch 564 Loss 0.0014 Accuracy 0.3567\n",
      "Time taken for 1 epoch: 15.60840392112732 secs\n",
      "\n",
      "Epoch 565 Batch 0 Loss 0.0001 Accuracy 0.3641\n",
      "Saving checkpoint for epoch 565 at ./checkpoints/train/ckpt-117\n",
      "Epoch 565 Loss 0.0015 Accuracy 0.3523\n",
      "Time taken for 1 epoch: 15.647937774658203 secs\n",
      "\n",
      "Epoch 566 Batch 0 Loss 0.0001 Accuracy 0.3108\n",
      "Epoch 566 Loss 0.0008 Accuracy 0.3517\n",
      "Time taken for 1 epoch: 15.220082998275757 secs\n",
      "\n",
      "Epoch 567 Batch 0 Loss 0.0001 Accuracy 0.4468\n",
      "Epoch 567 Loss 0.0009 Accuracy 0.3527\n",
      "Time taken for 1 epoch: 14.970970630645752 secs\n",
      "\n",
      "Epoch 568 Batch 0 Loss 0.0001 Accuracy 0.3353\n",
      "Epoch 568 Loss 0.0010 Accuracy 0.3562\n",
      "Time taken for 1 epoch: 14.95512866973877 secs\n",
      "\n",
      "Epoch 569 Batch 0 Loss 0.0004 Accuracy 0.2876\n",
      "Epoch 569 Loss 0.0010 Accuracy 0.3588\n",
      "Time taken for 1 epoch: 14.912975072860718 secs\n",
      "\n",
      "Epoch 570 Batch 0 Loss 0.0033 Accuracy 0.3980\n",
      "Saving checkpoint for epoch 570 at ./checkpoints/train/ckpt-118\n",
      "Epoch 570 Loss 0.0008 Accuracy 0.3608\n",
      "Time taken for 1 epoch: 15.198034524917603 secs\n",
      "\n",
      "Epoch 571 Batch 0 Loss 0.0010 Accuracy 0.3754\n",
      "Epoch 571 Loss 0.0010 Accuracy 0.3587\n",
      "Time taken for 1 epoch: 14.674212217330933 secs\n",
      "\n",
      "Epoch 572 Batch 0 Loss 0.0002 Accuracy 0.4645\n",
      "Epoch 572 Loss 0.0010 Accuracy 0.3607\n",
      "Time taken for 1 epoch: 14.897881031036377 secs\n",
      "\n",
      "Epoch 573 Batch 0 Loss 0.0002 Accuracy 0.3725\n",
      "Epoch 573 Loss 0.0009 Accuracy 0.3552\n",
      "Time taken for 1 epoch: 14.907810926437378 secs\n",
      "\n",
      "Epoch 574 Batch 0 Loss 0.0003 Accuracy 0.3343\n",
      "Epoch 574 Loss 0.0012 Accuracy 0.3561\n",
      "Time taken for 1 epoch: 15.429145336151123 secs\n",
      "\n",
      "Epoch 575 Batch 0 Loss 0.0003 Accuracy 0.3838\n",
      "Saving checkpoint for epoch 575 at ./checkpoints/train/ckpt-119\n",
      "Epoch 575 Loss 0.0014 Accuracy 0.3548\n",
      "Time taken for 1 epoch: 15.331243753433228 secs\n",
      "\n",
      "Epoch 576 Batch 0 Loss 0.0001 Accuracy 0.3922\n",
      "Epoch 576 Loss 0.0015 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 14.886882066726685 secs\n",
      "\n",
      "Epoch 577 Batch 0 Loss 0.0003 Accuracy 0.2792\n",
      "Epoch 577 Loss 0.0014 Accuracy 0.3653\n",
      "Time taken for 1 epoch: 14.574884414672852 secs\n",
      "\n",
      "Epoch 578 Batch 0 Loss 0.0000 Accuracy 0.3759\n",
      "Epoch 578 Loss 0.0007 Accuracy 0.3596\n",
      "Time taken for 1 epoch: 15.061111450195312 secs\n",
      "\n",
      "Epoch 579 Batch 0 Loss 0.0001 Accuracy 0.3357\n",
      "Epoch 579 Loss 0.0009 Accuracy 0.3604\n",
      "Time taken for 1 epoch: 14.838930130004883 secs\n",
      "\n",
      "Epoch 580 Batch 0 Loss 0.0007 Accuracy 0.3416\n",
      "Saving checkpoint for epoch 580 at ./checkpoints/train/ckpt-120\n",
      "Epoch 580 Loss 0.0017 Accuracy 0.3549\n",
      "Time taken for 1 epoch: 15.275655031204224 secs\n",
      "\n",
      "Epoch 581 Batch 0 Loss 0.0014 Accuracy 0.4425\n",
      "Epoch 581 Loss 0.0017 Accuracy 0.3573\n",
      "Time taken for 1 epoch: 14.853706121444702 secs\n",
      "\n",
      "Epoch 582 Batch 0 Loss 0.0002 Accuracy 0.3151\n",
      "Epoch 582 Loss 0.0007 Accuracy 0.3592\n",
      "Time taken for 1 epoch: 14.785200357437134 secs\n",
      "\n",
      "Epoch 583 Batch 0 Loss 0.0000 Accuracy 0.3455\n",
      "Epoch 583 Loss 0.0013 Accuracy 0.3576\n",
      "Time taken for 1 epoch: 14.83279538154602 secs\n",
      "\n",
      "Epoch 584 Batch 0 Loss 0.0001 Accuracy 0.3531\n",
      "Epoch 584 Loss 0.0011 Accuracy 0.3530\n",
      "Time taken for 1 epoch: 15.128717422485352 secs\n",
      "\n",
      "Epoch 585 Batch 0 Loss 0.0001 Accuracy 0.3336\n",
      "Saving checkpoint for epoch 585 at ./checkpoints/train/ckpt-121\n",
      "Epoch 585 Loss 0.0014 Accuracy 0.3584\n",
      "Time taken for 1 epoch: 15.305609941482544 secs\n",
      "\n",
      "Epoch 586 Batch 0 Loss 0.0001 Accuracy 0.4244\n",
      "Epoch 586 Loss 0.0012 Accuracy 0.3536\n",
      "Time taken for 1 epoch: 15.15010142326355 secs\n",
      "\n",
      "Epoch 587 Batch 0 Loss 0.0000 Accuracy 0.3618\n",
      "Epoch 587 Loss 0.0011 Accuracy 0.3590\n",
      "Time taken for 1 epoch: 14.946194410324097 secs\n",
      "\n",
      "Epoch 588 Batch 0 Loss 0.0024 Accuracy 0.3637\n",
      "Epoch 588 Loss 0.0012 Accuracy 0.3578\n",
      "Time taken for 1 epoch: 14.682867050170898 secs\n",
      "\n",
      "Epoch 589 Batch 0 Loss 0.0001 Accuracy 0.3530\n",
      "Epoch 589 Loss 0.0010 Accuracy 0.3534\n",
      "Time taken for 1 epoch: 14.93070650100708 secs\n",
      "\n",
      "Epoch 590 Batch 0 Loss 0.0001 Accuracy 0.3181\n",
      "Saving checkpoint for epoch 590 at ./checkpoints/train/ckpt-122\n",
      "Epoch 590 Loss 0.0008 Accuracy 0.3472\n",
      "Time taken for 1 epoch: 15.733921527862549 secs\n",
      "\n",
      "Epoch 591 Batch 0 Loss 0.0001 Accuracy 0.4087\n",
      "Epoch 591 Loss 0.0009 Accuracy 0.3539\n",
      "Time taken for 1 epoch: 14.855212211608887 secs\n",
      "\n",
      "Epoch 592 Batch 0 Loss 0.0025 Accuracy 0.3550\n",
      "Epoch 592 Loss 0.0009 Accuracy 0.3578\n",
      "Time taken for 1 epoch: 14.81296181678772 secs\n",
      "\n",
      "Epoch 593 Batch 0 Loss 0.0014 Accuracy 0.3222\n",
      "Epoch 593 Loss 0.0019 Accuracy 0.3518\n",
      "Time taken for 1 epoch: 15.160179138183594 secs\n",
      "\n",
      "Epoch 594 Batch 0 Loss 0.0001 Accuracy 0.3205\n",
      "Epoch 594 Loss 0.0012 Accuracy 0.3605\n",
      "Time taken for 1 epoch: 14.804022312164307 secs\n",
      "\n",
      "Epoch 595 Batch 0 Loss 0.0023 Accuracy 0.2893\n",
      "Saving checkpoint for epoch 595 at ./checkpoints/train/ckpt-123\n",
      "Epoch 595 Loss 0.0009 Accuracy 0.3631\n",
      "Time taken for 1 epoch: 14.852910041809082 secs\n",
      "\n",
      "Epoch 596 Batch 0 Loss 0.0009 Accuracy 0.3589\n",
      "Epoch 596 Loss 0.0010 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 15.082183837890625 secs\n",
      "\n",
      "Epoch 597 Batch 0 Loss 0.0001 Accuracy 0.3104\n",
      "Epoch 597 Loss 0.0014 Accuracy 0.3529\n",
      "Time taken for 1 epoch: 14.871061563491821 secs\n",
      "\n",
      "Epoch 598 Batch 0 Loss 0.0004 Accuracy 0.3475\n",
      "Epoch 598 Loss 0.0014 Accuracy 0.3593\n",
      "Time taken for 1 epoch: 14.683096408843994 secs\n",
      "\n",
      "Epoch 599 Batch 0 Loss 0.0003 Accuracy 0.3646\n",
      "Epoch 599 Loss 0.0006 Accuracy 0.3607\n",
      "Time taken for 1 epoch: 14.689141750335693 secs\n",
      "\n",
      "Epoch 600 Batch 0 Loss 0.0002 Accuracy 0.3775\n",
      "Saving checkpoint for epoch 600 at ./checkpoints/train/ckpt-124\n",
      "Epoch 600 Loss 0.0011 Accuracy 0.3554\n",
      "Time taken for 1 epoch: 15.15580677986145 secs\n",
      "\n",
      "Epoch 601 Batch 0 Loss 0.0001 Accuracy 0.4327\n",
      "Epoch 601 Loss 0.0005 Accuracy 0.3595\n",
      "Time taken for 1 epoch: 14.571151733398438 secs\n",
      "\n",
      "Epoch 602 Batch 0 Loss 0.0003 Accuracy 0.3813\n",
      "Epoch 602 Loss 0.0008 Accuracy 0.3575\n",
      "Time taken for 1 epoch: 14.902389764785767 secs\n",
      "\n",
      "Epoch 603 Batch 0 Loss 0.0000 Accuracy 0.3641\n",
      "Epoch 603 Loss 0.0013 Accuracy 0.3683\n",
      "Time taken for 1 epoch: 15.487664461135864 secs\n",
      "\n",
      "Epoch 604 Batch 0 Loss 0.0010 Accuracy 0.3261\n",
      "Epoch 604 Loss 0.0016 Accuracy 0.3633\n",
      "Time taken for 1 epoch: 14.62156367301941 secs\n",
      "\n",
      "Epoch 605 Batch 0 Loss 0.0001 Accuracy 0.3679\n",
      "Saving checkpoint for epoch 605 at ./checkpoints/train/ckpt-125\n",
      "Epoch 605 Loss 0.0011 Accuracy 0.3491\n",
      "Time taken for 1 epoch: 15.491799592971802 secs\n",
      "\n",
      "Epoch 606 Batch 0 Loss 0.0204 Accuracy 0.3081\n",
      "Epoch 606 Loss 0.0019 Accuracy 0.3572\n",
      "Time taken for 1 epoch: 14.875359535217285 secs\n",
      "\n",
      "Epoch 607 Batch 0 Loss 0.0012 Accuracy 0.3929\n",
      "Epoch 607 Loss 0.0015 Accuracy 0.3557\n",
      "Time taken for 1 epoch: 14.763588905334473 secs\n",
      "\n",
      "Epoch 608 Batch 0 Loss 0.0005 Accuracy 0.3224\n",
      "Epoch 608 Loss 0.0016 Accuracy 0.3559\n",
      "Time taken for 1 epoch: 15.046391725540161 secs\n",
      "\n",
      "Epoch 609 Batch 0 Loss 0.0008 Accuracy 0.3589\n",
      "Epoch 609 Loss 0.0010 Accuracy 0.3559\n",
      "Time taken for 1 epoch: 14.540447473526001 secs\n",
      "\n",
      "Epoch 610 Batch 0 Loss 0.0001 Accuracy 0.3949\n",
      "Saving checkpoint for epoch 610 at ./checkpoints/train/ckpt-126\n",
      "Epoch 610 Loss 0.0009 Accuracy 0.3652\n",
      "Time taken for 1 epoch: 15.061361312866211 secs\n",
      "\n",
      "Epoch 611 Batch 0 Loss 0.0003 Accuracy 0.4098\n",
      "Epoch 611 Loss 0.0014 Accuracy 0.3545\n",
      "Time taken for 1 epoch: 14.805685043334961 secs\n",
      "\n",
      "Epoch 612 Batch 0 Loss 0.0055 Accuracy 0.3991\n",
      "Epoch 612 Loss 0.0023 Accuracy 0.3577\n",
      "Time taken for 1 epoch: 14.887381076812744 secs\n",
      "\n",
      "Epoch 613 Batch 0 Loss 0.0010 Accuracy 0.3916\n",
      "Epoch 613 Loss 0.0011 Accuracy 0.3578\n",
      "Time taken for 1 epoch: 14.666335582733154 secs\n",
      "\n",
      "Epoch 614 Batch 0 Loss 0.0121 Accuracy 0.3736\n",
      "Epoch 614 Loss 0.0018 Accuracy 0.3516\n",
      "Time taken for 1 epoch: 15.139127731323242 secs\n",
      "\n",
      "Epoch 615 Batch 0 Loss 0.0002 Accuracy 0.3369\n",
      "Saving checkpoint for epoch 615 at ./checkpoints/train/ckpt-127\n",
      "Epoch 615 Loss 0.0014 Accuracy 0.3572\n",
      "Time taken for 1 epoch: 15.201201677322388 secs\n",
      "\n",
      "Epoch 616 Batch 0 Loss 0.0009 Accuracy 0.2880\n",
      "Epoch 616 Loss 0.0018 Accuracy 0.3567\n",
      "Time taken for 1 epoch: 14.674848556518555 secs\n",
      "\n",
      "Epoch 617 Batch 0 Loss 0.0002 Accuracy 0.3856\n",
      "Epoch 617 Loss 0.0011 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 14.520444393157959 secs\n",
      "\n",
      "Epoch 618 Batch 0 Loss 0.0029 Accuracy 0.3984\n",
      "Epoch 618 Loss 0.0014 Accuracy 0.3586\n",
      "Time taken for 1 epoch: 14.875722169876099 secs\n",
      "\n",
      "Epoch 619 Batch 0 Loss 0.0002 Accuracy 0.3525\n",
      "Epoch 619 Loss 0.0015 Accuracy 0.3586\n",
      "Time taken for 1 epoch: 14.820245742797852 secs\n",
      "\n",
      "Epoch 620 Batch 0 Loss 0.0022 Accuracy 0.3087\n",
      "Saving checkpoint for epoch 620 at ./checkpoints/train/ckpt-128\n",
      "Epoch 620 Loss 0.0007 Accuracy 0.3601\n",
      "Time taken for 1 epoch: 15.205530643463135 secs\n",
      "\n",
      "Epoch 621 Batch 0 Loss 0.0012 Accuracy 0.3021\n",
      "Epoch 621 Loss 0.0012 Accuracy 0.3564\n",
      "Time taken for 1 epoch: 14.57145619392395 secs\n",
      "\n",
      "Epoch 622 Batch 0 Loss 0.0003 Accuracy 0.4314\n",
      "Epoch 622 Loss 0.0019 Accuracy 0.3567\n",
      "Time taken for 1 epoch: 14.846227407455444 secs\n",
      "\n",
      "Epoch 623 Batch 0 Loss 0.0023 Accuracy 0.4278\n",
      "Epoch 623 Loss 0.0018 Accuracy 0.3545\n",
      "Time taken for 1 epoch: 15.216861724853516 secs\n",
      "\n",
      "Epoch 624 Batch 0 Loss 0.0012 Accuracy 0.3526\n",
      "Epoch 624 Loss 0.0018 Accuracy 0.3528\n",
      "Time taken for 1 epoch: 14.897993326187134 secs\n",
      "\n",
      "Epoch 625 Batch 0 Loss 0.0016 Accuracy 0.3512\n",
      "Saving checkpoint for epoch 625 at ./checkpoints/train/ckpt-129\n",
      "Epoch 625 Loss 0.0009 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 15.495668649673462 secs\n",
      "\n",
      "Epoch 626 Batch 0 Loss 0.0019 Accuracy 0.3072\n",
      "Epoch 626 Loss 0.0009 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 14.913047075271606 secs\n",
      "\n",
      "Epoch 627 Batch 0 Loss 0.0001 Accuracy 0.4851\n",
      "Epoch 627 Loss 0.0010 Accuracy 0.3613\n",
      "Time taken for 1 epoch: 14.963610887527466 secs\n",
      "\n",
      "Epoch 628 Batch 0 Loss 0.0004 Accuracy 0.3185\n",
      "Epoch 628 Loss 0.0013 Accuracy 0.3521\n",
      "Time taken for 1 epoch: 14.979419708251953 secs\n",
      "\n",
      "Epoch 629 Batch 0 Loss 0.0009 Accuracy 0.3984\n",
      "Epoch 629 Loss 0.0007 Accuracy 0.3606\n",
      "Time taken for 1 epoch: 14.65507698059082 secs\n",
      "\n",
      "Epoch 630 Batch 0 Loss 0.0001 Accuracy 0.3368\n",
      "Saving checkpoint for epoch 630 at ./checkpoints/train/ckpt-130\n",
      "Epoch 630 Loss 0.0008 Accuracy 0.3628\n",
      "Time taken for 1 epoch: 14.99882459640503 secs\n",
      "\n",
      "Epoch 631 Batch 0 Loss 0.0005 Accuracy 0.4342\n",
      "Epoch 631 Loss 0.0010 Accuracy 0.3564\n",
      "Time taken for 1 epoch: 14.956430912017822 secs\n",
      "\n",
      "Epoch 632 Batch 0 Loss 0.0004 Accuracy 0.4477\n",
      "Epoch 632 Loss 0.0014 Accuracy 0.3568\n",
      "Time taken for 1 epoch: 14.75423264503479 secs\n",
      "\n",
      "Epoch 633 Batch 0 Loss 0.0001 Accuracy 0.3763\n",
      "Epoch 633 Loss 0.0010 Accuracy 0.3554\n",
      "Time taken for 1 epoch: 14.86990237236023 secs\n",
      "\n",
      "Epoch 634 Batch 0 Loss 0.0001 Accuracy 0.3298\n",
      "Epoch 634 Loss 0.0010 Accuracy 0.3614\n",
      "Time taken for 1 epoch: 14.91399073600769 secs\n",
      "\n",
      "Epoch 635 Batch 0 Loss 0.0001 Accuracy 0.2981\n",
      "Saving checkpoint for epoch 635 at ./checkpoints/train/ckpt-131\n",
      "Epoch 635 Loss 0.0005 Accuracy 0.3539\n",
      "Time taken for 1 epoch: 15.728474855422974 secs\n",
      "\n",
      "Epoch 636 Batch 0 Loss 0.0001 Accuracy 0.4526\n",
      "Epoch 636 Loss 0.0009 Accuracy 0.3549\n",
      "Time taken for 1 epoch: 14.826296329498291 secs\n",
      "\n",
      "Epoch 637 Batch 0 Loss 0.0003 Accuracy 0.3705\n",
      "Epoch 637 Loss 0.0012 Accuracy 0.3530\n",
      "Time taken for 1 epoch: 15.10993766784668 secs\n",
      "\n",
      "Epoch 638 Batch 0 Loss 0.0069 Accuracy 0.4067\n",
      "Epoch 638 Loss 0.0014 Accuracy 0.3567\n",
      "Time taken for 1 epoch: 15.004955291748047 secs\n",
      "\n",
      "Epoch 639 Batch 0 Loss 0.0002 Accuracy 0.3137\n",
      "Epoch 639 Loss 0.0006 Accuracy 0.3584\n",
      "Time taken for 1 epoch: 14.686274528503418 secs\n",
      "\n",
      "Epoch 640 Batch 0 Loss 0.0002 Accuracy 0.3057\n",
      "Saving checkpoint for epoch 640 at ./checkpoints/train/ckpt-132\n",
      "Epoch 640 Loss 0.0014 Accuracy 0.3641\n",
      "Time taken for 1 epoch: 15.007026672363281 secs\n",
      "\n",
      "Epoch 641 Batch 0 Loss 0.0001 Accuracy 0.3409\n",
      "Epoch 641 Loss 0.0015 Accuracy 0.3569\n",
      "Time taken for 1 epoch: 14.601951122283936 secs\n",
      "\n",
      "Epoch 642 Batch 0 Loss 0.0004 Accuracy 0.3129\n",
      "Epoch 642 Loss 0.0010 Accuracy 0.3579\n",
      "Time taken for 1 epoch: 14.900312185287476 secs\n",
      "\n",
      "Epoch 643 Batch 0 Loss 0.0000 Accuracy 0.3201\n",
      "Epoch 643 Loss 0.0011 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 16.302704334259033 secs\n",
      "\n",
      "Epoch 644 Batch 0 Loss 0.0001 Accuracy 0.3543\n",
      "Epoch 644 Loss 0.0012 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 15.794112205505371 secs\n",
      "\n",
      "Epoch 645 Batch 0 Loss 0.0011 Accuracy 0.3053\n",
      "Saving checkpoint for epoch 645 at ./checkpoints/train/ckpt-133\n",
      "Epoch 645 Loss 0.0019 Accuracy 0.3603\n",
      "Time taken for 1 epoch: 15.371249198913574 secs\n",
      "\n",
      "Epoch 646 Batch 0 Loss 0.0002 Accuracy 0.3979\n",
      "Epoch 646 Loss 0.0008 Accuracy 0.3561\n",
      "Time taken for 1 epoch: 14.705251455307007 secs\n",
      "\n",
      "Epoch 647 Batch 0 Loss 0.0012 Accuracy 0.3750\n",
      "Epoch 647 Loss 0.0010 Accuracy 0.3593\n",
      "Time taken for 1 epoch: 14.909345626831055 secs\n",
      "\n",
      "Epoch 648 Batch 0 Loss 0.0001 Accuracy 0.3468\n",
      "Epoch 648 Loss 0.0008 Accuracy 0.3583\n",
      "Time taken for 1 epoch: 14.77365517616272 secs\n",
      "\n",
      "Epoch 649 Batch 0 Loss 0.0001 Accuracy 0.4108\n",
      "Epoch 649 Loss 0.0008 Accuracy 0.3574\n",
      "Time taken for 1 epoch: 14.7510507106781 secs\n",
      "\n",
      "Epoch 650 Batch 0 Loss 0.0003 Accuracy 0.4111\n",
      "Saving checkpoint for epoch 650 at ./checkpoints/train/ckpt-134\n",
      "Epoch 650 Loss 0.0010 Accuracy 0.3581\n",
      "Time taken for 1 epoch: 15.179241418838501 secs\n",
      "\n",
      "Epoch 651 Batch 0 Loss 0.0009 Accuracy 0.3843\n",
      "Epoch 651 Loss 0.0008 Accuracy 0.3641\n",
      "Time taken for 1 epoch: 14.573537826538086 secs\n",
      "\n",
      "Epoch 652 Batch 0 Loss 0.0000 Accuracy 0.3542\n",
      "Epoch 652 Loss 0.0009 Accuracy 0.3646\n",
      "Time taken for 1 epoch: 14.629755735397339 secs\n",
      "\n",
      "Epoch 653 Batch 0 Loss 0.0001 Accuracy 0.3979\n",
      "Epoch 653 Loss 0.0013 Accuracy 0.3586\n",
      "Time taken for 1 epoch: 14.989912033081055 secs\n",
      "\n",
      "Epoch 654 Batch 0 Loss 0.0009 Accuracy 0.3570\n",
      "Epoch 654 Loss 0.0011 Accuracy 0.3548\n",
      "Time taken for 1 epoch: 14.862598419189453 secs\n",
      "\n",
      "Epoch 655 Batch 0 Loss 0.0007 Accuracy 0.3452\n",
      "Saving checkpoint for epoch 655 at ./checkpoints/train/ckpt-135\n",
      "Epoch 655 Loss 0.0011 Accuracy 0.3667\n",
      "Time taken for 1 epoch: 14.976212739944458 secs\n",
      "\n",
      "Epoch 656 Batch 0 Loss 0.0012 Accuracy 0.3650\n",
      "Epoch 656 Loss 0.0010 Accuracy 0.3528\n",
      "Time taken for 1 epoch: 14.786293506622314 secs\n",
      "\n",
      "Epoch 657 Batch 0 Loss 0.0019 Accuracy 0.3774\n",
      "Epoch 657 Loss 0.0012 Accuracy 0.3533\n",
      "Time taken for 1 epoch: 15.116790771484375 secs\n",
      "\n",
      "Epoch 658 Batch 0 Loss 0.0001 Accuracy 0.4315\n",
      "Epoch 658 Loss 0.0008 Accuracy 0.3597\n",
      "Time taken for 1 epoch: 14.84044098854065 secs\n",
      "\n",
      "Epoch 659 Batch 0 Loss 0.0001 Accuracy 0.3390\n",
      "Epoch 659 Loss 0.0005 Accuracy 0.3569\n",
      "Time taken for 1 epoch: 14.880247116088867 secs\n",
      "\n",
      "Epoch 660 Batch 0 Loss 0.0000 Accuracy 0.3490\n",
      "Saving checkpoint for epoch 660 at ./checkpoints/train/ckpt-136\n",
      "Epoch 660 Loss 0.0002 Accuracy 0.3607\n",
      "Time taken for 1 epoch: 15.337606430053711 secs\n",
      "\n",
      "Epoch 661 Batch 0 Loss 0.0007 Accuracy 0.3826\n",
      "Epoch 661 Loss 0.0015 Accuracy 0.3536\n",
      "Time taken for 1 epoch: 14.793951272964478 secs\n",
      "\n",
      "Epoch 662 Batch 0 Loss 0.0002 Accuracy 0.4294\n",
      "Epoch 662 Loss 0.0009 Accuracy 0.3591\n",
      "Time taken for 1 epoch: 15.002410888671875 secs\n",
      "\n",
      "Epoch 663 Batch 0 Loss 0.0004 Accuracy 0.2829\n",
      "Epoch 663 Loss 0.0007 Accuracy 0.3575\n",
      "Time taken for 1 epoch: 14.965722560882568 secs\n",
      "\n",
      "Epoch 664 Batch 0 Loss 0.0006 Accuracy 0.3332\n",
      "Epoch 664 Loss 0.0016 Accuracy 0.3529\n",
      "Time taken for 1 epoch: 14.913118362426758 secs\n",
      "\n",
      "Epoch 665 Batch 0 Loss 0.0010 Accuracy 0.3870\n",
      "Saving checkpoint for epoch 665 at ./checkpoints/train/ckpt-137\n",
      "Epoch 665 Loss 0.0010 Accuracy 0.3605\n",
      "Time taken for 1 epoch: 15.557430028915405 secs\n",
      "\n",
      "Epoch 666 Batch 0 Loss 0.0004 Accuracy 0.3611\n",
      "Epoch 666 Loss 0.0018 Accuracy 0.3536\n",
      "Time taken for 1 epoch: 14.839008808135986 secs\n",
      "\n",
      "Epoch 667 Batch 0 Loss 0.0013 Accuracy 0.3862\n",
      "Epoch 667 Loss 0.0014 Accuracy 0.3532\n",
      "Time taken for 1 epoch: 15.496793508529663 secs\n",
      "\n",
      "Epoch 668 Batch 0 Loss 0.0002 Accuracy 0.3416\n",
      "Epoch 668 Loss 0.0008 Accuracy 0.3604\n",
      "Time taken for 1 epoch: 14.786010503768921 secs\n",
      "\n",
      "Epoch 669 Batch 0 Loss 0.0001 Accuracy 0.4792\n",
      "Epoch 669 Loss 0.0011 Accuracy 0.3631\n",
      "Time taken for 1 epoch: 14.56277060508728 secs\n",
      "\n",
      "Epoch 670 Batch 0 Loss 0.0009 Accuracy 0.3456\n",
      "Saving checkpoint for epoch 670 at ./checkpoints/train/ckpt-138\n",
      "Epoch 670 Loss 0.0008 Accuracy 0.3571\n",
      "Time taken for 1 epoch: 15.443022966384888 secs\n",
      "\n",
      "Epoch 671 Batch 0 Loss 0.0067 Accuracy 0.3760\n",
      "Epoch 671 Loss 0.0008 Accuracy 0.3576\n",
      "Time taken for 1 epoch: 14.610259294509888 secs\n",
      "\n",
      "Epoch 672 Batch 0 Loss 0.0001 Accuracy 0.4172\n",
      "Epoch 672 Loss 0.0015 Accuracy 0.3587\n",
      "Time taken for 1 epoch: 14.822545289993286 secs\n",
      "\n",
      "Epoch 673 Batch 0 Loss 0.0003 Accuracy 0.3524\n",
      "Epoch 673 Loss 0.0006 Accuracy 0.3573\n",
      "Time taken for 1 epoch: 14.642656326293945 secs\n",
      "\n",
      "Epoch 674 Batch 0 Loss 0.0000 Accuracy 0.3713\n",
      "Epoch 674 Loss 0.0014 Accuracy 0.3557\n",
      "Time taken for 1 epoch: 15.150686264038086 secs\n",
      "\n",
      "Epoch 675 Batch 0 Loss 0.0003 Accuracy 0.3996\n",
      "Saving checkpoint for epoch 675 at ./checkpoints/train/ckpt-139\n",
      "Epoch 675 Loss 0.0013 Accuracy 0.3577\n",
      "Time taken for 1 epoch: 15.402669191360474 secs\n",
      "\n",
      "Epoch 676 Batch 0 Loss 0.0018 Accuracy 0.3156\n",
      "Epoch 676 Loss 0.0014 Accuracy 0.3592\n",
      "Time taken for 1 epoch: 14.606430768966675 secs\n",
      "\n",
      "Epoch 677 Batch 0 Loss 0.0002 Accuracy 0.3017\n",
      "Epoch 677 Loss 0.0022 Accuracy 0.3547\n",
      "Time taken for 1 epoch: 15.170949220657349 secs\n",
      "\n",
      "Epoch 678 Batch 0 Loss 0.0009 Accuracy 0.3503\n",
      "Epoch 678 Loss 0.0010 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 14.559741735458374 secs\n",
      "\n",
      "Epoch 679 Batch 0 Loss 0.0004 Accuracy 0.3229\n",
      "Epoch 679 Loss 0.0005 Accuracy 0.3538\n",
      "Time taken for 1 epoch: 14.925230979919434 secs\n",
      "\n",
      "Epoch 680 Batch 0 Loss 0.0000 Accuracy 0.3031\n",
      "Saving checkpoint for epoch 680 at ./checkpoints/train/ckpt-140\n",
      "Epoch 680 Loss 0.0013 Accuracy 0.3610\n",
      "Time taken for 1 epoch: 15.053390979766846 secs\n",
      "\n",
      "Epoch 681 Batch 0 Loss 0.0003 Accuracy 0.3454\n",
      "Epoch 681 Loss 0.0007 Accuracy 0.3595\n",
      "Time taken for 1 epoch: 14.676647186279297 secs\n",
      "\n",
      "Epoch 682 Batch 0 Loss 0.0002 Accuracy 0.3576\n",
      "Epoch 682 Loss 0.0008 Accuracy 0.3568\n",
      "Time taken for 1 epoch: 14.629946947097778 secs\n",
      "\n",
      "Epoch 683 Batch 0 Loss 0.0002 Accuracy 0.3750\n",
      "Epoch 683 Loss 0.0005 Accuracy 0.3569\n",
      "Time taken for 1 epoch: 15.954755544662476 secs\n",
      "\n",
      "Epoch 684 Batch 0 Loss 0.0007 Accuracy 0.2877\n",
      "Epoch 684 Loss 0.0014 Accuracy 0.3531\n",
      "Time taken for 1 epoch: 14.906994581222534 secs\n",
      "\n",
      "Epoch 685 Batch 0 Loss 0.0000 Accuracy 0.4057\n",
      "Saving checkpoint for epoch 685 at ./checkpoints/train/ckpt-141\n",
      "Epoch 685 Loss 0.0016 Accuracy 0.3616\n",
      "Time taken for 1 epoch: 15.301236867904663 secs\n",
      "\n",
      "Epoch 686 Batch 0 Loss 0.0028 Accuracy 0.3145\n",
      "Epoch 686 Loss 0.0013 Accuracy 0.3553\n",
      "Time taken for 1 epoch: 14.84980297088623 secs\n",
      "\n",
      "Epoch 687 Batch 0 Loss 0.0001 Accuracy 0.3346\n",
      "Epoch 687 Loss 0.0009 Accuracy 0.3557\n",
      "Time taken for 1 epoch: 14.851774215698242 secs\n",
      "\n",
      "Epoch 688 Batch 0 Loss 0.0001 Accuracy 0.4088\n",
      "Epoch 688 Loss 0.0011 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 14.749200820922852 secs\n",
      "\n",
      "Epoch 689 Batch 0 Loss 0.0004 Accuracy 0.3720\n",
      "Epoch 689 Loss 0.0010 Accuracy 0.3658\n",
      "Time taken for 1 epoch: 14.381923913955688 secs\n",
      "\n",
      "Epoch 690 Batch 0 Loss 0.0008 Accuracy 0.3167\n",
      "Saving checkpoint for epoch 690 at ./checkpoints/train/ckpt-142\n",
      "Epoch 690 Loss 0.0011 Accuracy 0.3577\n",
      "Time taken for 1 epoch: 15.276158809661865 secs\n",
      "\n",
      "Epoch 691 Batch 0 Loss 0.0001 Accuracy 0.3474\n",
      "Epoch 691 Loss 0.0012 Accuracy 0.3569\n",
      "Time taken for 1 epoch: 14.734351634979248 secs\n",
      "\n",
      "Epoch 692 Batch 0 Loss 0.0003 Accuracy 0.4092\n",
      "Epoch 692 Loss 0.0012 Accuracy 0.3590\n",
      "Time taken for 1 epoch: 14.935880422592163 secs\n",
      "\n",
      "Epoch 693 Batch 0 Loss 0.0001 Accuracy 0.3397\n",
      "Epoch 693 Loss 0.0011 Accuracy 0.3532\n",
      "Time taken for 1 epoch: 14.937659740447998 secs\n",
      "\n",
      "Epoch 694 Batch 0 Loss 0.0000 Accuracy 0.3215\n",
      "Epoch 694 Loss 0.0010 Accuracy 0.3551\n",
      "Time taken for 1 epoch: 15.097137212753296 secs\n",
      "\n",
      "Epoch 695 Batch 0 Loss 0.0011 Accuracy 0.3696\n",
      "Saving checkpoint for epoch 695 at ./checkpoints/train/ckpt-143\n",
      "Epoch 695 Loss 0.0006 Accuracy 0.3517\n",
      "Time taken for 1 epoch: 15.391557216644287 secs\n",
      "\n",
      "Epoch 696 Batch 0 Loss 0.0004 Accuracy 0.3398\n",
      "Epoch 696 Loss 0.0013 Accuracy 0.3560\n",
      "Time taken for 1 epoch: 14.598307132720947 secs\n",
      "\n",
      "Epoch 697 Batch 0 Loss 0.0000 Accuracy 0.2886\n",
      "Epoch 697 Loss 0.0015 Accuracy 0.3554\n",
      "Time taken for 1 epoch: 15.103378057479858 secs\n",
      "\n",
      "Epoch 698 Batch 0 Loss 0.0007 Accuracy 0.4113\n",
      "Epoch 698 Loss 0.0007 Accuracy 0.3612\n",
      "Time taken for 1 epoch: 14.522320985794067 secs\n",
      "\n",
      "Epoch 699 Batch 0 Loss 0.0001 Accuracy 0.3644\n",
      "Epoch 699 Loss 0.0013 Accuracy 0.3661\n",
      "Time taken for 1 epoch: 14.472915649414062 secs\n",
      "\n",
      "Epoch 700 Batch 0 Loss 0.0006 Accuracy 0.3790\n",
      "Saving checkpoint for epoch 700 at ./checkpoints/train/ckpt-144\n",
      "Epoch 700 Loss 0.0009 Accuracy 0.3616\n",
      "Time taken for 1 epoch: 15.075879335403442 secs\n",
      "\n",
      "Epoch 701 Batch 0 Loss 0.0003 Accuracy 0.3732\n",
      "Epoch 701 Loss 0.0010 Accuracy 0.3589\n",
      "Time taken for 1 epoch: 14.878082036972046 secs\n",
      "\n",
      "Epoch 702 Batch 0 Loss 0.0000 Accuracy 0.3086\n",
      "Epoch 702 Loss 0.0015 Accuracy 0.3629\n",
      "Time taken for 1 epoch: 14.44420838356018 secs\n",
      "\n",
      "Epoch 703 Batch 0 Loss 0.0001 Accuracy 0.3530\n",
      "Epoch 703 Loss 0.0011 Accuracy 0.3596\n",
      "Time taken for 1 epoch: 14.908178567886353 secs\n",
      "\n",
      "Epoch 704 Batch 0 Loss 0.0001 Accuracy 0.2997\n",
      "Epoch 704 Loss 0.0011 Accuracy 0.3587\n",
      "Time taken for 1 epoch: 14.530229568481445 secs\n",
      "\n",
      "Epoch 705 Batch 0 Loss 0.0001 Accuracy 0.3809\n",
      "Saving checkpoint for epoch 705 at ./checkpoints/train/ckpt-145\n",
      "Epoch 705 Loss 0.0012 Accuracy 0.3646\n",
      "Time taken for 1 epoch: 15.189436197280884 secs\n",
      "\n",
      "Epoch 706 Batch 0 Loss 0.0002 Accuracy 0.3307\n",
      "Epoch 706 Loss 0.0011 Accuracy 0.3587\n",
      "Time taken for 1 epoch: 14.491806745529175 secs\n",
      "\n",
      "Epoch 707 Batch 0 Loss 0.0005 Accuracy 0.2833\n",
      "Epoch 707 Loss 0.0005 Accuracy 0.3567\n",
      "Time taken for 1 epoch: 15.021952867507935 secs\n",
      "\n",
      "Epoch 708 Batch 0 Loss 0.0005 Accuracy 0.3145\n",
      "Epoch 708 Loss 0.0009 Accuracy 0.3589\n",
      "Time taken for 1 epoch: 14.867110967636108 secs\n",
      "\n",
      "Epoch 709 Batch 0 Loss 0.0001 Accuracy 0.3252\n",
      "Epoch 709 Loss 0.0008 Accuracy 0.3550\n",
      "Time taken for 1 epoch: 14.72563362121582 secs\n",
      "\n",
      "Epoch 710 Batch 0 Loss 0.0081 Accuracy 0.3590\n",
      "Saving checkpoint for epoch 710 at ./checkpoints/train/ckpt-146\n",
      "Epoch 710 Loss 0.0015 Accuracy 0.3609\n",
      "Time taken for 1 epoch: 15.22896933555603 secs\n",
      "\n",
      "Epoch 711 Batch 0 Loss 0.0005 Accuracy 0.3613\n",
      "Epoch 711 Loss 0.0019 Accuracy 0.3587\n",
      "Time taken for 1 epoch: 14.74300765991211 secs\n",
      "\n",
      "Epoch 712 Batch 0 Loss 0.0008 Accuracy 0.4189\n",
      "Epoch 712 Loss 0.0006 Accuracy 0.3527\n",
      "Time taken for 1 epoch: 15.099976062774658 secs\n",
      "\n",
      "Epoch 713 Batch 0 Loss 0.0001 Accuracy 0.3551\n",
      "Epoch 713 Loss 0.0011 Accuracy 0.3552\n",
      "Time taken for 1 epoch: 15.164164304733276 secs\n",
      "\n",
      "Epoch 714 Batch 0 Loss 0.0002 Accuracy 0.3594\n",
      "Epoch 714 Loss 0.0009 Accuracy 0.3568\n",
      "Time taken for 1 epoch: 14.838350296020508 secs\n",
      "\n",
      "Epoch 715 Batch 0 Loss 0.0010 Accuracy 0.3513\n",
      "Saving checkpoint for epoch 715 at ./checkpoints/train/ckpt-147\n",
      "Epoch 715 Loss 0.0007 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 15.703096866607666 secs\n",
      "\n",
      "Epoch 716 Batch 0 Loss 0.0004 Accuracy 0.3482\n",
      "Epoch 716 Loss 0.0007 Accuracy 0.3573\n",
      "Time taken for 1 epoch: 14.809917211532593 secs\n",
      "\n",
      "Epoch 717 Batch 0 Loss 0.0005 Accuracy 0.3745\n",
      "Epoch 717 Loss 0.0010 Accuracy 0.3533\n",
      "Time taken for 1 epoch: 15.299517393112183 secs\n",
      "\n",
      "Epoch 718 Batch 0 Loss 0.0000 Accuracy 0.3672\n",
      "Epoch 718 Loss 0.0014 Accuracy 0.3591\n",
      "Time taken for 1 epoch: 14.947113037109375 secs\n",
      "\n",
      "Epoch 719 Batch 0 Loss 0.0003 Accuracy 0.4181\n",
      "Epoch 719 Loss 0.0007 Accuracy 0.3525\n",
      "Time taken for 1 epoch: 15.157965660095215 secs\n",
      "\n",
      "Epoch 720 Batch 0 Loss 0.0003 Accuracy 0.4068\n",
      "Saving checkpoint for epoch 720 at ./checkpoints/train/ckpt-148\n",
      "Epoch 720 Loss 0.0012 Accuracy 0.3523\n",
      "Time taken for 1 epoch: 15.552188158035278 secs\n",
      "\n",
      "Epoch 721 Batch 0 Loss 0.0001 Accuracy 0.3325\n",
      "Epoch 721 Loss 0.0004 Accuracy 0.3625\n",
      "Time taken for 1 epoch: 14.469067096710205 secs\n",
      "\n",
      "Epoch 722 Batch 0 Loss 0.0005 Accuracy 0.3825\n",
      "Epoch 722 Loss 0.0010 Accuracy 0.3530\n",
      "Time taken for 1 epoch: 15.250030279159546 secs\n",
      "\n",
      "Epoch 723 Batch 0 Loss 0.0027 Accuracy 0.4116\n",
      "Epoch 723 Loss 0.0012 Accuracy 0.3561\n",
      "Time taken for 1 epoch: 16.04301118850708 secs\n",
      "\n",
      "Epoch 724 Batch 0 Loss 0.0001 Accuracy 0.3693\n",
      "Epoch 724 Loss 0.0015 Accuracy 0.3545\n",
      "Time taken for 1 epoch: 15.964936017990112 secs\n",
      "\n",
      "Epoch 725 Batch 0 Loss 0.0007 Accuracy 0.3475\n",
      "Saving checkpoint for epoch 725 at ./checkpoints/train/ckpt-149\n",
      "Epoch 725 Loss 0.0012 Accuracy 0.3584\n",
      "Time taken for 1 epoch: 15.658268451690674 secs\n",
      "\n",
      "Epoch 726 Batch 0 Loss 0.0002 Accuracy 0.4073\n",
      "Epoch 726 Loss 0.0021 Accuracy 0.3679\n",
      "Time taken for 1 epoch: 14.338624477386475 secs\n",
      "\n",
      "Epoch 727 Batch 0 Loss 0.0001 Accuracy 0.3328\n",
      "Epoch 727 Loss 0.0009 Accuracy 0.3551\n",
      "Time taken for 1 epoch: 15.36011528968811 secs\n",
      "\n",
      "Epoch 728 Batch 0 Loss 0.0012 Accuracy 0.4041\n",
      "Epoch 728 Loss 0.0014 Accuracy 0.3609\n",
      "Time taken for 1 epoch: 14.471811294555664 secs\n",
      "\n",
      "Epoch 729 Batch 0 Loss 0.0006 Accuracy 0.4353\n",
      "Epoch 729 Loss 0.0013 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 15.015569686889648 secs\n",
      "\n",
      "Epoch 730 Batch 0 Loss 0.0002 Accuracy 0.3876\n",
      "Saving checkpoint for epoch 730 at ./checkpoints/train/ckpt-150\n",
      "Epoch 730 Loss 0.0011 Accuracy 0.3511\n",
      "Time taken for 1 epoch: 15.597538709640503 secs\n",
      "\n",
      "Epoch 731 Batch 0 Loss 0.0036 Accuracy 0.3826\n",
      "Epoch 731 Loss 0.0015 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 14.694860458374023 secs\n",
      "\n",
      "Epoch 732 Batch 0 Loss 0.0004 Accuracy 0.3181\n",
      "Epoch 732 Loss 0.0010 Accuracy 0.3515\n",
      "Time taken for 1 epoch: 15.409918546676636 secs\n",
      "\n",
      "Epoch 733 Batch 0 Loss 0.0000 Accuracy 0.2977\n",
      "Epoch 733 Loss 0.0008 Accuracy 0.3539\n",
      "Time taken for 1 epoch: 14.885475873947144 secs\n",
      "\n",
      "Epoch 734 Batch 0 Loss 0.0009 Accuracy 0.3790\n",
      "Epoch 734 Loss 0.0006 Accuracy 0.3597\n",
      "Time taken for 1 epoch: 14.782881736755371 secs\n",
      "\n",
      "Epoch 735 Batch 0 Loss 0.0001 Accuracy 0.3944\n",
      "Saving checkpoint for epoch 735 at ./checkpoints/train/ckpt-151\n",
      "Epoch 735 Loss 0.0005 Accuracy 0.3523\n",
      "Time taken for 1 epoch: 15.62240743637085 secs\n",
      "\n",
      "Epoch 736 Batch 0 Loss 0.0008 Accuracy 0.4267\n",
      "Epoch 736 Loss 0.0011 Accuracy 0.3584\n",
      "Time taken for 1 epoch: 14.495655059814453 secs\n",
      "\n",
      "Epoch 737 Batch 0 Loss 0.0000 Accuracy 0.3324\n",
      "Epoch 737 Loss 0.0014 Accuracy 0.3540\n",
      "Time taken for 1 epoch: 15.087780952453613 secs\n",
      "\n",
      "Epoch 738 Batch 0 Loss 0.0023 Accuracy 0.4500\n",
      "Epoch 738 Loss 0.0006 Accuracy 0.3629\n",
      "Time taken for 1 epoch: 14.777113199234009 secs\n",
      "\n",
      "Epoch 739 Batch 0 Loss 0.0003 Accuracy 0.3303\n",
      "Epoch 739 Loss 0.0006 Accuracy 0.3553\n",
      "Time taken for 1 epoch: 14.861578702926636 secs\n",
      "\n",
      "Epoch 740 Batch 0 Loss 0.0008 Accuracy 0.3490\n",
      "Saving checkpoint for epoch 740 at ./checkpoints/train/ckpt-152\n",
      "Epoch 740 Loss 0.0010 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 15.303122520446777 secs\n",
      "\n",
      "Epoch 741 Batch 0 Loss 0.0000 Accuracy 0.3852\n",
      "Epoch 741 Loss 0.0006 Accuracy 0.3547\n",
      "Time taken for 1 epoch: 15.098970890045166 secs\n",
      "\n",
      "Epoch 742 Batch 0 Loss 0.0003 Accuracy 0.3209\n",
      "Epoch 742 Loss 0.0009 Accuracy 0.3539\n",
      "Time taken for 1 epoch: 14.772262811660767 secs\n",
      "\n",
      "Epoch 743 Batch 0 Loss 0.0022 Accuracy 0.3558\n",
      "Epoch 743 Loss 0.0011 Accuracy 0.3619\n",
      "Time taken for 1 epoch: 14.754115104675293 secs\n",
      "\n",
      "Epoch 744 Batch 0 Loss 0.0016 Accuracy 0.3679\n",
      "Epoch 744 Loss 0.0013 Accuracy 0.3526\n",
      "Time taken for 1 epoch: 14.863202810287476 secs\n",
      "\n",
      "Epoch 745 Batch 0 Loss 0.0038 Accuracy 0.3421\n",
      "Saving checkpoint for epoch 745 at ./checkpoints/train/ckpt-153\n",
      "Epoch 745 Loss 0.0013 Accuracy 0.3602\n",
      "Time taken for 1 epoch: 15.34786868095398 secs\n",
      "\n",
      "Epoch 746 Batch 0 Loss 0.0003 Accuracy 0.4017\n",
      "Epoch 746 Loss 0.0010 Accuracy 0.3577\n",
      "Time taken for 1 epoch: 14.59502649307251 secs\n",
      "\n",
      "Epoch 747 Batch 0 Loss 0.0000 Accuracy 0.3896\n",
      "Epoch 747 Loss 0.0005 Accuracy 0.3572\n",
      "Time taken for 1 epoch: 15.114910364151001 secs\n",
      "\n",
      "Epoch 748 Batch 0 Loss 0.0013 Accuracy 0.3550\n",
      "Epoch 748 Loss 0.0011 Accuracy 0.3574\n",
      "Time taken for 1 epoch: 15.094080924987793 secs\n",
      "\n",
      "Epoch 749 Batch 0 Loss 0.0008 Accuracy 0.3739\n",
      "Epoch 749 Loss 0.0006 Accuracy 0.3581\n",
      "Time taken for 1 epoch: 14.612703800201416 secs\n",
      "\n",
      "Epoch 750 Batch 0 Loss 0.0000 Accuracy 0.3643\n",
      "Saving checkpoint for epoch 750 at ./checkpoints/train/ckpt-154\n",
      "Epoch 750 Loss 0.0012 Accuracy 0.3606\n",
      "Time taken for 1 epoch: 15.12230396270752 secs\n",
      "\n",
      "Epoch 751 Batch 0 Loss 0.0031 Accuracy 0.3301\n",
      "Epoch 751 Loss 0.0009 Accuracy 0.3562\n",
      "Time taken for 1 epoch: 14.762638092041016 secs\n",
      "\n",
      "Epoch 752 Batch 0 Loss 0.0010 Accuracy 0.4118\n",
      "Epoch 752 Loss 0.0007 Accuracy 0.3524\n",
      "Time taken for 1 epoch: 15.07520866394043 secs\n",
      "\n",
      "Epoch 753 Batch 0 Loss 0.0002 Accuracy 0.3977\n",
      "Epoch 753 Loss 0.0008 Accuracy 0.3513\n",
      "Time taken for 1 epoch: 15.053197860717773 secs\n",
      "\n",
      "Epoch 754 Batch 0 Loss 0.0001 Accuracy 0.3712\n",
      "Epoch 754 Loss 0.0008 Accuracy 0.3589\n",
      "Time taken for 1 epoch: 14.837736129760742 secs\n",
      "\n",
      "Epoch 755 Batch 0 Loss 0.0039 Accuracy 0.3996\n",
      "Saving checkpoint for epoch 755 at ./checkpoints/train/ckpt-155\n",
      "Epoch 755 Loss 0.0011 Accuracy 0.3601\n",
      "Time taken for 1 epoch: 15.364527225494385 secs\n",
      "\n",
      "Epoch 756 Batch 0 Loss 0.0025 Accuracy 0.3406\n",
      "Epoch 756 Loss 0.0008 Accuracy 0.3575\n",
      "Time taken for 1 epoch: 14.825305700302124 secs\n",
      "\n",
      "Epoch 757 Batch 0 Loss 0.0002 Accuracy 0.3447\n",
      "Epoch 757 Loss 0.0007 Accuracy 0.3578\n",
      "Time taken for 1 epoch: 15.020382165908813 secs\n",
      "\n",
      "Epoch 758 Batch 0 Loss 0.0031 Accuracy 0.3696\n",
      "Epoch 758 Loss 0.0007 Accuracy 0.3560\n",
      "Time taken for 1 epoch: 14.827739477157593 secs\n",
      "\n",
      "Epoch 759 Batch 0 Loss 0.0000 Accuracy 0.2656\n",
      "Epoch 759 Loss 0.0011 Accuracy 0.3598\n",
      "Time taken for 1 epoch: 14.604850053787231 secs\n",
      "\n",
      "Epoch 760 Batch 0 Loss 0.0000 Accuracy 0.3290\n",
      "Saving checkpoint for epoch 760 at ./checkpoints/train/ckpt-156\n",
      "Epoch 760 Loss 0.0009 Accuracy 0.3605\n",
      "Time taken for 1 epoch: 14.983283519744873 secs\n",
      "\n",
      "Epoch 761 Batch 0 Loss 0.0005 Accuracy 0.4434\n",
      "Epoch 761 Loss 0.0010 Accuracy 0.3559\n",
      "Time taken for 1 epoch: 15.45398736000061 secs\n",
      "\n",
      "Epoch 762 Batch 0 Loss 0.0005 Accuracy 0.4052\n",
      "Epoch 762 Loss 0.0013 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 15.605238676071167 secs\n",
      "\n",
      "Epoch 763 Batch 0 Loss 0.0001 Accuracy 0.3810\n",
      "Epoch 763 Loss 0.0010 Accuracy 0.3578\n",
      "Time taken for 1 epoch: 15.790587186813354 secs\n",
      "\n",
      "Epoch 764 Batch 0 Loss 0.0001 Accuracy 0.2903\n",
      "Epoch 764 Loss 0.0007 Accuracy 0.3551\n",
      "Time taken for 1 epoch: 14.983479022979736 secs\n",
      "\n",
      "Epoch 765 Batch 0 Loss 0.0005 Accuracy 0.3927\n",
      "Saving checkpoint for epoch 765 at ./checkpoints/train/ckpt-157\n",
      "Epoch 765 Loss 0.0007 Accuracy 0.3597\n",
      "Time taken for 1 epoch: 15.253563165664673 secs\n",
      "\n",
      "Epoch 766 Batch 0 Loss 0.0003 Accuracy 0.3357\n",
      "Epoch 766 Loss 0.0009 Accuracy 0.3586\n",
      "Time taken for 1 epoch: 14.746721029281616 secs\n",
      "\n",
      "Epoch 767 Batch 0 Loss 0.0001 Accuracy 0.3585\n",
      "Epoch 767 Loss 0.0006 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 15.006447315216064 secs\n",
      "\n",
      "Epoch 768 Batch 0 Loss 0.0006 Accuracy 0.4554\n",
      "Epoch 768 Loss 0.0008 Accuracy 0.3605\n",
      "Time taken for 1 epoch: 14.664017915725708 secs\n",
      "\n",
      "Epoch 769 Batch 0 Loss 0.0001 Accuracy 0.4084\n",
      "Epoch 769 Loss 0.0013 Accuracy 0.3588\n",
      "Time taken for 1 epoch: 14.904929637908936 secs\n",
      "\n",
      "Epoch 770 Batch 0 Loss 0.0015 Accuracy 0.4235\n",
      "Saving checkpoint for epoch 770 at ./checkpoints/train/ckpt-158\n",
      "Epoch 770 Loss 0.0008 Accuracy 0.3596\n",
      "Time taken for 1 epoch: 15.161289930343628 secs\n",
      "\n",
      "Epoch 771 Batch 0 Loss 0.0001 Accuracy 0.3233\n",
      "Epoch 771 Loss 0.0004 Accuracy 0.3572\n",
      "Time taken for 1 epoch: 14.643090963363647 secs\n",
      "\n",
      "Epoch 772 Batch 0 Loss 0.0009 Accuracy 0.3184\n",
      "Epoch 772 Loss 0.0003 Accuracy 0.3522\n",
      "Time taken for 1 epoch: 15.253655433654785 secs\n",
      "\n",
      "Epoch 773 Batch 0 Loss 0.0005 Accuracy 0.3545\n",
      "Epoch 773 Loss 0.0009 Accuracy 0.3521\n",
      "Time taken for 1 epoch: 15.050495386123657 secs\n",
      "\n",
      "Epoch 774 Batch 0 Loss 0.0005 Accuracy 0.3696\n",
      "Epoch 774 Loss 0.0013 Accuracy 0.3535\n",
      "Time taken for 1 epoch: 15.003536939620972 secs\n",
      "\n",
      "Epoch 775 Batch 0 Loss 0.0001 Accuracy 0.3912\n",
      "Saving checkpoint for epoch 775 at ./checkpoints/train/ckpt-159\n",
      "Epoch 775 Loss 0.0012 Accuracy 0.3601\n",
      "Time taken for 1 epoch: 15.363629817962646 secs\n",
      "\n",
      "Epoch 776 Batch 0 Loss 0.0011 Accuracy 0.3772\n",
      "Epoch 776 Loss 0.0004 Accuracy 0.3526\n",
      "Time taken for 1 epoch: 14.796732425689697 secs\n",
      "\n",
      "Epoch 777 Batch 0 Loss 0.0006 Accuracy 0.3401\n",
      "Epoch 777 Loss 0.0007 Accuracy 0.3681\n",
      "Time taken for 1 epoch: 14.491222143173218 secs\n",
      "\n",
      "Epoch 778 Batch 0 Loss 0.0001 Accuracy 0.4181\n",
      "Epoch 778 Loss 0.0014 Accuracy 0.3639\n",
      "Time taken for 1 epoch: 14.601219892501831 secs\n",
      "\n",
      "Epoch 779 Batch 0 Loss 0.0001 Accuracy 0.3906\n",
      "Epoch 779 Loss 0.0009 Accuracy 0.3537\n",
      "Time taken for 1 epoch: 14.973061800003052 secs\n",
      "\n",
      "Epoch 780 Batch 0 Loss 0.0003 Accuracy 0.4018\n",
      "Saving checkpoint for epoch 780 at ./checkpoints/train/ckpt-160\n",
      "Epoch 780 Loss 0.0007 Accuracy 0.3562\n",
      "Time taken for 1 epoch: 15.287747144699097 secs\n",
      "\n",
      "Epoch 781 Batch 0 Loss 0.0001 Accuracy 0.4375\n",
      "Epoch 781 Loss 0.0008 Accuracy 0.3601\n",
      "Time taken for 1 epoch: 14.621073961257935 secs\n",
      "\n",
      "Epoch 782 Batch 0 Loss 0.0001 Accuracy 0.3438\n",
      "Epoch 782 Loss 0.0008 Accuracy 0.3592\n",
      "Time taken for 1 epoch: 14.8981294631958 secs\n",
      "\n",
      "Epoch 783 Batch 0 Loss 0.0002 Accuracy 0.3349\n",
      "Epoch 783 Loss 0.0009 Accuracy 0.3591\n",
      "Time taken for 1 epoch: 15.139385223388672 secs\n",
      "\n",
      "Epoch 784 Batch 0 Loss 0.0000 Accuracy 0.4149\n",
      "Epoch 784 Loss 0.0012 Accuracy 0.3562\n",
      "Time taken for 1 epoch: 14.738998889923096 secs\n",
      "\n",
      "Epoch 785 Batch 0 Loss 0.0006 Accuracy 0.3598\n",
      "Saving checkpoint for epoch 785 at ./checkpoints/train/ckpt-161\n",
      "Epoch 785 Loss 0.0009 Accuracy 0.3556\n",
      "Time taken for 1 epoch: 15.283810138702393 secs\n",
      "\n",
      "Epoch 786 Batch 0 Loss 0.0004 Accuracy 0.3342\n",
      "Epoch 786 Loss 0.0007 Accuracy 0.3625\n",
      "Time taken for 1 epoch: 14.472569942474365 secs\n",
      "\n",
      "Epoch 787 Batch 0 Loss 0.0000 Accuracy 0.3205\n",
      "Epoch 787 Loss 0.0004 Accuracy 0.3534\n",
      "Time taken for 1 epoch: 15.30882215499878 secs\n",
      "\n",
      "Epoch 788 Batch 0 Loss 0.0122 Accuracy 0.3656\n",
      "Epoch 788 Loss 0.0014 Accuracy 0.3593\n",
      "Time taken for 1 epoch: 14.912545680999756 secs\n",
      "\n",
      "Epoch 789 Batch 0 Loss 0.0010 Accuracy 0.3866\n",
      "Epoch 789 Loss 0.0016 Accuracy 0.3593\n",
      "Time taken for 1 epoch: 14.838761568069458 secs\n",
      "\n",
      "Epoch 790 Batch 0 Loss 0.0019 Accuracy 0.3513\n",
      "Saving checkpoint for epoch 790 at ./checkpoints/train/ckpt-162\n",
      "Epoch 790 Loss 0.0009 Accuracy 0.3568\n",
      "Time taken for 1 epoch: 15.263263940811157 secs\n",
      "\n",
      "Epoch 791 Batch 0 Loss 0.0043 Accuracy 0.4234\n",
      "Epoch 791 Loss 0.0012 Accuracy 0.3550\n",
      "Time taken for 1 epoch: 14.881481647491455 secs\n",
      "\n",
      "Epoch 792 Batch 0 Loss 0.0001 Accuracy 0.4219\n",
      "Epoch 792 Loss 0.0008 Accuracy 0.3506\n",
      "Time taken for 1 epoch: 15.029973030090332 secs\n",
      "\n",
      "Epoch 793 Batch 0 Loss 0.0001 Accuracy 0.3100\n",
      "Epoch 793 Loss 0.0009 Accuracy 0.3508\n",
      "Time taken for 1 epoch: 15.199700355529785 secs\n",
      "\n",
      "Epoch 794 Batch 0 Loss 0.0000 Accuracy 0.4185\n",
      "Epoch 794 Loss 0.0008 Accuracy 0.3620\n",
      "Time taken for 1 epoch: 14.833118200302124 secs\n",
      "\n",
      "Epoch 795 Batch 0 Loss 0.0013 Accuracy 0.4186\n",
      "Saving checkpoint for epoch 795 at ./checkpoints/train/ckpt-163\n",
      "Epoch 795 Loss 0.0011 Accuracy 0.3600\n",
      "Time taken for 1 epoch: 14.971166133880615 secs\n",
      "\n",
      "Epoch 796 Batch 0 Loss 0.0002 Accuracy 0.2986\n",
      "Epoch 796 Loss 0.0008 Accuracy 0.3558\n",
      "Time taken for 1 epoch: 14.7649085521698 secs\n",
      "\n",
      "Epoch 797 Batch 0 Loss 0.0057 Accuracy 0.3482\n",
      "Epoch 797 Loss 0.0010 Accuracy 0.3695\n",
      "Time taken for 1 epoch: 14.494832038879395 secs\n",
      "\n",
      "Epoch 798 Batch 0 Loss 0.0026 Accuracy 0.3226\n",
      "Epoch 798 Loss 0.0007 Accuracy 0.3589\n",
      "Time taken for 1 epoch: 14.60151743888855 secs\n",
      "\n",
      "Epoch 799 Batch 0 Loss 0.0007 Accuracy 0.4025\n",
      "Epoch 799 Loss 0.0006 Accuracy 0.3604\n",
      "Time taken for 1 epoch: 14.57913851737976 secs\n",
      "\n",
      "Epoch 800 Batch 0 Loss 0.0003 Accuracy 0.3011\n",
      "Saving checkpoint for epoch 800 at ./checkpoints/train/ckpt-164\n",
      "Epoch 800 Loss 0.0011 Accuracy 0.3581\n",
      "Time taken for 1 epoch: 15.208598375320435 secs\n",
      "\n",
      "Epoch 801 Batch 0 Loss 0.0000 Accuracy 0.3207\n",
      "Epoch 801 Loss 0.0008 Accuracy 0.3538\n",
      "Time taken for 1 epoch: 14.789817571640015 secs\n",
      "\n",
      "Epoch 802 Batch 0 Loss 0.0002 Accuracy 0.3290\n",
      "Epoch 802 Loss 0.0010 Accuracy 0.3595\n",
      "Time taken for 1 epoch: 14.98982310295105 secs\n",
      "\n",
      "Epoch 803 Batch 0 Loss 0.0001 Accuracy 0.3277\n",
      "Epoch 803 Loss 0.0005 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 16.34598135948181 secs\n",
      "\n",
      "Epoch 804 Batch 0 Loss 0.0002 Accuracy 0.4152\n",
      "Epoch 804 Loss 0.0009 Accuracy 0.3624\n",
      "Time taken for 1 epoch: 15.457447528839111 secs\n",
      "\n",
      "Epoch 805 Batch 0 Loss 0.0001 Accuracy 0.3922\n",
      "Saving checkpoint for epoch 805 at ./checkpoints/train/ckpt-165\n",
      "Epoch 805 Loss 0.0010 Accuracy 0.3630\n",
      "Time taken for 1 epoch: 15.115066289901733 secs\n",
      "\n",
      "Epoch 806 Batch 0 Loss 0.0003 Accuracy 0.3912\n",
      "Epoch 806 Loss 0.0009 Accuracy 0.3550\n",
      "Time taken for 1 epoch: 14.967390775680542 secs\n",
      "\n",
      "Epoch 807 Batch 0 Loss 0.0001 Accuracy 0.3922\n",
      "Epoch 807 Loss 0.0005 Accuracy 0.3607\n",
      "Time taken for 1 epoch: 14.659834146499634 secs\n",
      "\n",
      "Epoch 808 Batch 0 Loss 0.0000 Accuracy 0.3459\n",
      "Epoch 808 Loss 0.0006 Accuracy 0.3559\n",
      "Time taken for 1 epoch: 15.056771755218506 secs\n",
      "\n",
      "Epoch 809 Batch 0 Loss 0.0001 Accuracy 0.3329\n",
      "Epoch 809 Loss 0.0007 Accuracy 0.3508\n",
      "Time taken for 1 epoch: 15.023282766342163 secs\n",
      "\n",
      "Epoch 810 Batch 0 Loss 0.0003 Accuracy 0.3464\n",
      "Saving checkpoint for epoch 810 at ./checkpoints/train/ckpt-166\n",
      "Epoch 810 Loss 0.0006 Accuracy 0.3579\n",
      "Time taken for 1 epoch: 15.265541791915894 secs\n",
      "\n",
      "Epoch 811 Batch 0 Loss 0.0000 Accuracy 0.2604\n",
      "Epoch 811 Loss 0.0004 Accuracy 0.3499\n",
      "Time taken for 1 epoch: 15.226794242858887 secs\n",
      "\n",
      "Epoch 812 Batch 0 Loss 0.0000 Accuracy 0.3603\n",
      "Epoch 812 Loss 0.0004 Accuracy 0.3588\n",
      "Time taken for 1 epoch: 14.856929063796997 secs\n",
      "\n",
      "Epoch 813 Batch 0 Loss 0.0026 Accuracy 0.3750\n",
      "Epoch 813 Loss 0.0005 Accuracy 0.3607\n",
      "Time taken for 1 epoch: 14.818014144897461 secs\n",
      "\n",
      "Epoch 814 Batch 0 Loss 0.0015 Accuracy 0.3621\n",
      "Epoch 814 Loss 0.0007 Accuracy 0.3615\n",
      "Time taken for 1 epoch: 14.680582046508789 secs\n",
      "\n",
      "Epoch 815 Batch 0 Loss 0.0000 Accuracy 0.3447\n",
      "Saving checkpoint for epoch 815 at ./checkpoints/train/ckpt-167\n",
      "Epoch 815 Loss 0.0012 Accuracy 0.3647\n",
      "Time taken for 1 epoch: 15.105621576309204 secs\n",
      "\n",
      "Epoch 816 Batch 0 Loss 0.0004 Accuracy 0.3446\n",
      "Epoch 816 Loss 0.0006 Accuracy 0.3601\n",
      "Time taken for 1 epoch: 14.528762340545654 secs\n",
      "\n",
      "Epoch 817 Batch 0 Loss 0.0015 Accuracy 0.3170\n",
      "Epoch 817 Loss 0.0009 Accuracy 0.3597\n",
      "Time taken for 1 epoch: 15.071582555770874 secs\n",
      "\n",
      "Epoch 818 Batch 0 Loss 0.0032 Accuracy 0.3134\n",
      "Epoch 818 Loss 0.0008 Accuracy 0.3550\n",
      "Time taken for 1 epoch: 14.922630071640015 secs\n",
      "\n",
      "Epoch 819 Batch 0 Loss 0.0001 Accuracy 0.4150\n",
      "Epoch 819 Loss 0.0009 Accuracy 0.3581\n",
      "Time taken for 1 epoch: 14.898559093475342 secs\n",
      "\n",
      "Epoch 820 Batch 0 Loss 0.0003 Accuracy 0.3486\n",
      "Saving checkpoint for epoch 820 at ./checkpoints/train/ckpt-168\n",
      "Epoch 820 Loss 0.0015 Accuracy 0.3567\n",
      "Time taken for 1 epoch: 15.503986597061157 secs\n",
      "\n",
      "Epoch 821 Batch 0 Loss 0.0032 Accuracy 0.3831\n",
      "Epoch 821 Loss 0.0009 Accuracy 0.3583\n",
      "Time taken for 1 epoch: 14.792568445205688 secs\n",
      "\n",
      "Epoch 822 Batch 0 Loss 0.0001 Accuracy 0.3290\n",
      "Epoch 822 Loss 0.0011 Accuracy 0.3587\n",
      "Time taken for 1 epoch: 14.767236709594727 secs\n",
      "\n",
      "Epoch 823 Batch 0 Loss 0.0016 Accuracy 0.3728\n",
      "Epoch 823 Loss 0.0009 Accuracy 0.3634\n",
      "Time taken for 1 epoch: 14.751730680465698 secs\n",
      "\n",
      "Epoch 824 Batch 0 Loss 0.0000 Accuracy 0.3569\n",
      "Epoch 824 Loss 0.0007 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 14.695106506347656 secs\n",
      "\n",
      "Epoch 825 Batch 0 Loss 0.0000 Accuracy 0.3693\n",
      "Saving checkpoint for epoch 825 at ./checkpoints/train/ckpt-169\n",
      "Epoch 825 Loss 0.0004 Accuracy 0.3543\n",
      "Time taken for 1 epoch: 15.575025081634521 secs\n",
      "\n",
      "Epoch 826 Batch 0 Loss 0.0016 Accuracy 0.4128\n",
      "Epoch 826 Loss 0.0006 Accuracy 0.3623\n",
      "Time taken for 1 epoch: 14.462934494018555 secs\n",
      "\n",
      "Epoch 827 Batch 0 Loss 0.0011 Accuracy 0.3901\n",
      "Epoch 827 Loss 0.0009 Accuracy 0.3559\n",
      "Time taken for 1 epoch: 14.994288921356201 secs\n",
      "\n",
      "Epoch 828 Batch 0 Loss 0.0000 Accuracy 0.3945\n",
      "Epoch 828 Loss 0.0013 Accuracy 0.3565\n",
      "Time taken for 1 epoch: 14.745357990264893 secs\n",
      "\n",
      "Epoch 829 Batch 0 Loss 0.0004 Accuracy 0.3978\n",
      "Epoch 829 Loss 0.0009 Accuracy 0.3574\n",
      "Time taken for 1 epoch: 14.800121545791626 secs\n",
      "\n",
      "Epoch 830 Batch 0 Loss 0.0001 Accuracy 0.3225\n",
      "Saving checkpoint for epoch 830 at ./checkpoints/train/ckpt-170\n",
      "Epoch 830 Loss 0.0013 Accuracy 0.3612\n",
      "Time taken for 1 epoch: 15.179564952850342 secs\n",
      "\n",
      "Epoch 831 Batch 0 Loss 0.0002 Accuracy 0.3450\n",
      "Epoch 831 Loss 0.0006 Accuracy 0.3597\n",
      "Time taken for 1 epoch: 14.625415563583374 secs\n",
      "\n",
      "Epoch 832 Batch 0 Loss 0.0029 Accuracy 0.3121\n",
      "Epoch 832 Loss 0.0010 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 14.860181331634521 secs\n",
      "\n",
      "Epoch 833 Batch 0 Loss 0.0004 Accuracy 0.3637\n",
      "Epoch 833 Loss 0.0007 Accuracy 0.3614\n",
      "Time taken for 1 epoch: 14.508463382720947 secs\n",
      "\n",
      "Epoch 834 Batch 0 Loss 0.0008 Accuracy 0.3496\n",
      "Epoch 834 Loss 0.0010 Accuracy 0.3551\n",
      "Time taken for 1 epoch: 14.908677101135254 secs\n",
      "\n",
      "Epoch 835 Batch 0 Loss 0.0003 Accuracy 0.3940\n",
      "Saving checkpoint for epoch 835 at ./checkpoints/train/ckpt-171\n",
      "Epoch 835 Loss 0.0011 Accuracy 0.3575\n",
      "Time taken for 1 epoch: 15.49314284324646 secs\n",
      "\n",
      "Epoch 836 Batch 0 Loss 0.0033 Accuracy 0.4135\n",
      "Epoch 836 Loss 0.0006 Accuracy 0.3620\n",
      "Time taken for 1 epoch: 14.825700521469116 secs\n",
      "\n",
      "Epoch 837 Batch 0 Loss 0.0001 Accuracy 0.3842\n",
      "Epoch 837 Loss 0.0007 Accuracy 0.3553\n",
      "Time taken for 1 epoch: 15.245280981063843 secs\n",
      "\n",
      "Epoch 838 Batch 0 Loss 0.0010 Accuracy 0.4558\n",
      "Epoch 838 Loss 0.0004 Accuracy 0.3510\n",
      "Time taken for 1 epoch: 15.10072946548462 secs\n",
      "\n",
      "Epoch 839 Batch 0 Loss 0.0030 Accuracy 0.4688\n",
      "Epoch 839 Loss 0.0008 Accuracy 0.3584\n",
      "Time taken for 1 epoch: 14.914852380752563 secs\n",
      "\n",
      "Epoch 840 Batch 0 Loss 0.0039 Accuracy 0.3478\n",
      "Saving checkpoint for epoch 840 at ./checkpoints/train/ckpt-172\n",
      "Epoch 840 Loss 0.0013 Accuracy 0.3600\n",
      "Time taken for 1 epoch: 15.243592500686646 secs\n",
      "\n",
      "Epoch 841 Batch 0 Loss 0.0003 Accuracy 0.4604\n",
      "Epoch 841 Loss 0.0011 Accuracy 0.3565\n",
      "Time taken for 1 epoch: 14.825357675552368 secs\n",
      "\n",
      "Epoch 842 Batch 0 Loss 0.0026 Accuracy 0.3628\n",
      "Epoch 842 Loss 0.0009 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 14.926663398742676 secs\n",
      "\n",
      "Epoch 843 Batch 0 Loss 0.0001 Accuracy 0.3108\n",
      "Epoch 843 Loss 0.0010 Accuracy 0.3612\n",
      "Time taken for 1 epoch: 15.472790479660034 secs\n",
      "\n",
      "Epoch 844 Batch 0 Loss 0.0017 Accuracy 0.3750\n",
      "Epoch 844 Loss 0.0007 Accuracy 0.3535\n",
      "Time taken for 1 epoch: 14.999882936477661 secs\n",
      "\n",
      "Epoch 845 Batch 0 Loss 0.0006 Accuracy 0.3463\n",
      "Saving checkpoint for epoch 845 at ./checkpoints/train/ckpt-173\n",
      "Epoch 845 Loss 0.0010 Accuracy 0.3645\n",
      "Time taken for 1 epoch: 15.684690713882446 secs\n",
      "\n",
      "Epoch 846 Batch 0 Loss 0.0001 Accuracy 0.3337\n",
      "Epoch 846 Loss 0.0008 Accuracy 0.3618\n",
      "Time taken for 1 epoch: 14.688296556472778 secs\n",
      "\n",
      "Epoch 847 Batch 0 Loss 0.0001 Accuracy 0.3598\n",
      "Epoch 847 Loss 0.0006 Accuracy 0.3621\n",
      "Time taken for 1 epoch: 14.761094331741333 secs\n",
      "\n",
      "Epoch 848 Batch 0 Loss 0.0002 Accuracy 0.3990\n",
      "Epoch 848 Loss 0.0008 Accuracy 0.3630\n",
      "Time taken for 1 epoch: 14.538702726364136 secs\n",
      "\n",
      "Epoch 849 Batch 0 Loss 0.0055 Accuracy 0.3429\n",
      "Epoch 849 Loss 0.0010 Accuracy 0.3617\n",
      "Time taken for 1 epoch: 14.792810201644897 secs\n",
      "\n",
      "Epoch 850 Batch 0 Loss 0.0004 Accuracy 0.3377\n",
      "Saving checkpoint for epoch 850 at ./checkpoints/train/ckpt-174\n",
      "Epoch 850 Loss 0.0008 Accuracy 0.3537\n",
      "Time taken for 1 epoch: 15.495226860046387 secs\n",
      "\n",
      "Epoch 851 Batch 0 Loss 0.0001 Accuracy 0.3290\n",
      "Epoch 851 Loss 0.0009 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 15.051462650299072 secs\n",
      "\n",
      "Epoch 852 Batch 0 Loss 0.0001 Accuracy 0.4002\n",
      "Epoch 852 Loss 0.0011 Accuracy 0.3597\n",
      "Time taken for 1 epoch: 14.75076961517334 secs\n",
      "\n",
      "Epoch 853 Batch 0 Loss 0.0001 Accuracy 0.3401\n",
      "Epoch 853 Loss 0.0015 Accuracy 0.3618\n",
      "Time taken for 1 epoch: 14.944748878479004 secs\n",
      "\n",
      "Epoch 854 Batch 0 Loss 0.0002 Accuracy 0.4014\n",
      "Epoch 854 Loss 0.0010 Accuracy 0.3569\n",
      "Time taken for 1 epoch: 14.969202756881714 secs\n",
      "\n",
      "Epoch 855 Batch 0 Loss 0.0068 Accuracy 0.3370\n",
      "Saving checkpoint for epoch 855 at ./checkpoints/train/ckpt-175\n",
      "Epoch 855 Loss 0.0012 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 15.477540254592896 secs\n",
      "\n",
      "Epoch 856 Batch 0 Loss 0.0000 Accuracy 0.3982\n",
      "Epoch 856 Loss 0.0004 Accuracy 0.3581\n",
      "Time taken for 1 epoch: 14.673461198806763 secs\n",
      "\n",
      "Epoch 857 Batch 0 Loss 0.0000 Accuracy 0.3049\n",
      "Epoch 857 Loss 0.0008 Accuracy 0.3595\n",
      "Time taken for 1 epoch: 15.050625801086426 secs\n",
      "\n",
      "Epoch 858 Batch 0 Loss 0.0022 Accuracy 0.3342\n",
      "Epoch 858 Loss 0.0008 Accuracy 0.3569\n",
      "Time taken for 1 epoch: 14.82092809677124 secs\n",
      "\n",
      "Epoch 859 Batch 0 Loss 0.0013 Accuracy 0.3257\n",
      "Epoch 859 Loss 0.0004 Accuracy 0.3608\n",
      "Time taken for 1 epoch: 14.806696653366089 secs\n",
      "\n",
      "Epoch 860 Batch 0 Loss 0.0001 Accuracy 0.3021\n",
      "Saving checkpoint for epoch 860 at ./checkpoints/train/ckpt-176\n",
      "Epoch 860 Loss 0.0006 Accuracy 0.3584\n",
      "Time taken for 1 epoch: 15.424540519714355 secs\n",
      "\n",
      "Epoch 861 Batch 0 Loss 0.0044 Accuracy 0.4413\n",
      "Epoch 861 Loss 0.0010 Accuracy 0.3547\n",
      "Time taken for 1 epoch: 14.90708303451538 secs\n",
      "\n",
      "Epoch 862 Batch 0 Loss 0.0027 Accuracy 0.3615\n",
      "Epoch 862 Loss 0.0009 Accuracy 0.3562\n",
      "Time taken for 1 epoch: 15.059604167938232 secs\n",
      "\n",
      "Epoch 863 Batch 0 Loss 0.0001 Accuracy 0.4129\n",
      "Epoch 863 Loss 0.0010 Accuracy 0.3623\n",
      "Time taken for 1 epoch: 14.977134704589844 secs\n",
      "\n",
      "Epoch 864 Batch 0 Loss 0.0001 Accuracy 0.4131\n",
      "Epoch 864 Loss 0.0010 Accuracy 0.3626\n",
      "Time taken for 1 epoch: 14.491419792175293 secs\n",
      "\n",
      "Epoch 865 Batch 0 Loss 0.0035 Accuracy 0.3241\n",
      "Saving checkpoint for epoch 865 at ./checkpoints/train/ckpt-177\n",
      "Epoch 865 Loss 0.0016 Accuracy 0.3573\n",
      "Time taken for 1 epoch: 15.339101314544678 secs\n",
      "\n",
      "Epoch 866 Batch 0 Loss 0.0008 Accuracy 0.3634\n",
      "Epoch 866 Loss 0.0012 Accuracy 0.3613\n",
      "Time taken for 1 epoch: 14.659491062164307 secs\n",
      "\n",
      "Epoch 867 Batch 0 Loss 0.0001 Accuracy 0.3604\n",
      "Epoch 867 Loss 0.0008 Accuracy 0.3564\n",
      "Time taken for 1 epoch: 14.833979368209839 secs\n",
      "\n",
      "Epoch 868 Batch 0 Loss 0.0000 Accuracy 0.3609\n",
      "Epoch 868 Loss 0.0008 Accuracy 0.3521\n",
      "Time taken for 1 epoch: 15.01319146156311 secs\n",
      "\n",
      "Epoch 869 Batch 0 Loss 0.0004 Accuracy 0.3333\n",
      "Epoch 869 Loss 0.0011 Accuracy 0.3525\n",
      "Time taken for 1 epoch: 15.354873657226562 secs\n",
      "\n",
      "Epoch 870 Batch 0 Loss 0.0005 Accuracy 0.3546\n",
      "Saving checkpoint for epoch 870 at ./checkpoints/train/ckpt-178\n",
      "Epoch 870 Loss 0.0008 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 15.31102466583252 secs\n",
      "\n",
      "Epoch 871 Batch 0 Loss 0.0001 Accuracy 0.3957\n",
      "Epoch 871 Loss 0.0005 Accuracy 0.3617\n",
      "Time taken for 1 epoch: 14.652675867080688 secs\n",
      "\n",
      "Epoch 872 Batch 0 Loss 0.0000 Accuracy 0.3193\n",
      "Epoch 872 Loss 0.0010 Accuracy 0.3570\n",
      "Time taken for 1 epoch: 14.998393774032593 secs\n",
      "\n",
      "Epoch 873 Batch 0 Loss 0.0002 Accuracy 0.4019\n",
      "Epoch 873 Loss 0.0011 Accuracy 0.3574\n",
      "Time taken for 1 epoch: 14.829699277877808 secs\n",
      "\n",
      "Epoch 874 Batch 0 Loss 0.0026 Accuracy 0.3704\n",
      "Epoch 874 Loss 0.0013 Accuracy 0.3559\n",
      "Time taken for 1 epoch: 14.936622858047485 secs\n",
      "\n",
      "Epoch 875 Batch 0 Loss 0.0011 Accuracy 0.3294\n",
      "Saving checkpoint for epoch 875 at ./checkpoints/train/ckpt-179\n",
      "Epoch 875 Loss 0.0009 Accuracy 0.3612\n",
      "Time taken for 1 epoch: 15.347430229187012 secs\n",
      "\n",
      "Epoch 876 Batch 0 Loss 0.0002 Accuracy 0.3412\n",
      "Epoch 876 Loss 0.0005 Accuracy 0.3513\n",
      "Time taken for 1 epoch: 14.927844762802124 secs\n",
      "\n",
      "Epoch 877 Batch 0 Loss 0.0002 Accuracy 0.3514\n",
      "Epoch 877 Loss 0.0005 Accuracy 0.3622\n",
      "Time taken for 1 epoch: 14.848132133483887 secs\n",
      "\n",
      "Epoch 878 Batch 0 Loss 0.0001 Accuracy 0.3262\n",
      "Epoch 878 Loss 0.0010 Accuracy 0.3645\n",
      "Time taken for 1 epoch: 14.42453670501709 secs\n",
      "\n",
      "Epoch 879 Batch 0 Loss 0.0001 Accuracy 0.3545\n",
      "Epoch 879 Loss 0.0007 Accuracy 0.3587\n",
      "Time taken for 1 epoch: 14.69752287864685 secs\n",
      "\n",
      "Epoch 880 Batch 0 Loss 0.0001 Accuracy 0.3416\n",
      "Saving checkpoint for epoch 880 at ./checkpoints/train/ckpt-180\n",
      "Epoch 880 Loss 0.0008 Accuracy 0.3575\n",
      "Time taken for 1 epoch: 15.320122480392456 secs\n",
      "\n",
      "Epoch 881 Batch 0 Loss 0.0017 Accuracy 0.4058\n",
      "Epoch 881 Loss 0.0003 Accuracy 0.3596\n",
      "Time taken for 1 epoch: 14.517664670944214 secs\n",
      "\n",
      "Epoch 882 Batch 0 Loss 0.0000 Accuracy 0.3281\n",
      "Epoch 882 Loss 0.0010 Accuracy 0.3518\n",
      "Time taken for 1 epoch: 15.080515623092651 secs\n",
      "\n",
      "Epoch 883 Batch 0 Loss 0.0001 Accuracy 0.4028\n",
      "Epoch 883 Loss 0.0017 Accuracy 0.3551\n",
      "Time taken for 1 epoch: 16.106229305267334 secs\n",
      "\n",
      "Epoch 884 Batch 0 Loss 0.0005 Accuracy 0.4406\n",
      "Epoch 884 Loss 0.0009 Accuracy 0.3653\n",
      "Time taken for 1 epoch: 15.872359275817871 secs\n",
      "\n",
      "Epoch 885 Batch 0 Loss 0.0001 Accuracy 0.3214\n",
      "Saving checkpoint for epoch 885 at ./checkpoints/train/ckpt-181\n",
      "Epoch 885 Loss 0.0009 Accuracy 0.3560\n",
      "Time taken for 1 epoch: 15.538053750991821 secs\n",
      "\n",
      "Epoch 886 Batch 0 Loss 0.0000 Accuracy 0.3911\n",
      "Epoch 886 Loss 0.0010 Accuracy 0.3607\n",
      "Time taken for 1 epoch: 14.894991397857666 secs\n",
      "\n",
      "Epoch 887 Batch 0 Loss 0.0016 Accuracy 0.3312\n",
      "Epoch 887 Loss 0.0004 Accuracy 0.3592\n",
      "Time taken for 1 epoch: 14.734517335891724 secs\n",
      "\n",
      "Epoch 888 Batch 0 Loss 0.0027 Accuracy 0.3977\n",
      "Epoch 888 Loss 0.0005 Accuracy 0.3611\n",
      "Time taken for 1 epoch: 14.802125215530396 secs\n",
      "\n",
      "Epoch 889 Batch 0 Loss 0.0000 Accuracy 0.3454\n",
      "Epoch 889 Loss 0.0003 Accuracy 0.3588\n",
      "Time taken for 1 epoch: 14.809680223464966 secs\n",
      "\n",
      "Epoch 890 Batch 0 Loss 0.0002 Accuracy 0.3714\n",
      "Saving checkpoint for epoch 890 at ./checkpoints/train/ckpt-182\n",
      "Epoch 890 Loss 0.0006 Accuracy 0.3605\n",
      "Time taken for 1 epoch: 15.045711994171143 secs\n",
      "\n",
      "Epoch 891 Batch 0 Loss 0.0005 Accuracy 0.3203\n",
      "Epoch 891 Loss 0.0012 Accuracy 0.3511\n",
      "Time taken for 1 epoch: 15.023834705352783 secs\n",
      "\n",
      "Epoch 892 Batch 0 Loss 0.0040 Accuracy 0.3560\n",
      "Epoch 892 Loss 0.0008 Accuracy 0.3534\n",
      "Time taken for 1 epoch: 15.074802160263062 secs\n",
      "\n",
      "Epoch 893 Batch 0 Loss 0.0004 Accuracy 0.3816\n",
      "Epoch 893 Loss 0.0005 Accuracy 0.3521\n",
      "Time taken for 1 epoch: 15.00732707977295 secs\n",
      "\n",
      "Epoch 894 Batch 0 Loss 0.0001 Accuracy 0.3454\n",
      "Epoch 894 Loss 0.0012 Accuracy 0.3544\n",
      "Time taken for 1 epoch: 15.053373575210571 secs\n",
      "\n",
      "Epoch 895 Batch 0 Loss 0.0001 Accuracy 0.3764\n",
      "Saving checkpoint for epoch 895 at ./checkpoints/train/ckpt-183\n",
      "Epoch 895 Loss 0.0009 Accuracy 0.3620\n",
      "Time taken for 1 epoch: 15.095745086669922 secs\n",
      "\n",
      "Epoch 896 Batch 0 Loss 0.0013 Accuracy 0.3209\n",
      "Epoch 896 Loss 0.0012 Accuracy 0.3551\n",
      "Time taken for 1 epoch: 14.813663959503174 secs\n",
      "\n",
      "Epoch 897 Batch 0 Loss 0.0005 Accuracy 0.3589\n",
      "Epoch 897 Loss 0.0005 Accuracy 0.3595\n",
      "Time taken for 1 epoch: 14.928164958953857 secs\n",
      "\n",
      "Epoch 898 Batch 0 Loss 0.0000 Accuracy 0.3028\n",
      "Epoch 898 Loss 0.0009 Accuracy 0.3564\n",
      "Time taken for 1 epoch: 14.807986497879028 secs\n",
      "\n",
      "Epoch 899 Batch 0 Loss 0.0001 Accuracy 0.3433\n",
      "Epoch 899 Loss 0.0009 Accuracy 0.3553\n",
      "Time taken for 1 epoch: 14.981969594955444 secs\n",
      "\n",
      "Epoch 900 Batch 0 Loss 0.0003 Accuracy 0.2869\n",
      "Saving checkpoint for epoch 900 at ./checkpoints/train/ckpt-184\n",
      "Epoch 900 Loss 0.0012 Accuracy 0.3493\n",
      "Time taken for 1 epoch: 16.00054955482483 secs\n",
      "\n",
      "Epoch 901 Batch 0 Loss 0.0005 Accuracy 0.3921\n",
      "Epoch 901 Loss 0.0016 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 14.905030488967896 secs\n",
      "\n",
      "Epoch 902 Batch 0 Loss 0.0003 Accuracy 0.3217\n",
      "Epoch 902 Loss 0.0009 Accuracy 0.3518\n",
      "Time taken for 1 epoch: 15.64102840423584 secs\n",
      "\n",
      "Epoch 903 Batch 0 Loss 0.0014 Accuracy 0.3188\n",
      "Epoch 903 Loss 0.0014 Accuracy 0.3525\n",
      "Time taken for 1 epoch: 15.038674354553223 secs\n",
      "\n",
      "Epoch 904 Batch 0 Loss 0.0000 Accuracy 0.3772\n",
      "Epoch 904 Loss 0.0009 Accuracy 0.3605\n",
      "Time taken for 1 epoch: 15.014984130859375 secs\n",
      "\n",
      "Epoch 905 Batch 0 Loss 0.0001 Accuracy 0.3091\n",
      "Saving checkpoint for epoch 905 at ./checkpoints/train/ckpt-185\n",
      "Epoch 905 Loss 0.0010 Accuracy 0.3598\n",
      "Time taken for 1 epoch: 15.149633646011353 secs\n",
      "\n",
      "Epoch 906 Batch 0 Loss 0.0001 Accuracy 0.3488\n",
      "Epoch 906 Loss 0.0007 Accuracy 0.3504\n",
      "Time taken for 1 epoch: 15.252096176147461 secs\n",
      "\n",
      "Epoch 907 Batch 0 Loss 0.0001 Accuracy 0.3237\n",
      "Epoch 907 Loss 0.0004 Accuracy 0.3618\n",
      "Time taken for 1 epoch: 14.782307386398315 secs\n",
      "\n",
      "Epoch 908 Batch 0 Loss 0.0022 Accuracy 0.3824\n",
      "Epoch 908 Loss 0.0004 Accuracy 0.3598\n",
      "Time taken for 1 epoch: 14.833406925201416 secs\n",
      "\n",
      "Epoch 909 Batch 0 Loss 0.0005 Accuracy 0.4123\n",
      "Epoch 909 Loss 0.0005 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 14.822003364562988 secs\n",
      "\n",
      "Epoch 910 Batch 0 Loss 0.0006 Accuracy 0.3875\n",
      "Saving checkpoint for epoch 910 at ./checkpoints/train/ckpt-186\n",
      "Epoch 910 Loss 0.0010 Accuracy 0.3577\n",
      "Time taken for 1 epoch: 19.274662494659424 secs\n",
      "\n",
      "Epoch 911 Batch 0 Loss 0.0002 Accuracy 0.3736\n",
      "Epoch 911 Loss 0.0011 Accuracy 0.3609\n",
      "Time taken for 1 epoch: 16.591896533966064 secs\n",
      "\n",
      "Epoch 912 Batch 0 Loss 0.0000 Accuracy 0.3944\n",
      "Epoch 912 Loss 0.0007 Accuracy 0.3534\n",
      "Time taken for 1 epoch: 16.358024835586548 secs\n",
      "\n",
      "Epoch 913 Batch 0 Loss 0.0001 Accuracy 0.4564\n",
      "Epoch 913 Loss 0.0009 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 15.097322940826416 secs\n",
      "\n",
      "Epoch 914 Batch 0 Loss 0.0019 Accuracy 0.4365\n",
      "Epoch 914 Loss 0.0009 Accuracy 0.3541\n",
      "Time taken for 1 epoch: 15.661791324615479 secs\n",
      "\n",
      "Epoch 915 Batch 0 Loss 0.0045 Accuracy 0.2964\n",
      "Saving checkpoint for epoch 915 at ./checkpoints/train/ckpt-187\n",
      "Epoch 915 Loss 0.0004 Accuracy 0.3610\n",
      "Time taken for 1 epoch: 16.14879584312439 secs\n",
      "\n",
      "Epoch 916 Batch 0 Loss 0.0001 Accuracy 0.3875\n",
      "Epoch 916 Loss 0.0004 Accuracy 0.3593\n",
      "Time taken for 1 epoch: 14.812770366668701 secs\n",
      "\n",
      "Epoch 917 Batch 0 Loss 0.0002 Accuracy 0.3369\n",
      "Epoch 917 Loss 0.0004 Accuracy 0.3650\n",
      "Time taken for 1 epoch: 14.923563003540039 secs\n",
      "\n",
      "Epoch 918 Batch 0 Loss 0.0000 Accuracy 0.3698\n",
      "Epoch 918 Loss 0.0010 Accuracy 0.3627\n",
      "Time taken for 1 epoch: 14.549713611602783 secs\n",
      "\n",
      "Epoch 919 Batch 0 Loss 0.0008 Accuracy 0.3654\n",
      "Epoch 919 Loss 0.0012 Accuracy 0.3562\n",
      "Time taken for 1 epoch: 14.981406211853027 secs\n",
      "\n",
      "Epoch 920 Batch 0 Loss 0.0002 Accuracy 0.3836\n",
      "Saving checkpoint for epoch 920 at ./checkpoints/train/ckpt-188\n",
      "Epoch 920 Loss 0.0015 Accuracy 0.3587\n",
      "Time taken for 1 epoch: 15.02052116394043 secs\n",
      "\n",
      "Epoch 921 Batch 0 Loss 0.0002 Accuracy 0.3607\n",
      "Epoch 921 Loss 0.0005 Accuracy 0.3633\n",
      "Time taken for 1 epoch: 14.495903730392456 secs\n",
      "\n",
      "Epoch 922 Batch 0 Loss 0.0002 Accuracy 0.4035\n",
      "Epoch 922 Loss 0.0004 Accuracy 0.3595\n",
      "Time taken for 1 epoch: 15.665458679199219 secs\n",
      "\n",
      "Epoch 923 Batch 0 Loss 0.0000 Accuracy 0.3167\n",
      "Epoch 923 Loss 0.0013 Accuracy 0.3486\n",
      "Time taken for 1 epoch: 15.813813209533691 secs\n",
      "\n",
      "Epoch 924 Batch 0 Loss 0.0001 Accuracy 0.3277\n",
      "Epoch 924 Loss 0.0004 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 15.042582511901855 secs\n",
      "\n",
      "Epoch 925 Batch 0 Loss 0.0028 Accuracy 0.3485\n",
      "Saving checkpoint for epoch 925 at ./checkpoints/train/ckpt-189\n",
      "Epoch 925 Loss 0.0008 Accuracy 0.3573\n",
      "Time taken for 1 epoch: 15.535129070281982 secs\n",
      "\n",
      "Epoch 926 Batch 0 Loss 0.0007 Accuracy 0.3496\n",
      "Epoch 926 Loss 0.0010 Accuracy 0.3542\n",
      "Time taken for 1 epoch: 15.314442873001099 secs\n",
      "\n",
      "Epoch 927 Batch 0 Loss 0.0003 Accuracy 0.3936\n",
      "Epoch 927 Loss 0.0008 Accuracy 0.3583\n",
      "Time taken for 1 epoch: 14.840110063552856 secs\n",
      "\n",
      "Epoch 928 Batch 0 Loss 0.0002 Accuracy 0.3514\n",
      "Epoch 928 Loss 0.0004 Accuracy 0.3549\n",
      "Time taken for 1 epoch: 15.24394154548645 secs\n",
      "\n",
      "Epoch 929 Batch 0 Loss 0.0001 Accuracy 0.3692\n",
      "Epoch 929 Loss 0.0008 Accuracy 0.3600\n",
      "Time taken for 1 epoch: 14.747371196746826 secs\n",
      "\n",
      "Epoch 930 Batch 0 Loss 0.0058 Accuracy 0.3503\n",
      "Saving checkpoint for epoch 930 at ./checkpoints/train/ckpt-190\n",
      "Epoch 930 Loss 0.0012 Accuracy 0.3557\n",
      "Time taken for 1 epoch: 15.304307460784912 secs\n",
      "\n",
      "Epoch 931 Batch 0 Loss 0.0008 Accuracy 0.3177\n",
      "Epoch 931 Loss 0.0014 Accuracy 0.3522\n",
      "Time taken for 1 epoch: 15.234044790267944 secs\n",
      "\n",
      "Epoch 932 Batch 0 Loss 0.0014 Accuracy 0.3298\n",
      "Epoch 932 Loss 0.0012 Accuracy 0.3562\n",
      "Time taken for 1 epoch: 15.047165393829346 secs\n",
      "\n",
      "Epoch 933 Batch 0 Loss 0.0019 Accuracy 0.3952\n",
      "Epoch 933 Loss 0.0009 Accuracy 0.3634\n",
      "Time taken for 1 epoch: 14.838462114334106 secs\n",
      "\n",
      "Epoch 934 Batch 0 Loss 0.0016 Accuracy 0.4231\n",
      "Epoch 934 Loss 0.0007 Accuracy 0.3585\n",
      "Time taken for 1 epoch: 15.14324164390564 secs\n",
      "\n",
      "Epoch 935 Batch 0 Loss 0.0083 Accuracy 0.3719\n",
      "Saving checkpoint for epoch 935 at ./checkpoints/train/ckpt-191\n",
      "Epoch 935 Loss 0.0017 Accuracy 0.3524\n",
      "Time taken for 1 epoch: 15.552720785140991 secs\n",
      "\n",
      "Epoch 936 Batch 0 Loss 0.0005 Accuracy 0.3085\n",
      "Epoch 936 Loss 0.0007 Accuracy 0.3535\n",
      "Time taken for 1 epoch: 15.329260110855103 secs\n",
      "\n",
      "Epoch 937 Batch 0 Loss 0.0001 Accuracy 0.3377\n",
      "Epoch 937 Loss 0.0003 Accuracy 0.3560\n",
      "Time taken for 1 epoch: 14.806217193603516 secs\n",
      "\n",
      "Epoch 938 Batch 0 Loss 0.0001 Accuracy 0.3168\n",
      "Epoch 938 Loss 0.0006 Accuracy 0.3596\n",
      "Time taken for 1 epoch: 14.783438444137573 secs\n",
      "\n",
      "Epoch 939 Batch 0 Loss 0.0001 Accuracy 0.3277\n",
      "Epoch 939 Loss 0.0009 Accuracy 0.3621\n",
      "Time taken for 1 epoch: 14.751491785049438 secs\n",
      "\n",
      "Epoch 940 Batch 0 Loss 0.0001 Accuracy 0.3819\n",
      "Saving checkpoint for epoch 940 at ./checkpoints/train/ckpt-192\n",
      "Epoch 940 Loss 0.0004 Accuracy 0.3547\n",
      "Time taken for 1 epoch: 15.300730228424072 secs\n",
      "\n",
      "Epoch 941 Batch 0 Loss 0.0059 Accuracy 0.3395\n",
      "Epoch 941 Loss 0.0010 Accuracy 0.3521\n",
      "Time taken for 1 epoch: 15.19098949432373 secs\n",
      "\n",
      "Epoch 942 Batch 0 Loss 0.0000 Accuracy 0.3155\n",
      "Epoch 942 Loss 0.0009 Accuracy 0.3609\n",
      "Time taken for 1 epoch: 14.92537236213684 secs\n",
      "\n",
      "Epoch 943 Batch 0 Loss 0.0001 Accuracy 0.3286\n",
      "Epoch 943 Loss 0.0007 Accuracy 0.3578\n",
      "Time taken for 1 epoch: 15.0711190700531 secs\n",
      "\n",
      "Epoch 944 Batch 0 Loss 0.0002 Accuracy 0.3788\n",
      "Epoch 944 Loss 0.0009 Accuracy 0.3591\n",
      "Time taken for 1 epoch: 14.86724591255188 secs\n",
      "\n",
      "Epoch 945 Batch 0 Loss 0.0008 Accuracy 0.3594\n",
      "Saving checkpoint for epoch 945 at ./checkpoints/train/ckpt-193\n",
      "Epoch 945 Loss 0.0008 Accuracy 0.3567\n",
      "Time taken for 1 epoch: 15.363507986068726 secs\n",
      "\n",
      "Epoch 946 Batch 0 Loss 0.0008 Accuracy 0.3795\n",
      "Epoch 946 Loss 0.0004 Accuracy 0.3665\n",
      "Time taken for 1 epoch: 14.692258358001709 secs\n",
      "\n",
      "Epoch 947 Batch 0 Loss 0.0000 Accuracy 0.3571\n",
      "Epoch 947 Loss 0.0008 Accuracy 0.3507\n",
      "Time taken for 1 epoch: 15.244264364242554 secs\n",
      "\n",
      "Epoch 948 Batch 0 Loss 0.0001 Accuracy 0.3125\n",
      "Epoch 948 Loss 0.0004 Accuracy 0.3628\n",
      "Time taken for 1 epoch: 14.912892818450928 secs\n",
      "\n",
      "Epoch 949 Batch 0 Loss 0.0006 Accuracy 0.3335\n",
      "Epoch 949 Loss 0.0006 Accuracy 0.3634\n",
      "Time taken for 1 epoch: 14.491791486740112 secs\n",
      "\n",
      "Epoch 950 Batch 0 Loss 0.0007 Accuracy 0.3761\n",
      "Saving checkpoint for epoch 950 at ./checkpoints/train/ckpt-194\n",
      "Epoch 950 Loss 0.0011 Accuracy 0.3571\n",
      "Time taken for 1 epoch: 15.329503774642944 secs\n",
      "\n",
      "Epoch 951 Batch 0 Loss 0.0022 Accuracy 0.4093\n",
      "Epoch 951 Loss 0.0012 Accuracy 0.3509\n",
      "Time taken for 1 epoch: 15.050101280212402 secs\n",
      "\n",
      "Epoch 952 Batch 0 Loss 0.0003 Accuracy 0.3141\n",
      "Epoch 952 Loss 0.0012 Accuracy 0.3617\n",
      "Time taken for 1 epoch: 14.779690265655518 secs\n",
      "\n",
      "Epoch 953 Batch 0 Loss 0.0000 Accuracy 0.3498\n",
      "Epoch 953 Loss 0.0007 Accuracy 0.3554\n",
      "Time taken for 1 epoch: 14.75126600265503 secs\n",
      "\n",
      "Epoch 954 Batch 0 Loss 0.0002 Accuracy 0.3374\n",
      "Epoch 954 Loss 0.0007 Accuracy 0.3546\n",
      "Time taken for 1 epoch: 15.337723016738892 secs\n",
      "\n",
      "Epoch 955 Batch 0 Loss 0.0010 Accuracy 0.3524\n",
      "Saving checkpoint for epoch 955 at ./checkpoints/train/ckpt-195\n",
      "Epoch 955 Loss 0.0010 Accuracy 0.3600\n",
      "Time taken for 1 epoch: 15.195823907852173 secs\n",
      "\n",
      "Epoch 956 Batch 0 Loss 0.0003 Accuracy 0.4002\n",
      "Epoch 956 Loss 0.0009 Accuracy 0.3517\n",
      "Time taken for 1 epoch: 15.078980684280396 secs\n",
      "\n",
      "Epoch 957 Batch 0 Loss 0.0005 Accuracy 0.4072\n",
      "Epoch 957 Loss 0.0004 Accuracy 0.3567\n",
      "Time taken for 1 epoch: 14.900676012039185 secs\n",
      "\n",
      "Epoch 958 Batch 0 Loss 0.0002 Accuracy 0.3478\n",
      "Epoch 958 Loss 0.0006 Accuracy 0.3551\n",
      "Time taken for 1 epoch: 14.885494232177734 secs\n",
      "\n",
      "Epoch 959 Batch 0 Loss 0.0000 Accuracy 0.2764\n",
      "Epoch 959 Loss 0.0004 Accuracy 0.3550\n",
      "Time taken for 1 epoch: 15.152730703353882 secs\n",
      "\n",
      "Epoch 960 Batch 0 Loss 0.0001 Accuracy 0.3258\n",
      "Saving checkpoint for epoch 960 at ./checkpoints/train/ckpt-196\n",
      "Epoch 960 Loss 0.0013 Accuracy 0.3633\n",
      "Time taken for 1 epoch: 15.080321311950684 secs\n",
      "\n",
      "Epoch 961 Batch 0 Loss 0.0015 Accuracy 0.4456\n",
      "Epoch 961 Loss 0.0010 Accuracy 0.3563\n",
      "Time taken for 1 epoch: 14.802564144134521 secs\n",
      "\n",
      "Epoch 962 Batch 0 Loss 0.0001 Accuracy 0.3412\n",
      "Epoch 962 Loss 0.0009 Accuracy 0.3561\n",
      "Time taken for 1 epoch: 15.876235485076904 secs\n",
      "\n",
      "Epoch 963 Batch 0 Loss 0.0000 Accuracy 0.3089\n",
      "Epoch 963 Loss 0.0005 Accuracy 0.3573\n",
      "Time taken for 1 epoch: 16.191540479660034 secs\n",
      "\n",
      "Epoch 964 Batch 0 Loss 0.0008 Accuracy 0.4289\n",
      "Epoch 964 Loss 0.0004 Accuracy 0.3549\n",
      "Time taken for 1 epoch: 15.129286527633667 secs\n",
      "\n",
      "Epoch 965 Batch 0 Loss 0.0000 Accuracy 0.3589\n",
      "Saving checkpoint for epoch 965 at ./checkpoints/train/ckpt-197\n",
      "Epoch 965 Loss 0.0006 Accuracy 0.3674\n",
      "Time taken for 1 epoch: 15.264444828033447 secs\n",
      "\n",
      "Epoch 966 Batch 0 Loss 0.0001 Accuracy 0.3254\n",
      "Epoch 966 Loss 0.0009 Accuracy 0.3565\n",
      "Time taken for 1 epoch: 15.048327445983887 secs\n",
      "\n",
      "Epoch 967 Batch 0 Loss 0.0045 Accuracy 0.2877\n",
      "Epoch 967 Loss 0.0011 Accuracy 0.3559\n",
      "Time taken for 1 epoch: 14.946551322937012 secs\n",
      "\n",
      "Epoch 968 Batch 0 Loss 0.0000 Accuracy 0.3121\n",
      "Epoch 968 Loss 0.0007 Accuracy 0.3540\n",
      "Time taken for 1 epoch: 15.167098760604858 secs\n",
      "\n",
      "Epoch 969 Batch 0 Loss 0.0021 Accuracy 0.3174\n",
      "Epoch 969 Loss 0.0010 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 14.729925394058228 secs\n",
      "\n",
      "Epoch 970 Batch 0 Loss 0.0030 Accuracy 0.3216\n",
      "Saving checkpoint for epoch 970 at ./checkpoints/train/ckpt-198\n",
      "Epoch 970 Loss 0.0011 Accuracy 0.3571\n",
      "Time taken for 1 epoch: 15.38391637802124 secs\n",
      "\n",
      "Epoch 971 Batch 0 Loss 0.0006 Accuracy 0.3346\n",
      "Epoch 971 Loss 0.0015 Accuracy 0.3555\n",
      "Time taken for 1 epoch: 14.697618007659912 secs\n",
      "\n",
      "Epoch 972 Batch 0 Loss 0.0011 Accuracy 0.3780\n",
      "Epoch 972 Loss 0.0009 Accuracy 0.3658\n",
      "Time taken for 1 epoch: 14.894193887710571 secs\n",
      "\n",
      "Epoch 973 Batch 0 Loss 0.0008 Accuracy 0.3691\n",
      "Epoch 973 Loss 0.0012 Accuracy 0.3564\n",
      "Time taken for 1 epoch: 15.134466886520386 secs\n",
      "\n",
      "Epoch 974 Batch 0 Loss 0.0000 Accuracy 0.3117\n",
      "Epoch 974 Loss 0.0007 Accuracy 0.3598\n",
      "Time taken for 1 epoch: 14.875383377075195 secs\n",
      "\n",
      "Epoch 975 Batch 0 Loss 0.0001 Accuracy 0.4224\n",
      "Saving checkpoint for epoch 975 at ./checkpoints/train/ckpt-199\n",
      "Epoch 975 Loss 0.0009 Accuracy 0.3617\n",
      "Time taken for 1 epoch: 15.284899950027466 secs\n",
      "\n",
      "Epoch 976 Batch 0 Loss 0.0002 Accuracy 0.4413\n",
      "Epoch 976 Loss 0.0007 Accuracy 0.3604\n",
      "Time taken for 1 epoch: 14.656444072723389 secs\n",
      "\n",
      "Epoch 977 Batch 0 Loss 0.0001 Accuracy 0.4007\n",
      "Epoch 977 Loss 0.0015 Accuracy 0.3580\n",
      "Time taken for 1 epoch: 14.949852466583252 secs\n",
      "\n",
      "Epoch 978 Batch 0 Loss 0.0015 Accuracy 0.3579\n",
      "Epoch 978 Loss 0.0003 Accuracy 0.3618\n",
      "Time taken for 1 epoch: 14.6279296875 secs\n",
      "\n",
      "Epoch 979 Batch 0 Loss 0.0040 Accuracy 0.4353\n",
      "Epoch 979 Loss 0.0007 Accuracy 0.3559\n",
      "Time taken for 1 epoch: 14.846008539199829 secs\n",
      "\n",
      "Epoch 980 Batch 0 Loss 0.0005 Accuracy 0.4047\n",
      "Saving checkpoint for epoch 980 at ./checkpoints/train/ckpt-200\n",
      "Epoch 980 Loss 0.0008 Accuracy 0.3551\n",
      "Time taken for 1 epoch: 15.514872074127197 secs\n",
      "\n",
      "Epoch 981 Batch 0 Loss 0.0001 Accuracy 0.3603\n",
      "Epoch 981 Loss 0.0012 Accuracy 0.3595\n",
      "Time taken for 1 epoch: 14.785926580429077 secs\n",
      "\n",
      "Epoch 982 Batch 0 Loss 0.0000 Accuracy 0.3053\n",
      "Epoch 982 Loss 0.0006 Accuracy 0.3641\n",
      "Time taken for 1 epoch: 14.868167400360107 secs\n",
      "\n",
      "Epoch 983 Batch 0 Loss 0.0003 Accuracy 0.3780\n",
      "Epoch 983 Loss 0.0012 Accuracy 0.3554\n",
      "Time taken for 1 epoch: 14.955696821212769 secs\n",
      "\n",
      "Epoch 984 Batch 0 Loss 0.0006 Accuracy 0.3655\n",
      "Epoch 984 Loss 0.0008 Accuracy 0.3617\n",
      "Time taken for 1 epoch: 14.83964228630066 secs\n",
      "\n",
      "Epoch 985 Batch 0 Loss 0.0001 Accuracy 0.3504\n",
      "Saving checkpoint for epoch 985 at ./checkpoints/train/ckpt-201\n",
      "Epoch 985 Loss 0.0006 Accuracy 0.3631\n",
      "Time taken for 1 epoch: 15.057647705078125 secs\n",
      "\n",
      "Epoch 986 Batch 0 Loss 0.0001 Accuracy 0.3468\n",
      "Epoch 986 Loss 0.0009 Accuracy 0.3575\n",
      "Time taken for 1 epoch: 15.042171955108643 secs\n",
      "\n",
      "Epoch 987 Batch 0 Loss 0.0000 Accuracy 0.3374\n",
      "Epoch 987 Loss 0.0004 Accuracy 0.3622\n",
      "Time taken for 1 epoch: 15.073104619979858 secs\n",
      "\n",
      "Epoch 988 Batch 0 Loss 0.0046 Accuracy 0.3581\n",
      "Epoch 988 Loss 0.0006 Accuracy 0.3573\n",
      "Time taken for 1 epoch: 15.355563879013062 secs\n",
      "\n",
      "Epoch 989 Batch 0 Loss 0.0000 Accuracy 0.2950\n",
      "Epoch 989 Loss 0.0013 Accuracy 0.3530\n",
      "Time taken for 1 epoch: 15.891542911529541 secs\n",
      "\n",
      "Epoch 990 Batch 0 Loss 0.0005 Accuracy 0.3802\n",
      "Saving checkpoint for epoch 990 at ./checkpoints/train/ckpt-202\n",
      "Epoch 990 Loss 0.0011 Accuracy 0.3622\n",
      "Time taken for 1 epoch: 14.982116937637329 secs\n",
      "\n",
      "Epoch 991 Batch 0 Loss 0.0094 Accuracy 0.3813\n",
      "Epoch 991 Loss 0.0015 Accuracy 0.3594\n",
      "Time taken for 1 epoch: 14.743549346923828 secs\n",
      "\n",
      "Epoch 992 Batch 0 Loss 0.0000 Accuracy 0.3143\n",
      "Epoch 992 Loss 0.0008 Accuracy 0.3536\n",
      "Time taken for 1 epoch: 15.252561330795288 secs\n",
      "\n",
      "Epoch 993 Batch 0 Loss 0.0005 Accuracy 0.4370\n",
      "Epoch 993 Loss 0.0007 Accuracy 0.3537\n",
      "Time taken for 1 epoch: 15.196136236190796 secs\n",
      "\n",
      "Epoch 994 Batch 0 Loss 0.0002 Accuracy 0.3911\n",
      "Epoch 994 Loss 0.0003 Accuracy 0.3550\n",
      "Time taken for 1 epoch: 15.036142110824585 secs\n",
      "\n",
      "Epoch 995 Batch 0 Loss 0.0012 Accuracy 0.3316\n",
      "Saving checkpoint for epoch 995 at ./checkpoints/train/ckpt-203\n",
      "Epoch 995 Loss 0.0011 Accuracy 0.3547\n",
      "Time taken for 1 epoch: 15.243618488311768 secs\n",
      "\n",
      "Epoch 996 Batch 0 Loss 0.0000 Accuracy 0.3293\n",
      "Epoch 996 Loss 0.0006 Accuracy 0.3609\n",
      "Time taken for 1 epoch: 14.652136325836182 secs\n",
      "\n",
      "Epoch 997 Batch 0 Loss 0.0000 Accuracy 0.3416\n",
      "Epoch 997 Loss 0.0009 Accuracy 0.3528\n",
      "Time taken for 1 epoch: 15.122386932373047 secs\n",
      "\n",
      "Epoch 998 Batch 0 Loss 0.0011 Accuracy 0.3177\n",
      "Epoch 998 Loss 0.0009 Accuracy 0.3553\n",
      "Time taken for 1 epoch: 15.411014556884766 secs\n",
      "\n",
      "Epoch 999 Batch 0 Loss 0.0003 Accuracy 0.3184\n",
      "Epoch 999 Loss 0.0010 Accuracy 0.3535\n",
      "Time taken for 1 epoch: 14.91484808921814 secs\n",
      "\n",
      "Epoch 1000 Batch 0 Loss 0.0016 Accuracy 0.3413\n",
      "Saving checkpoint for epoch 1000 at ./checkpoints/train/ckpt-204\n",
      "Epoch 1000 Loss 0.0013 Accuracy 0.3649\n",
      "Time taken for 1 epoch: 14.942262172698975 secs\n",
      "\n",
      "Epoch 1001 Batch 0 Loss 0.0003 Accuracy 0.3693\n",
      "Epoch 1001 Loss 0.0004 Accuracy 0.3564\n",
      "Time taken for 1 epoch: 14.899857997894287 secs\n",
      "\n",
      "Epoch 1002 Batch 0 Loss 0.0001 Accuracy 0.3511\n",
      "Epoch 1002 Loss 0.0005 Accuracy 0.3527\n",
      "Time taken for 1 epoch: 15.967922449111938 secs\n",
      "\n",
      "Epoch 1003 Batch 0 Loss 0.0009 Accuracy 0.4047\n",
      "Epoch 1003 Loss 0.0008 Accuracy 0.3625\n",
      "Time taken for 1 epoch: 15.106470108032227 secs\n",
      "\n",
      "Epoch 1004 Batch 0 Loss 0.0001 Accuracy 0.4022\n",
      "Epoch 1004 Loss 0.0005 Accuracy 0.3585\n",
      "Time taken for 1 epoch: 15.09937572479248 secs\n",
      "\n",
      "Epoch 1005 Batch 0 Loss 0.0001 Accuracy 0.4657\n",
      "Saving checkpoint for epoch 1005 at ./checkpoints/train/ckpt-205\n",
      "Epoch 1005 Loss 0.0005 Accuracy 0.3564\n",
      "Time taken for 1 epoch: 15.379742622375488 secs\n",
      "\n",
      "Epoch 1006 Batch 0 Loss 0.0006 Accuracy 0.3724\n",
      "Epoch 1006 Loss 0.0003 Accuracy 0.3553\n",
      "Time taken for 1 epoch: 14.942964792251587 secs\n",
      "\n",
      "Epoch 1007 Batch 0 Loss 0.0005 Accuracy 0.3094\n",
      "Epoch 1007 Loss 0.0006 Accuracy 0.3551\n",
      "Time taken for 1 epoch: 15.33671259880066 secs\n",
      "\n",
      "Epoch 1008 Batch 0 Loss 0.0006 Accuracy 0.3220\n",
      "Epoch 1008 Loss 0.0003 Accuracy 0.3559\n",
      "Time taken for 1 epoch: 15.306222677230835 secs\n",
      "\n",
      "Epoch 1009 Batch 0 Loss 0.0057 Accuracy 0.4403\n",
      "Epoch 1009 Loss 0.0008 Accuracy 0.3606\n",
      "Time taken for 1 epoch: 14.652973175048828 secs\n",
      "\n",
      "Epoch 1010 Batch 0 Loss 0.0001 Accuracy 0.3774\n",
      "Saving checkpoint for epoch 1010 at ./checkpoints/train/ckpt-206\n",
      "Epoch 1010 Loss 0.0013 Accuracy 0.3554\n",
      "Time taken for 1 epoch: 15.5458984375 secs\n",
      "\n",
      "Epoch 1011 Batch 0 Loss 0.0005 Accuracy 0.4023\n",
      "Epoch 1011 Loss 0.0003 Accuracy 0.3578\n",
      "Time taken for 1 epoch: 14.786418914794922 secs\n",
      "\n",
      "Epoch 1012 Batch 0 Loss 0.0000 Accuracy 0.3789\n",
      "Epoch 1012 Loss 0.0005 Accuracy 0.3623\n",
      "Time taken for 1 epoch: 14.789648532867432 secs\n",
      "\n",
      "Epoch 1013 Batch 0 Loss 0.0002 Accuracy 0.4016\n",
      "Epoch 1013 Loss 0.0004 Accuracy 0.3584\n",
      "Time taken for 1 epoch: 15.037607908248901 secs\n",
      "\n",
      "Epoch 1014 Batch 0 Loss 0.0016 Accuracy 0.4107\n",
      "Epoch 1014 Loss 0.0003 Accuracy 0.3569\n",
      "Time taken for 1 epoch: 15.039962530136108 secs\n",
      "\n",
      "Epoch 1015 Batch 0 Loss 0.0003 Accuracy 0.4100\n",
      "Saving checkpoint for epoch 1015 at ./checkpoints/train/ckpt-207\n",
      "Epoch 1015 Loss 0.0009 Accuracy 0.3575\n",
      "Time taken for 1 epoch: 15.275984525680542 secs\n",
      "\n",
      "Epoch 1016 Batch 0 Loss 0.0001 Accuracy 0.3404\n",
      "Epoch 1016 Loss 0.0009 Accuracy 0.3611\n",
      "Time taken for 1 epoch: 14.583184003829956 secs\n",
      "\n",
      "Epoch 1017 Batch 0 Loss 0.0058 Accuracy 0.3664\n",
      "Epoch 1017 Loss 0.0009 Accuracy 0.3601\n",
      "Time taken for 1 epoch: 14.967183113098145 secs\n",
      "\n",
      "Epoch 1018 Batch 0 Loss 0.0015 Accuracy 0.3057\n",
      "Epoch 1018 Loss 0.0008 Accuracy 0.3560\n",
      "Time taken for 1 epoch: 14.883347272872925 secs\n",
      "\n",
      "Epoch 1019 Batch 0 Loss 0.0015 Accuracy 0.4062\n",
      "Epoch 1019 Loss 0.0008 Accuracy 0.3556\n",
      "Time taken for 1 epoch: 15.11502456665039 secs\n",
      "\n",
      "Epoch 1020 Batch 0 Loss 0.0000 Accuracy 0.2977\n",
      "Saving checkpoint for epoch 1020 at ./checkpoints/train/ckpt-208\n",
      "Epoch 1020 Loss 0.0006 Accuracy 0.3505\n",
      "Time taken for 1 epoch: 15.684420585632324 secs\n",
      "\n",
      "Epoch 1021 Batch 0 Loss 0.0003 Accuracy 0.3845\n",
      "Epoch 1021 Loss 0.0006 Accuracy 0.3630\n",
      "Time taken for 1 epoch: 15.006250619888306 secs\n",
      "\n",
      "Epoch 1022 Batch 0 Loss 0.0008 Accuracy 0.3277\n",
      "Epoch 1022 Loss 0.0010 Accuracy 0.3515\n",
      "Time taken for 1 epoch: 17.008058071136475 secs\n",
      "\n",
      "Epoch 1023 Batch 0 Loss 0.0007 Accuracy 0.3781\n",
      "Epoch 1023 Loss 0.0013 Accuracy 0.3573\n",
      "Time taken for 1 epoch: 15.662914276123047 secs\n",
      "\n",
      "Epoch 1024 Batch 0 Loss 0.0001 Accuracy 0.3055\n",
      "Epoch 1024 Loss 0.0009 Accuracy 0.3577\n",
      "Time taken for 1 epoch: 17.48023533821106 secs\n",
      "\n",
      "Epoch 1025 Batch 0 Loss 0.0001 Accuracy 0.3165\n",
      "Saving checkpoint for epoch 1025 at ./checkpoints/train/ckpt-209\n",
      "Epoch 1025 Loss 0.0009 Accuracy 0.3635\n",
      "Time taken for 1 epoch: 16.559645891189575 secs\n",
      "\n",
      "Epoch 1026 Batch 0 Loss 0.0002 Accuracy 0.3770\n",
      "Epoch 1026 Loss 0.0004 Accuracy 0.3504\n",
      "Time taken for 1 epoch: 15.103856086730957 secs\n",
      "\n",
      "Epoch 1027 Batch 0 Loss 0.0000 Accuracy 0.3425\n",
      "Epoch 1027 Loss 0.0006 Accuracy 0.3618\n",
      "Time taken for 1 epoch: 15.05725383758545 secs\n",
      "\n",
      "Epoch 1028 Batch 0 Loss 0.0000 Accuracy 0.3163\n",
      "Epoch 1028 Loss 0.0006 Accuracy 0.3609\n",
      "Time taken for 1 epoch: 14.723769187927246 secs\n",
      "\n",
      "Epoch 1029 Batch 0 Loss 0.0007 Accuracy 0.3203\n",
      "Epoch 1029 Loss 0.0005 Accuracy 0.3535\n",
      "Time taken for 1 epoch: 15.249454498291016 secs\n",
      "\n",
      "Epoch 1030 Batch 0 Loss 0.0007 Accuracy 0.4098\n",
      "Saving checkpoint for epoch 1030 at ./checkpoints/train/ckpt-210\n",
      "Epoch 1030 Loss 0.0010 Accuracy 0.3509\n",
      "Time taken for 1 epoch: 15.943700551986694 secs\n",
      "\n",
      "Epoch 1031 Batch 0 Loss 0.0083 Accuracy 0.3306\n",
      "Epoch 1031 Loss 0.0011 Accuracy 0.3484\n",
      "Time taken for 1 epoch: 15.24826717376709 secs\n",
      "\n",
      "Epoch 1032 Batch 0 Loss 0.0002 Accuracy 0.3919\n",
      "Epoch 1032 Loss 0.0006 Accuracy 0.3525\n",
      "Time taken for 1 epoch: 15.311613321304321 secs\n",
      "\n",
      "Epoch 1033 Batch 0 Loss 0.0000 Accuracy 0.3342\n",
      "Epoch 1033 Loss 0.0006 Accuracy 0.3631\n",
      "Time taken for 1 epoch: 15.30174446105957 secs\n",
      "\n",
      "Epoch 1034 Batch 0 Loss 0.0000 Accuracy 0.3955\n",
      "Epoch 1034 Loss 0.0006 Accuracy 0.3616\n",
      "Time taken for 1 epoch: 14.564539432525635 secs\n",
      "\n",
      "Epoch 1035 Batch 0 Loss 0.0000 Accuracy 0.3498\n",
      "Saving checkpoint for epoch 1035 at ./checkpoints/train/ckpt-211\n",
      "Epoch 1035 Loss 0.0005 Accuracy 0.3560\n",
      "Time taken for 1 epoch: 15.727492332458496 secs\n",
      "\n",
      "Epoch 1036 Batch 0 Loss 0.0000 Accuracy 0.3921\n",
      "Epoch 1036 Loss 0.0007 Accuracy 0.3587\n",
      "Time taken for 1 epoch: 14.636122226715088 secs\n",
      "\n",
      "Epoch 1037 Batch 0 Loss 0.0000 Accuracy 0.3891\n",
      "Epoch 1037 Loss 0.0009 Accuracy 0.3546\n",
      "Time taken for 1 epoch: 15.1406831741333 secs\n",
      "\n",
      "Epoch 1038 Batch 0 Loss 0.0004 Accuracy 0.3207\n",
      "Epoch 1038 Loss 0.0008 Accuracy 0.3524\n",
      "Time taken for 1 epoch: 15.24011492729187 secs\n",
      "\n",
      "Epoch 1039 Batch 0 Loss 0.0001 Accuracy 0.3499\n",
      "Epoch 1039 Loss 0.0009 Accuracy 0.3493\n",
      "Time taken for 1 epoch: 15.199134588241577 secs\n",
      "\n",
      "Epoch 1040 Batch 0 Loss 0.0001 Accuracy 0.3945\n",
      "Saving checkpoint for epoch 1040 at ./checkpoints/train/ckpt-212\n",
      "Epoch 1040 Loss 0.0008 Accuracy 0.3533\n",
      "Time taken for 1 epoch: 15.471482515335083 secs\n",
      "\n",
      "Epoch 1041 Batch 0 Loss 0.0001 Accuracy 0.3825\n",
      "Epoch 1041 Loss 0.0010 Accuracy 0.3518\n",
      "Time taken for 1 epoch: 14.978787422180176 secs\n",
      "\n",
      "Epoch 1042 Batch 0 Loss 0.0001 Accuracy 0.4550\n",
      "Epoch 1042 Loss 0.0006 Accuracy 0.3577\n",
      "Time taken for 1 epoch: 15.020405769348145 secs\n",
      "\n",
      "Epoch 1043 Batch 0 Loss 0.0000 Accuracy 0.4364\n",
      "Epoch 1043 Loss 0.0011 Accuracy 0.3535\n",
      "Time taken for 1 epoch: 15.070871114730835 secs\n",
      "\n",
      "Epoch 1044 Batch 0 Loss 0.0046 Accuracy 0.3247\n",
      "Epoch 1044 Loss 0.0006 Accuracy 0.3565\n",
      "Time taken for 1 epoch: 14.980181217193604 secs\n",
      "\n",
      "Epoch 1045 Batch 0 Loss 0.0003 Accuracy 0.4042\n",
      "Saving checkpoint for epoch 1045 at ./checkpoints/train/ckpt-213\n",
      "Epoch 1045 Loss 0.0004 Accuracy 0.3603\n",
      "Time taken for 1 epoch: 15.34022331237793 secs\n",
      "\n",
      "Epoch 1046 Batch 0 Loss 0.0002 Accuracy 0.3069\n",
      "Epoch 1046 Loss 0.0008 Accuracy 0.3519\n",
      "Time taken for 1 epoch: 15.165416240692139 secs\n",
      "\n",
      "Epoch 1047 Batch 0 Loss 0.0014 Accuracy 0.3281\n",
      "Epoch 1047 Loss 0.0009 Accuracy 0.3596\n",
      "Time taken for 1 epoch: 14.918392419815063 secs\n",
      "\n",
      "Epoch 1048 Batch 0 Loss 0.0006 Accuracy 0.4045\n",
      "Epoch 1048 Loss 0.0011 Accuracy 0.3574\n",
      "Time taken for 1 epoch: 14.807740449905396 secs\n",
      "\n",
      "Epoch 1049 Batch 0 Loss 0.0006 Accuracy 0.3612\n",
      "Epoch 1049 Loss 0.0012 Accuracy 0.3568\n",
      "Time taken for 1 epoch: 14.89477252960205 secs\n",
      "\n",
      "Epoch 1050 Batch 0 Loss 0.0039 Accuracy 0.3640\n",
      "Saving checkpoint for epoch 1050 at ./checkpoints/train/ckpt-214\n",
      "Epoch 1050 Loss 0.0015 Accuracy 0.3595\n",
      "Time taken for 1 epoch: 15.339519500732422 secs\n",
      "\n",
      "Epoch 1051 Batch 0 Loss 0.0000 Accuracy 0.3718\n",
      "Epoch 1051 Loss 0.0008 Accuracy 0.3610\n",
      "Time taken for 1 epoch: 14.706111669540405 secs\n",
      "\n",
      "Epoch 1052 Batch 0 Loss 0.0013 Accuracy 0.4068\n",
      "Epoch 1052 Loss 0.0008 Accuracy 0.3498\n",
      "Time taken for 1 epoch: 15.127464771270752 secs\n",
      "\n",
      "Epoch 1053 Batch 0 Loss 0.0000 Accuracy 0.3342\n",
      "Epoch 1053 Loss 0.0010 Accuracy 0.3538\n",
      "Time taken for 1 epoch: 15.494019269943237 secs\n",
      "\n",
      "Epoch 1054 Batch 0 Loss 0.0010 Accuracy 0.3569\n",
      "Epoch 1054 Loss 0.0007 Accuracy 0.3591\n",
      "Time taken for 1 epoch: 15.0606849193573 secs\n",
      "\n",
      "Epoch 1055 Batch 0 Loss 0.0001 Accuracy 0.3917\n",
      "Saving checkpoint for epoch 1055 at ./checkpoints/train/ckpt-215\n",
      "Epoch 1055 Loss 0.0010 Accuracy 0.3573\n",
      "Time taken for 1 epoch: 15.540072441101074 secs\n",
      "\n",
      "Epoch 1056 Batch 0 Loss 0.0000 Accuracy 0.3932\n",
      "Epoch 1056 Loss 0.0009 Accuracy 0.3536\n",
      "Time taken for 1 epoch: 14.956780910491943 secs\n",
      "\n",
      "Epoch 1057 Batch 0 Loss 0.0000 Accuracy 0.3634\n",
      "Epoch 1057 Loss 0.0010 Accuracy 0.3576\n",
      "Time taken for 1 epoch: 14.988480806350708 secs\n",
      "\n",
      "Epoch 1058 Batch 0 Loss 0.0000 Accuracy 0.3621\n",
      "Epoch 1058 Loss 0.0005 Accuracy 0.3619\n",
      "Time taken for 1 epoch: 14.813224792480469 secs\n",
      "\n",
      "Epoch 1059 Batch 0 Loss 0.0016 Accuracy 0.3395\n",
      "Epoch 1059 Loss 0.0006 Accuracy 0.3661\n",
      "Time taken for 1 epoch: 14.446857929229736 secs\n",
      "\n",
      "Epoch 1060 Batch 0 Loss 0.0005 Accuracy 0.3812\n",
      "Saving checkpoint for epoch 1060 at ./checkpoints/train/ckpt-216\n",
      "Epoch 1060 Loss 0.0009 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 15.361665964126587 secs\n",
      "\n",
      "Epoch 1061 Batch 0 Loss 0.0000 Accuracy 0.3589\n",
      "Epoch 1061 Loss 0.0004 Accuracy 0.3611\n",
      "Time taken for 1 epoch: 15.851540088653564 secs\n",
      "\n",
      "Epoch 1062 Batch 0 Loss 0.0001 Accuracy 0.3165\n",
      "Epoch 1062 Loss 0.0007 Accuracy 0.3529\n",
      "Time taken for 1 epoch: 15.252923011779785 secs\n",
      "\n",
      "Epoch 1063 Batch 0 Loss 0.0000 Accuracy 0.3520\n",
      "Epoch 1063 Loss 0.0007 Accuracy 0.3599\n",
      "Time taken for 1 epoch: 14.856605052947998 secs\n",
      "\n",
      "Epoch 1064 Batch 0 Loss 0.0001 Accuracy 0.3516\n",
      "Epoch 1064 Loss 0.0010 Accuracy 0.3665\n",
      "Time taken for 1 epoch: 14.766391038894653 secs\n",
      "\n",
      "Epoch 1065 Batch 0 Loss 0.0012 Accuracy 0.3730\n",
      "Saving checkpoint for epoch 1065 at ./checkpoints/train/ckpt-217\n",
      "Epoch 1065 Loss 0.0012 Accuracy 0.3522\n",
      "Time taken for 1 epoch: 15.422214984893799 secs\n",
      "\n",
      "Epoch 1066 Batch 0 Loss 0.0003 Accuracy 0.3858\n",
      "Epoch 1066 Loss 0.0009 Accuracy 0.3616\n",
      "Time taken for 1 epoch: 14.692437410354614 secs\n",
      "\n",
      "Epoch 1067 Batch 0 Loss 0.0001 Accuracy 0.3157\n",
      "Epoch 1067 Loss 0.0013 Accuracy 0.3545\n",
      "Time taken for 1 epoch: 15.163053750991821 secs\n",
      "\n",
      "Epoch 1068 Batch 0 Loss 0.0077 Accuracy 0.3053\n",
      "Epoch 1068 Loss 0.0010 Accuracy 0.3663\n",
      "Time taken for 1 epoch: 14.56530499458313 secs\n",
      "\n",
      "Epoch 1069 Batch 0 Loss 0.0020 Accuracy 0.3816\n",
      "Epoch 1069 Loss 0.0007 Accuracy 0.3538\n",
      "Time taken for 1 epoch: 15.042333602905273 secs\n",
      "\n",
      "Epoch 1070 Batch 0 Loss 0.0000 Accuracy 0.4154\n",
      "Saving checkpoint for epoch 1070 at ./checkpoints/train/ckpt-218\n",
      "Epoch 1070 Loss 0.0008 Accuracy 0.3592\n",
      "Time taken for 1 epoch: 15.482482671737671 secs\n",
      "\n",
      "Epoch 1071 Batch 0 Loss 0.0004 Accuracy 0.3665\n",
      "Epoch 1071 Loss 0.0005 Accuracy 0.3585\n",
      "Time taken for 1 epoch: 14.720610857009888 secs\n",
      "\n",
      "Epoch 1072 Batch 0 Loss 0.0014 Accuracy 0.3589\n",
      "Epoch 1072 Loss 0.0005 Accuracy 0.3541\n",
      "Time taken for 1 epoch: 15.273082494735718 secs\n",
      "\n",
      "Epoch 1073 Batch 0 Loss 0.0009 Accuracy 0.4294\n",
      "Epoch 1073 Loss 0.0005 Accuracy 0.3539\n",
      "Time taken for 1 epoch: 15.046370506286621 secs\n",
      "\n",
      "Epoch 1074 Batch 0 Loss 0.0002 Accuracy 0.3239\n",
      "Epoch 1074 Loss 0.0007 Accuracy 0.3553\n",
      "Time taken for 1 epoch: 14.93864917755127 secs\n",
      "\n",
      "Epoch 1075 Batch 0 Loss 0.0035 Accuracy 0.3225\n",
      "Saving checkpoint for epoch 1075 at ./checkpoints/train/ckpt-219\n",
      "Epoch 1075 Loss 0.0009 Accuracy 0.3560\n",
      "Time taken for 1 epoch: 15.559462547302246 secs\n",
      "\n",
      "Epoch 1076 Batch 0 Loss 0.0001 Accuracy 0.3295\n",
      "Epoch 1076 Loss 0.0007 Accuracy 0.3569\n",
      "Time taken for 1 epoch: 14.859851121902466 secs\n",
      "\n",
      "Epoch 1077 Batch 0 Loss 0.0000 Accuracy 0.3652\n",
      "Epoch 1077 Loss 0.0010 Accuracy 0.3608\n",
      "Time taken for 1 epoch: 15.010719776153564 secs\n",
      "\n",
      "Epoch 1078 Batch 0 Loss 0.0065 Accuracy 0.3295\n",
      "Epoch 1078 Loss 0.0006 Accuracy 0.3585\n",
      "Time taken for 1 epoch: 14.975105285644531 secs\n",
      "\n",
      "Epoch 1079 Batch 0 Loss 0.0005 Accuracy 0.3679\n",
      "Epoch 1079 Loss 0.0004 Accuracy 0.3660\n",
      "Time taken for 1 epoch: 14.622575759887695 secs\n",
      "\n",
      "Epoch 1080 Batch 0 Loss 0.0000 Accuracy 0.3397\n",
      "Saving checkpoint for epoch 1080 at ./checkpoints/train/ckpt-220\n",
      "Epoch 1080 Loss 0.0005 Accuracy 0.3599\n",
      "Time taken for 1 epoch: 15.066308736801147 secs\n",
      "\n",
      "Epoch 1081 Batch 0 Loss 0.0000 Accuracy 0.3357\n",
      "Epoch 1081 Loss 0.0006 Accuracy 0.3572\n",
      "Time taken for 1 epoch: 14.81056547164917 secs\n",
      "\n",
      "Epoch 1082 Batch 0 Loss 0.0001 Accuracy 0.3556\n",
      "Epoch 1082 Loss 0.0006 Accuracy 0.3583\n",
      "Time taken for 1 epoch: 15.153124332427979 secs\n",
      "\n",
      "Epoch 1083 Batch 0 Loss 0.0024 Accuracy 0.3712\n",
      "Epoch 1083 Loss 0.0009 Accuracy 0.3600\n",
      "Time taken for 1 epoch: 14.76718783378601 secs\n",
      "\n",
      "Epoch 1084 Batch 0 Loss 0.0085 Accuracy 0.4333\n",
      "Epoch 1084 Loss 0.0010 Accuracy 0.3543\n",
      "Time taken for 1 epoch: 14.994153499603271 secs\n",
      "\n",
      "Epoch 1085 Batch 0 Loss 0.0032 Accuracy 0.4134\n",
      "Saving checkpoint for epoch 1085 at ./checkpoints/train/ckpt-221\n",
      "Epoch 1085 Loss 0.0004 Accuracy 0.3526\n",
      "Time taken for 1 epoch: 15.512207508087158 secs\n",
      "\n",
      "Epoch 1086 Batch 0 Loss 0.0000 Accuracy 0.3795\n",
      "Epoch 1086 Loss 0.0007 Accuracy 0.3558\n",
      "Time taken for 1 epoch: 15.181862592697144 secs\n",
      "\n",
      "Epoch 1087 Batch 0 Loss 0.0023 Accuracy 0.3125\n",
      "Epoch 1087 Loss 0.0008 Accuracy 0.3564\n",
      "Time taken for 1 epoch: 14.725092649459839 secs\n",
      "\n",
      "Epoch 1088 Batch 0 Loss 0.0002 Accuracy 0.4095\n",
      "Epoch 1088 Loss 0.0009 Accuracy 0.3621\n",
      "Time taken for 1 epoch: 14.75800895690918 secs\n",
      "\n",
      "Epoch 1089 Batch 0 Loss 0.0005 Accuracy 0.3231\n",
      "Epoch 1089 Loss 0.0010 Accuracy 0.3629\n",
      "Time taken for 1 epoch: 14.831698417663574 secs\n",
      "\n",
      "Epoch 1090 Batch 0 Loss 0.0000 Accuracy 0.3653\n",
      "Saving checkpoint for epoch 1090 at ./checkpoints/train/ckpt-222\n",
      "Epoch 1090 Loss 0.0012 Accuracy 0.3542\n",
      "Time taken for 1 epoch: 18.912712574005127 secs\n",
      "\n",
      "Epoch 1091 Batch 0 Loss 0.0004 Accuracy 0.3536\n",
      "Epoch 1091 Loss 0.0010 Accuracy 0.3597\n",
      "Time taken for 1 epoch: 17.02122211456299 secs\n",
      "\n",
      "Epoch 1092 Batch 0 Loss 0.0002 Accuracy 0.3105\n",
      "Epoch 1092 Loss 0.0008 Accuracy 0.3524\n",
      "Time taken for 1 epoch: 18.89897322654724 secs\n",
      "\n",
      "Epoch 1093 Batch 0 Loss 0.0001 Accuracy 0.3944\n",
      "Epoch 1093 Loss 0.0010 Accuracy 0.3483\n",
      "Time taken for 1 epoch: 18.76451849937439 secs\n",
      "\n",
      "Epoch 1094 Batch 0 Loss 0.0011 Accuracy 0.3195\n",
      "Epoch 1094 Loss 0.0005 Accuracy 0.3536\n",
      "Time taken for 1 epoch: 19.616108179092407 secs\n",
      "\n",
      "Epoch 1095 Batch 0 Loss 0.0001 Accuracy 0.3973\n",
      "Saving checkpoint for epoch 1095 at ./checkpoints/train/ckpt-223\n",
      "Epoch 1095 Loss 0.0007 Accuracy 0.3533\n",
      "Time taken for 1 epoch: 19.58848738670349 secs\n",
      "\n",
      "Epoch 1096 Batch 0 Loss 0.0005 Accuracy 0.3205\n",
      "Epoch 1096 Loss 0.0007 Accuracy 0.3571\n",
      "Time taken for 1 epoch: 18.684524059295654 secs\n",
      "\n",
      "Epoch 1097 Batch 0 Loss 0.0002 Accuracy 0.3012\n",
      "Epoch 1097 Loss 0.0005 Accuracy 0.3550\n",
      "Time taken for 1 epoch: 16.83525776863098 secs\n",
      "\n",
      "Epoch 1098 Batch 0 Loss 0.0001 Accuracy 0.3269\n",
      "Epoch 1098 Loss 0.0004 Accuracy 0.3567\n",
      "Time taken for 1 epoch: 17.129870414733887 secs\n",
      "\n",
      "Epoch 1099 Batch 0 Loss 0.0001 Accuracy 0.2993\n",
      "Epoch 1099 Loss 0.0008 Accuracy 0.3585\n",
      "Time taken for 1 epoch: 18.50908613204956 secs\n",
      "\n",
      "Epoch 1100 Batch 0 Loss 0.0000 Accuracy 0.3462\n",
      "Saving checkpoint for epoch 1100 at ./checkpoints/train/ckpt-224\n",
      "Epoch 1100 Loss 0.0006 Accuracy 0.3621\n",
      "Time taken for 1 epoch: 18.928727865219116 secs\n",
      "\n",
      "Epoch 1101 Batch 0 Loss 0.0005 Accuracy 0.2977\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-0133f04feef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# inp -> portuguese, tar -> english\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfcsSWswSdGV"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6APsFrgImLW"
   },
   "source": [
    "The following steps are used for evaluation:\n",
    "\n",
    "* Encode the input sentence using the Portuguese tokenizer (`tokenizer_pt`). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
    "* The decoder input is the `start token == tokenizer_en.vocab_size`.\n",
    "* Calculate the padding masks and the look ahead masks.\n",
    "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
    "* Select the last word and calculate the argmax of that.\n",
    "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
    "* In this approach, the decoder predicts the next word based on the previous words it predicted.\n",
    "\n",
    "Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the paper, use the entire dataset and base transformer model or transformer XL, by changing the hyperparameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5buvMlnvyrFm"
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_pt.vocab_size]\n",
    "  end_token = [tokenizer_pt.vocab_size + 1]\n",
    "  \n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if predicted_id == tokenizer_en.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CN-BV43FMBej"
   },
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "  sentence = tokenizer_pt.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                        if i < tokenizer_en.vocab_size], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lU2_yG_vBGza"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "  print(sentence)\n",
    "  print(predicted_sentence)\n",
    "#   print('Input:                 {}'.format(sentence))\n",
    "#   print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t\n",
    "Ða wearð Melantia micclum ofsceamod\tþa weorþan Melantia micel ofsceamian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: And he hine gesette to heahgerefan ofer Alexandrian and Ægyfto lande and het þæt he heolde þa romaniscan gesætnysse\n",
      "Predicted translation: and he he gesettan to heahgerefa ofer Alexandria and Egipte land and hatan þæt he healdan se Romanisc gesetnes\n",
      "and he he gesettan to heahgerefa ofer Alexandria and Egipte land and hatan þæt he healdan se Romanisc gesetnes\n"
     ]
    }
   ],
   "source": [
    "for a, b in train_examples.take(1):\n",
    "    translate(a.numpy().decode())\n",
    "    tf.print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Þa comon him to Sadcei þa secgað þæt ærist ne sy & hine ahsodon & þus cwædon\n",
      "Predicted translation: þa cuman hi to cyrran & hira lotwrencceast an gear\n",
      "þa cuman he to Sadducaei se secgan þæt ærist ne wesan & he ascian & þus cweþan\n",
      "----\n",
      "Input: ðæs Caseres\n",
      "Predicted translation: se Casere\n",
      "se Casere\n",
      "----\n",
      "Input: Hi ferdon þa & hine forleton\n",
      "Predicted translation: hi feran þa & he forlætan\n",
      "hi feran þa & he forlætan\n",
      "----\n",
      "Input: Eornostlice seofon gebroþru wæron\n",
      "Predicted translation: se þe gefyllan hi he\n",
      "eornostlice seofon gebroðor wesan\n",
      "----\n",
      "Input: þa wundrodon hi be þam\n",
      "Predicted translation: þa wundrian hi be þa\n",
      "þa wundrian hi be se\n",
      "----\n",
      "Input: þa cwæð he & heora lotwrencceaste wiste\n",
      "Predicted translation: þa cweþan he & hira lotwrencceast witan\n",
      "þa cweþan he & hira lotwrencceast witan\n",
      "----\n",
      "Input: & se æresta nam wif & wearð dead na læfedum sæde\n",
      "Predicted translation: & se Deniscan on ærmorgen niman wif & weorþan þe na se westrice beheonan Wendelsæ & begeondan þes heahsacherd\n",
      "& se ærest niman wif & weorþan dead na læfan sæd\n",
      "----\n",
      "Input: Lareow Moyses us wrat gif hwæs broðor dead bið & læfð his wif & n æfð nan bearn þæt his broðor nime his wif & his broðor sæd wecce\n",
      "Predicted translation: lareow Moyses we ascian gif hi  & geaf  & hira  & habban his rice geseon ne habban nan þing þæt hi gefultuman þæt hi his dohtor Iacob gesciran & se ea\n",
      "lareow Moyses us writan gif hwa broðor dead beon & læfan his wif & ne habban nan bearn þæt his broðor niman his wif & his broðor sæd weccan\n",
      "----\n",
      "Input: Ealra æftemest þa forðferde þæt wif\n",
      "Predicted translation: on se cweðan he\n",
      "eal æfter þa forþferan se wif\n",
      "----\n",
      "Input: & ealle seofon hi hæfdon & sæd ne læfdon\n",
      "Predicted translation: & eal seofon hi habban & ne sweltan ne hælend siððan gelome don\n",
      "& eal seofon heo habban & sæd ne læfan\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for a, b in val_examples.take(10):\n",
    "    translate(a.numpy().decode())\n",
    "    tf.print(b)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsxrAlvFG8SZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: We habbað ealle ðing mid þam ælmihtigan Drihtne\n",
      "Predicted translation: we habban eal þing mid se eallmihtig Dryhten\n",
      "Real translation: we habban eal þing mid se eallmihtig Dryhten\n"
     ]
    }
   ],
   "source": [
    "translate(\"We habbað ealle ðing mid þam ælmihtigan Drihtne\")\n",
    "print (\"Real translation: we habban eal þing mid se eallmihtig Dryhten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7EH5y_aqI4t1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: os meus vizinhos ouviram sobre esta ideia.\n",
      "Predicted translation: Darius swingan hi þes binnon feawa monað idelhende\n",
      "Real translation: and my neighboring homes heard about this idea .\n"
     ]
    }
   ],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-hVCTSUMlkb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\n",
      "Predicted translation: hira þa hire hand hira lotwrencceast witan\n",
      "Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\n"
     ]
    }
   ],
   "source": [
    "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
    "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MxkSZvz0jX"
   },
   "source": [
    "You can pass different layers and attention blocks of the decoder to the `plot` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-kFyiOLH0xg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é o primeiro livro que eu fiz.\n",
      "Predicted translation: þider se ea gif þes þe þes hire lac deor unbeboht six hund\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real translation: this is the first book i've ever done.\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RqQ1fIsLwkGE"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned about positional encoding, multi-head attention, the importance of masking and how to create a transformer.\n",
    "\n",
    "Try using a different dataset to train the transformer. You can also create the base transformer or transformer XL by changing the hyperparameters above. You can also use the layers defined here to create [BERT](https://arxiv.org/abs/1810.04805) and train state of the art models. Futhermore, you can implement beam search to get better predictions."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "s_qNSzzyaCbD"
   ],
   "name": "transformer.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0e0d890d0561404f91dbbe32c7a968d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "1607f2ecd0c64125a081503cc9eb2caa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "  0%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3e679a31c15d401dba8cbb929600c15f",
       "max": 1803,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_30eb27c4cec1420db11ad9b6e4eaa1bf",
       "value": 0
      }
     },
     "16484967d5374168afbca17948a94e31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1717a8bbc4564373affedb4e11e9aab8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "186792f23e564f8bbf0099d63328c6b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "194bd44ff15947ac85321fc3be00e932": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d6b5bd7826d46829c4e1a5b05c1e419": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e08b4b9bd314039b0eabd873f9daa18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "1fcc5dce2bec42458512e29ba578ae8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "27129d6afd1f4cf29b44e87687016eee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_35c90729b03b4ca8ad9e9cff09e42bee",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_915bc88dd2e2445cae18acca9830b170",
       "value": 1
      }
     },
     "2f526e6e7e954a5da83d333b6fbf2982": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "30eb27c4cec1420db11ad9b6e4eaa1bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "35c90729b03b4ca8ad9e9cff09e42bee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "36efa5fe9bb5464e9a6edaa460abb58d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_194bd44ff15947ac85321fc3be00e932",
       "placeholder": "​",
       "style": "IPY_MODEL_9c88f0004c864677b38d89ad1686035c",
       "value": " 19838/51785 [00:00&lt;00:00, 198379.24 examples/s]"
      }
     },
     "377c335c948f4c11ac806d381e2dbee6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e679a31c15d401dba8cbb929600c15f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e8606466c774b628ddec7d1d877c1a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3f892beaeb7942fe87dca1b44813098d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c7ae463517d147d3aeda0c6a8739934b",
       "placeholder": "​",
       "style": "IPY_MODEL_90498e8edda745bc86c008126e8277a5",
       "value": " 0/1193 [00:00&lt;?, ? examples/s]"
      }
     },
     "4459a3d62cf945338dcb31b61503a630": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "456a5511e517483f861c6250ccbdfef6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_822a1fcf13864a6592a208f52d3a45fa",
        "IPY_MODEL_f923fd02533a480d9bc74be4f35c84f1"
       ],
       "layout": "IPY_MODEL_9d825f2724af43b79a6fa1aabb479298"
      }
     },
     "458eb96a7a7f415e97ce61aa558a3c64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a6b4c6a3ae24f11adf416e62268d387": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cecfa836b02c4cdebefd9c601386cf7a",
       "placeholder": "​",
       "style": "IPY_MODEL_1717a8bbc4564373affedb4e11e9aab8",
       "value": " 1803/0 [00:00&lt;00:00, 4788.03 examples/s]"
      }
     },
     "5318f903280b41a2b8da23b81709a776": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a83ae990ed94f5989cf572b0a8af0be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6c2c4480920a4533a78996327463a2b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "73608d85c72a4dc5b3f6f0bd29a329d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "79b9d229ccb54716b368f4e572222933": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d3402aa4b0a4ba6839aa97664f649c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Dl Completed...: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1d6b5bd7826d46829c4e1a5b05c1e419",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1e08b4b9bd314039b0eabd873f9daa18",
       "value": 1
      }
     },
     "7d62cecd8db54cb492ee8f11b4c1e29a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "822a1fcf13864a6592a208f52d3a45fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Extraction completed...: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2f526e6e7e954a5da83d333b6fbf2982",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1fcc5dce2bec42458512e29ba578ae8f",
       "value": 1
      }
     },
     "827691b2955b4e4caec35c11e2dd0b5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_73608d85c72a4dc5b3f6f0bd29a329d4",
       "placeholder": "​",
       "style": "IPY_MODEL_b06137696b774319b960f03ad45af6e4",
       "value": " 1/1 [00:07&lt;00:00,  7.59s/ url]"
      }
     },
     "90498e8edda745bc86c008126e8277a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "915bc88dd2e2445cae18acca9830b170": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "91b14375c2784c63ae71350d0015d808": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "94ce25087ae44d6abfcc0122a6856c37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Dl Size...: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_377c335c948f4c11ac806d381e2dbee6",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0e0d890d0561404f91dbbe32c7a968d1",
       "value": 1
      }
     },
     "97d5e6641cda47d29fc5b8e6ebfedb68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "99283c9c5e2b405ba10e100f1ca39889": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c10c7e8975543b28496de7965e2654b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1607f2ecd0c64125a081503cc9eb2caa",
        "IPY_MODEL_ad61b5359af04ccebafd2b485dfb5065"
       ],
       "layout": "IPY_MODEL_ef7190ea813547028606283a17b1a8ba"
      }
     },
     "9c88f0004c864677b38d89ad1686035c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9c8bf84c78f94ea989e3dcf57705a246": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f6e68093dbd74cd4828b9985b181d274",
       "placeholder": "​",
       "style": "IPY_MODEL_7d62cecd8db54cb492ee8f11b4c1e29a",
       "value": " 1193/0 [00:00&lt;00:00, 4394.36 examples/s]"
      }
     },
     "9d825f2724af43b79a6fa1aabb479298": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f9b566492a9442f9b13547047e78498": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a40d47789da04c05b6ac13081930b181": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3e8606466c774b628ddec7d1d877c1a9",
       "placeholder": "​",
       "style": "IPY_MODEL_da64cb26752f478d894a9c921b3d7727",
       "value": " 51785/0 [00:09&lt;00:00, 5587.32 examples/s]"
      }
     },
     "a5cd4ad1711f4478b56711ebf2e4b74e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b046b2dc15e24cd990322e3f7eea50f2",
        "IPY_MODEL_4a6b4c6a3ae24f11adf416e62268d387"
       ],
       "layout": "IPY_MODEL_99283c9c5e2b405ba10e100f1ca39889"
      }
     },
     "ad61b5359af04ccebafd2b485dfb5065": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_186792f23e564f8bbf0099d63328c6b4",
       "placeholder": "​",
       "style": "IPY_MODEL_b811bbe8caaf41fcb78f7cbe026b8bf9",
       "value": " 0/1803 [00:00&lt;?, ? examples/s]"
      }
     },
     "b046b2dc15e24cd990322e3f7eea50f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f8275a203aa142f0b69360d0d3843bb4",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6c2c4480920a4533a78996327463a2b4",
       "value": 1
      }
     },
     "b06137696b774319b960f03ad45af6e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b6e57d6bd9f64c8c969e34c68dfae31c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bf5bc178960a4686bbb35afa9bade9a1",
        "IPY_MODEL_36efa5fe9bb5464e9a6edaa460abb58d"
       ],
       "layout": "IPY_MODEL_b8e9f0f21a604037843c20ffbf562690"
      }
     },
     "b811bbe8caaf41fcb78f7cbe026b8bf9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b8e9f0f21a604037843c20ffbf562690": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8f2f9964e4b4a2b87b159ac81f70aa7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "bf5bc178960a4686bbb35afa9bade9a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": " 38%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_16484967d5374168afbca17948a94e31",
       "max": 51785,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_db3e6516398e4e479cc101f889ad9cea",
       "value": 19838
      }
     },
     "c7ae463517d147d3aeda0c6a8739934b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cad5e524a43440b39c25e7902fee31a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_94ce25087ae44d6abfcc0122a6856c37",
        "IPY_MODEL_fcefc03e80f44fce8a4c2889b7d0a8d3"
       ],
       "layout": "IPY_MODEL_79b9d229ccb54716b368f4e572222933"
      }
     },
     "cecfa836b02c4cdebefd9c601386cf7a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d2b1004ba93f444eb9dadcbd29a0db2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d82d8c2fbed34fb6be93ea0bd2a383fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e715e304faf74221ba1479f4ff1a8847",
        "IPY_MODEL_3f892beaeb7942fe87dca1b44813098d"
       ],
       "layout": "IPY_MODEL_d2b1004ba93f444eb9dadcbd29a0db2f"
      }
     },
     "da64cb26752f478d894a9c921b3d7727": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "db3e6516398e4e479cc101f889ad9cea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "de497e2297a54a3d8dcb55b192d6718f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_27129d6afd1f4cf29b44e87687016eee",
        "IPY_MODEL_9c8bf84c78f94ea989e3dcf57705a246"
       ],
       "layout": "IPY_MODEL_97d5e6641cda47d29fc5b8e6ebfedb68"
      }
     },
     "e0739ade4c4a44ab82febedaa525a817": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9f9b566492a9442f9b13547047e78498",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b8f2f9964e4b4a2b87b159ac81f70aa7",
       "value": 1
      }
     },
     "e715e304faf74221ba1479f4ff1a8847": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "  0%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4459a3d62cf945338dcb31b61503a630",
       "max": 1193,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f5db4d1b1cc84a06abe54a3f457f441d",
       "value": 0
      }
     },
     "e84b3b232edb4df282436c2c4e02c7f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e0739ade4c4a44ab82febedaa525a817",
        "IPY_MODEL_a40d47789da04c05b6ac13081930b181"
       ],
       "layout": "IPY_MODEL_5318f903280b41a2b8da23b81709a776"
      }
     },
     "ecd08c8feb254d179d43189954695889": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef7190ea813547028606283a17b1a8ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f154c55ba0434a3194a3369d37cf5654": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7d3402aa4b0a4ba6839aa97664f649c9",
        "IPY_MODEL_827691b2955b4e4caec35c11e2dd0b5e"
       ],
       "layout": "IPY_MODEL_458eb96a7a7f415e97ce61aa558a3c64"
      }
     },
     "f37d5f48d763494a8674e9d7d58800db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f5db4d1b1cc84a06abe54a3f457f441d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f6e68093dbd74cd4828b9985b181d274": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8275a203aa142f0b69360d0d3843bb4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f923fd02533a480d9bc74be4f35c84f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f37d5f48d763494a8674e9d7d58800db",
       "placeholder": "​",
       "style": "IPY_MODEL_5a83ae990ed94f5989cf572b0a8af0be",
       "value": " 1/1 [00:07&lt;00:00,  7.54s/ file]"
      }
     },
     "fcefc03e80f44fce8a4c2889b7d0a8d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ecd08c8feb254d179d43189954695889",
       "placeholder": "​",
       "style": "IPY_MODEL_91b14375c2784c63ae71350d0015d808",
       "value": " 124/124 [00:07&lt;00:00, 16.39 MiB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
