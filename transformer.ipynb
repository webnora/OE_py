{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_qNSzzyaCbD"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "jmjh290raIky"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import pandas as pd\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Transformer model for language understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AOpGoE2T-YXS"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/transformer\">\n",
    "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
    "    View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/transformer.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-f8TnGpE_ex"
   },
   "source": [
    "This tutorial trains a <a href=\"https://arxiv.org/abs/1706.03762\" class=\"external\">Transformer model</a> to translate Portuguese to English. This is an advanced example that assumes knowledge of [text generation](text_generation.ipynb) and [attention](nmt_with_attention.ipynb).\n",
    "\n",
    "The core idea behind the Transformer model is *self-attention*—the ability to attend to different positions of the input sequence to compute a representation of that sequence. Transformer creates stacks of self-attention layers and is explained below in the sections *Scaled dot product attention* and *Multi-head attention*.\n",
    "\n",
    "A transformer model handles variable-sized input using stacks of self-attention layers instead of [RNNs](text_classification_rnn.ipynb) or [CNNs](../images/intro_to_cnns.ipynb). This general architecture has a number of advantages:\n",
    "\n",
    "* It make no assumptions about the temporal/spatial relationships across the data. This is ideal for processing a set of objects (for example, [StarCraft units](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/#block-8)).\n",
    "* Layer outputs can be calculated in parallel, instead of a series like an RNN.\n",
    "* Distant items can affect each other's output without passing through many RNN-steps, or convolution layers (see [Scene Memory Transformer](https://arxiv.org/pdf/1903.03878.pdf) for example).\n",
    "* It can learn long-range dependencies. This is a challenge in many sequence tasks.\n",
    "\n",
    "The downsides of this architecture are:\n",
    "\n",
    "* For a time-series, the output for a time-step is calculated from the *entire history* instead of only the inputs and current hidden-state. This _may_ be less efficient.   \n",
    "* If the input *does* have a  temporal/spatial relationship, like text, some positional encoding must be added or the model will effectively see a bag of words. \n",
    "\n",
    "After training the model in this notebook, you will be able to input a Portuguese sentence and return the English translation.\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/attention_map_portuguese.png\" width=\"800\" alt=\"Attention heatmap\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjJJyJTZYebt"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# try:\n",
    "#   !pip install -q tf-nightly\n",
    "# except Exception:\n",
    "#   pass\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fd1NWMxjfsDd"
   },
   "source": [
    "## Setup input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4_Qt8W1hJE_"
   },
   "source": [
    "Use [TFDS](https://www.tensorflow.org/datasets) to load the [Portugese-English translation dataset](https://github.com/neulab/word-embeddings-for-nmt) from the [TED Talks Open Translation Project](https://www.ted.com/participate/translate).\n",
    "\n",
    "This dataset contains approximately 50000 training examples, 1100 validation examples, and 2000 test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8q9t4FmN96eN"
   },
   "outputs": [],
   "source": [
    "# examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "#                                as_supervised=True)\n",
    "# train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET_SIZE 2673 val_size 134\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'data/iswoc-treebank.tsv'\n",
    "wc = !cat $DATASET | wc -l\n",
    "DATASET_SIZE = int(wc[0])\n",
    "train_size = int(0.95 * DATASET_SIZE)\n",
    "print('DATASET_SIZE', DATASET_SIZE, 'val_size', DATASET_SIZE - train_size)\n",
    "full_dataset = tf.data.experimental.CsvDataset(DATASET, [tf.string] * 2, field_delim='\\t')\n",
    "full_dataset = full_dataset.shuffle(buffer_size=10)\n",
    "train_examples = full_dataset.take(train_size)\n",
    "val_examples = full_dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Þa becom hyre on hand þæs halgan apostoles lar Paules þæs mæran ealles manncynnes lareowes\n",
      "þa becuman heo on hand se halig apostol lar Paulus se mære eal manncynn lareow\n"
     ]
    }
   ],
   "source": [
    "for a, b in train_examples.take(1):\n",
    "    tf.print(a)\n",
    "    tf.print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RCEKotqosGfq"
   },
   "source": [
    "Create a custom subwords tokenizer from the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVBg5Q8tBk5z"
   },
   "outputs": [],
   "source": [
    "tokenizer_forma = 'data/tokenizer_forma'\n",
    "tokenizer_lemma = 'data/tokenizer_lemma'\n",
    "if os.path.isfile(tokenizer_forma + \".subwords\") and os.path.isfile(tokenizer_lemma + \".subwords\"):\n",
    "    tokenizer_en = tfds.features.text.SubwordTextEncoder.load_from_file(tokenizer_forma)\n",
    "    tokenizer_pt = tfds.features.text.SubwordTextEncoder.load_from_file(tokenizer_lemma)\n",
    "else:\n",
    "    tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "        (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "    tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "        (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "    tokenizer_en.save_to_file(tokenizer_forma)\n",
    "    tokenizer_pt.save_to_file(tokenizer_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DYWukNFkGQN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [111, 5, 11, 338, 728, 155, 105, 4, 1195, 3791, 3722, 9, 4, 3807, 3885, 3866, 3809, 3811, 3806, 3791, 3793, 3807, 3800, 237]\n",
      "The original string: Eugenia þa þæt æðele mæden wel þeah on wisdome and on uðwytegunge\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Eugenia þa þæt æðele mæden wel þeah on wisdome and on uðwytegunge'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9KJWJjrsZ4Y"
   },
   "source": [
    "The tokenizer encodes the string by breaking it into subwords if the word is not in its dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bf2ntBxjkqK6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 ----> Eugenia \n",
      "5 ----> þa \n",
      "11 ----> þæt \n",
      "338 ----> æðele \n",
      "728 ----> mæden \n",
      "155 ----> wel \n",
      "105 ----> þeah \n",
      "4 ----> on \n",
      "1195 ----> wisdom\n",
      "3791 ----> e\n",
      "3722 ---->  \n",
      "9 ----> and \n",
      "4 ----> on \n",
      "3807 ----> u\n",
      "3885 ----> �\n",
      "3866 ----> �\n",
      "3809 ----> w\n",
      "3811 ----> y\n",
      "3806 ----> t\n",
      "3791 ----> e\n",
      "3793 ----> g\n",
      "3807 ----> u\n",
      "3800 ----> n\n",
      "237 ----> ge\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcRp7VcQ5m6g"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGi4PoVakxdc"
   },
   "source": [
    "Add a start and end token to the input and target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZwnPr4R055s"
   },
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "  \n",
    "  return lang1, lang2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tx1sFbR-9fRs"
   },
   "source": [
    "You want to use `Dataset.map` to apply this function to each element of the dataset.  `Dataset.map` runs in graph mode.\n",
    "\n",
    "* Graph tensors do not have a value. \n",
    "* In graph mode you can only use TensorFlow Ops and functions. \n",
    "\n",
    "So you can't `.map` this function directly: You need to wrap it in a `tf.py_function`. The `tf.py_function` will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mah1cS-P70Iz"
   },
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "  result_pt.set_shape([None])\n",
    "  result_en.set_shape([None])\n",
    "\n",
    "  return result_pt, result_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6JrGp5Gek6Ql"
   },
   "source": [
    "Note: To keep this example small and relatively fast, drop examples with a length of over 40 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QEgbjntk6Yf"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c081xPGv1CPI"
   },
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mk9AZdZ5bcS"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fXvfYVfQr2n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(60, 38), dtype=int64, numpy=\n",
       " array([[6906, 1115, 6764, ...,    0,    0,    0],\n",
       "        [6906, 1115, 6750, ...,    0,    0,    0],\n",
       "        [6906,  164, 4921, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [6906, 6719,  742, ...,    0,    0,    0],\n",
       "        [6906, 5550, 6756, ...,    0,    0,    0],\n",
       "        [6906, 6730, 6764, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: shape=(60, 40), dtype=int64, numpy=\n",
       " array([[3946,  954, 3804, ...,    0,    0,    0],\n",
       "        [3946,  954, 3790, ...,    0,    0,    0],\n",
       "        [3946,    4, 1519, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [3946, 3759, 3807, ...,    0,    0,    0],\n",
       "        [3946, 3789, 1666, ...,    0,    0,    0],\n",
       "        [3946, 3802, 3804, ...,    0,    0,    0]])>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBQuibYA4n0n"
   },
   "source": [
    "## Positional encoding\n",
    "\n",
    "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence. \n",
    "\n",
    "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n",
    "\n",
    "See the notebook on [positional encoding](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) to learn more about it. The formula for calculating the positional encoding is as follows:\n",
    "\n",
    "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
    "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhIOZjMNKujn"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Rz82wEs5biZ"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kLCla68EloE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_b4ou4TYqUN"
   },
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s42Uydjkv0hF"
   },
   "source": [
    "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value `0` is present: it outputs a `1` at those locations, and a `0` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2i8-e1s8ti9"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7BYeBCNvi7n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0hzukDBgVom"
   },
   "source": [
    "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
    "\n",
    "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVxS8OPI9uI0"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxKGuXxaBeeE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xluDl5cXYy4y"
   },
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vsxEE_-Wa1gF"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n",
    "\n",
    "The attention function used by the transformer takes three inputs: Q (query), K (key), V (value). The equation used to calculate the attention weights is:\n",
    "\n",
    "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n",
    "\n",
    "The dot-product attention is scaled by a factor of square root of the depth. This is done because for large values of depth, the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax. \n",
    "\n",
    "For example, consider that `Q` and `K` have a mean of 0 and variance of 1. Their matrix multiplication will have a mean of 0 and variance of `dk`. Hence, *square root of `dk`* is used for scaling (and not any other number) because the matmul of `Q` and `K` should have a mean of 0 and variance of 1, and you get a gentler softmax.\n",
    "\n",
    "The mask is multiplied with -1e9 (close to negative infinity). This is done because the mask is summed with the scaled matrix multiplication of Q and K and is applied immediately before a softmax. The goal is to zero out these cells, and large negative inputs to softmax are near zero in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LazzUq3bJ5SH"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiqETnhCkoXh"
   },
   "source": [
    "As the softmax normalization is done on K, its values decide the amount of importance given to Q.\n",
    "\n",
    "The output represents the multiplication of the attention weights and the V (value) vector. This ensures that the words you want to focus on are kept as-is and the irrelevant words are flushed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n90YjClyInFy"
   },
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAzUAf2DPlNt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zg6k-fGhgXra"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAq3YOzUgXhb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aOz-4_XIhaTP"
   },
   "source": [
    "Pass all the queries together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dlU8Tm-hYrF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmzGPEy64qmA"
   },
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fz5BMC8Kaoqo"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n",
    "\n",
    "\n",
    "Multi-head attention consists of four parts:\n",
    "*    Linear layers and split into heads.\n",
    "*    Scaled dot-product attention.\n",
    "*    Concatenation of heads.\n",
    "*    Final linear layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPmbr6F1C-v_"
   },
   "source": [
    "Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads. \n",
    "\n",
    "The `scaled_dot_product_attention` defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step.  The attention output for each head is then concatenated (using `tf.transpose`, and `tf.reshape`) and put through a final `Dense` layer.\n",
    "\n",
    "Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSV3PPKsYecw"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0D8FJue5lDyZ"
   },
   "source": [
    "Create a `MultiHeadAttention` layer to try out. At each location in the sequence, `y`, the `MultiHeadAttention` runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hu94p-_-2_BX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RdDqGayx67vv"
   },
   "source": [
    "## Point wise feed forward network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBqzJXGfHK3X"
   },
   "source": [
    "Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ET7xLt0yCT6Z"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mytb1lPyOHLB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7e7hKcxn6-zd"
   },
   "source": [
    "## Encoder and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yScbC0MUH8dS"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MfYJG-Kvgwy2"
   },
   "source": [
    "The transformer model follows the same general pattern as a standard [sequence to sequence with attention model](nmt_with_attention.ipynb). \n",
    "\n",
    "* The input sentence is passed through `N` encoder layers that generates an output for each word/token in the sequence.\n",
    "* The decoder attends on the encoder's output and its own input (self-attention) to predict the next word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFv-FNYUmvpn"
   },
   "source": [
    "### Encoder layer\n",
    "\n",
    "Each encoder layer consists of sublayers:\n",
    "\n",
    "1.   Multi-head attention (with padding mask) \n",
    "2.    Point wise feed forward networks. \n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
    "\n",
    "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncyS-Ms3i2x_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzZRXdO0mI48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LO_48Owmx_o"
   },
   "source": [
    "### Decoder layer\n",
    "\n",
    "Each decoder layer consists of sublayers:\n",
    "\n",
    "1.   Masked multi-head attention (with look ahead mask and padding mask)\n",
    "2.   Multi-head attention (with padding mask). V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
    "3.   Point wise feed forward networks\n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
    "\n",
    "There are N decoder layers in the transformer.\n",
    "\n",
    "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ne2Bqx8k71l0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SE1H51Ajm0q1"
   },
   "source": [
    "### Encoder\n",
    "\n",
    "The `Encoder` consists of:\n",
    "1.   Input Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N encoder layers\n",
    "\n",
    "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8QG9nueFQKXx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-uO6ls8m2O5"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZtT7PKzrXkNr"
   },
   "source": [
    " The `Decoder` consists of:\n",
    "1.   Output Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N decoder layers\n",
    "\n",
    "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1jXoAMRZyvu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y54xnJnuYgJ7"
   },
   "source": [
    "## Create the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uERO1y54cOKq"
   },
   "source": [
    "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJ4fbQcIkHW1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsINyf1VEQLC"
   },
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zVjWCxFNcgbt"
   },
   "source": [
    "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced. \n",
    "\n",
    "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
    "\n",
    "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lnJn5SLA2ahP"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xYEGhEOtzn5W"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOmWW--yP3zx"
   },
   "source": [
    "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYQdOO1axwEI"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7r4scdulztRx"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f33ZCgvHpPdG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgkDE7hzo8r5"
   },
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxGJtoDuYIHL"
   },
   "source": [
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlhsJMm0TW_B"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "67oqVHiT0Eiu"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phlyxMnm-Tpx"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeHumfr7zmMa"
   },
   "source": [
    "## Training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiysUa--4tOU"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOJUSB1T8GjM"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fzuf06YZp66w"
   },
   "source": [
    "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNhuYfllndLZ"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf checkpoints/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Di_Yaa1gf9r"
   },
   "source": [
    "The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the  next token that should be predicted.\n",
    "\n",
    "For example, `sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next. \n",
    "\n",
    "During training this example uses teacher-forcing (like in the [text generation tutorial](./text_generation.ipynb)). Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n",
    "\n",
    "As the transformer predicts each word, *self-attention* allows it to look at the previous words in the input sequence to better predict the next word.\n",
    "\n",
    "To prevent the model from peaking at the expected output the model uses a look-ahead mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKpoA6q1sJFj"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJwmp9OE29oj"
   },
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qM2PDWGDJ_8V"
   },
   "source": [
    "Portuguese is used as the input language and English is the target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bbvmaKNiznHZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.6852 Accuracy 0.0000\n",
      "Epoch 1 Batch 15 Loss 2.9097 Accuracy 0.0000\n",
      "Epoch 1 Batch 30 Loss 2.9604 Accuracy 0.0001\n",
      "Epoch 1 Loss 2.9548 Accuracy 0.0003\n",
      "Time taken for 1 epoch: 31.759862422943115 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.5243 Accuracy 0.0036\n",
      "Epoch 2 Batch 15 Loss 2.9053 Accuracy 0.0126\n",
      "Epoch 2 Batch 30 Loss 2.8543 Accuracy 0.0188\n",
      "Epoch 2 Loss 2.9311 Accuracy 0.0211\n",
      "Time taken for 1 epoch: 18.625934839248657 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.2890 Accuracy 0.0268\n",
      "Epoch 3 Batch 15 Loss 2.8062 Accuracy 0.0311\n",
      "Epoch 3 Batch 30 Loss 2.7876 Accuracy 0.0305\n",
      "Epoch 3 Loss 2.8431 Accuracy 0.0308\n",
      "Time taken for 1 epoch: 21.8665828704834 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 2.5067 Accuracy 0.0266\n",
      "Epoch 4 Batch 15 Loss 2.7237 Accuracy 0.0302\n",
      "Epoch 4 Batch 30 Loss 2.7165 Accuracy 0.0310\n",
      "Epoch 4 Loss 2.7249 Accuracy 0.0310\n",
      "Time taken for 1 epoch: 20.189033031463623 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 2.4084 Accuracy 0.0264\n",
      "Epoch 5 Batch 15 Loss 2.6074 Accuracy 0.0306\n",
      "Epoch 5 Batch 30 Loss 2.6246 Accuracy 0.0311\n",
      "Epoch 5 Loss 2.6745 Accuracy 0.0317\n",
      "Time taken for 1 epoch: 22.907621383666992 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 2.3860 Accuracy 0.0274\n",
      "Epoch 6 Batch 15 Loss 2.5968 Accuracy 0.0352\n",
      "Epoch 6 Batch 30 Loss 2.5306 Accuracy 0.0355\n",
      "Epoch 6 Loss 2.5598 Accuracy 0.0362\n",
      "Time taken for 1 epoch: 19.83004903793335 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 2.2359 Accuracy 0.0355\n",
      "Epoch 7 Batch 15 Loss 2.4283 Accuracy 0.0417\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 15 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 10 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfcsSWswSdGV"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6APsFrgImLW"
   },
   "source": [
    "The following steps are used for evaluation:\n",
    "\n",
    "* Encode the input sentence using the Portuguese tokenizer (`tokenizer_pt`). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
    "* The decoder input is the `start token == tokenizer_en.vocab_size`.\n",
    "* Calculate the padding masks and the look ahead masks.\n",
    "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
    "* Select the last word and calculate the argmax of that.\n",
    "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
    "* In this approach, the decoder predicts the next word based on the previous words it predicted.\n",
    "\n",
    "Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the paper, use the entire dataset and base transformer model or transformer XL, by changing the hyperparameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5buvMlnvyrFm"
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_pt.vocab_size]\n",
    "  end_token = [tokenizer_pt.vocab_size + 1]\n",
    "  \n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if predicted_id == tokenizer_en.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CN-BV43FMBej"
   },
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "  sentence = tokenizer_pt.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                        if i < tokenizer_en.vocab_size], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lU2_yG_vBGza"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "  print(sentence)\n",
    "  print(predicted_sentence)\n",
    "#   print('Input:                 {}'.format(sentence))\n",
    "#   print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t\n",
    "Ða wearð Melantia micclum ofsceamod\tþa weorþan Melantia micel ofsceamian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in train_examples.take(1):\n",
    "    translate(a.numpy().decode())\n",
    "    tf.print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in val_examples.take(10):\n",
    "    translate(a.numpy().decode())\n",
    "    tf.print(b)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsxrAlvFG8SZ"
   },
   "outputs": [],
   "source": [
    "translate(\"We habbað ealle ðing mid þam ælmihtigan Drihtne\")\n",
    "print (\"Real translation: we habban eal þing mid se eallmihtig Dryhten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7EH5y_aqI4t1"
   },
   "outputs": [],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-hVCTSUMlkb"
   },
   "outputs": [],
   "source": [
    "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
    "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MxkSZvz0jX"
   },
   "source": [
    "You can pass different layers and attention blocks of the decoder to the `plot` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-kFyiOLH0xg"
   },
   "outputs": [],
   "source": [
    "translate(\"este é o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RqQ1fIsLwkGE"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned about positional encoding, multi-head attention, the importance of masking and how to create a transformer.\n",
    "\n",
    "Try using a different dataset to train the transformer. You can also create the base transformer or transformer XL by changing the hyperparameters above. You can also use the layers defined here to create [BERT](https://arxiv.org/abs/1810.04805) and train state of the art models. Futhermore, you can implement beam search to get better predictions."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "s_qNSzzyaCbD"
   ],
   "name": "transformer.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0e0d890d0561404f91dbbe32c7a968d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "1607f2ecd0c64125a081503cc9eb2caa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "  0%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3e679a31c15d401dba8cbb929600c15f",
       "max": 1803,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_30eb27c4cec1420db11ad9b6e4eaa1bf",
       "value": 0
      }
     },
     "16484967d5374168afbca17948a94e31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1717a8bbc4564373affedb4e11e9aab8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "186792f23e564f8bbf0099d63328c6b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "194bd44ff15947ac85321fc3be00e932": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d6b5bd7826d46829c4e1a5b05c1e419": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e08b4b9bd314039b0eabd873f9daa18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "1fcc5dce2bec42458512e29ba578ae8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "27129d6afd1f4cf29b44e87687016eee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_35c90729b03b4ca8ad9e9cff09e42bee",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_915bc88dd2e2445cae18acca9830b170",
       "value": 1
      }
     },
     "2f526e6e7e954a5da83d333b6fbf2982": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "30eb27c4cec1420db11ad9b6e4eaa1bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "35c90729b03b4ca8ad9e9cff09e42bee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "36efa5fe9bb5464e9a6edaa460abb58d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_194bd44ff15947ac85321fc3be00e932",
       "placeholder": "​",
       "style": "IPY_MODEL_9c88f0004c864677b38d89ad1686035c",
       "value": " 19838/51785 [00:00&lt;00:00, 198379.24 examples/s]"
      }
     },
     "377c335c948f4c11ac806d381e2dbee6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e679a31c15d401dba8cbb929600c15f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e8606466c774b628ddec7d1d877c1a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3f892beaeb7942fe87dca1b44813098d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c7ae463517d147d3aeda0c6a8739934b",
       "placeholder": "​",
       "style": "IPY_MODEL_90498e8edda745bc86c008126e8277a5",
       "value": " 0/1193 [00:00&lt;?, ? examples/s]"
      }
     },
     "4459a3d62cf945338dcb31b61503a630": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "456a5511e517483f861c6250ccbdfef6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_822a1fcf13864a6592a208f52d3a45fa",
        "IPY_MODEL_f923fd02533a480d9bc74be4f35c84f1"
       ],
       "layout": "IPY_MODEL_9d825f2724af43b79a6fa1aabb479298"
      }
     },
     "458eb96a7a7f415e97ce61aa558a3c64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a6b4c6a3ae24f11adf416e62268d387": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cecfa836b02c4cdebefd9c601386cf7a",
       "placeholder": "​",
       "style": "IPY_MODEL_1717a8bbc4564373affedb4e11e9aab8",
       "value": " 1803/0 [00:00&lt;00:00, 4788.03 examples/s]"
      }
     },
     "5318f903280b41a2b8da23b81709a776": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a83ae990ed94f5989cf572b0a8af0be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6c2c4480920a4533a78996327463a2b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "73608d85c72a4dc5b3f6f0bd29a329d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "79b9d229ccb54716b368f4e572222933": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d3402aa4b0a4ba6839aa97664f649c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Dl Completed...: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1d6b5bd7826d46829c4e1a5b05c1e419",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1e08b4b9bd314039b0eabd873f9daa18",
       "value": 1
      }
     },
     "7d62cecd8db54cb492ee8f11b4c1e29a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "822a1fcf13864a6592a208f52d3a45fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Extraction completed...: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2f526e6e7e954a5da83d333b6fbf2982",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1fcc5dce2bec42458512e29ba578ae8f",
       "value": 1
      }
     },
     "827691b2955b4e4caec35c11e2dd0b5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_73608d85c72a4dc5b3f6f0bd29a329d4",
       "placeholder": "​",
       "style": "IPY_MODEL_b06137696b774319b960f03ad45af6e4",
       "value": " 1/1 [00:07&lt;00:00,  7.59s/ url]"
      }
     },
     "90498e8edda745bc86c008126e8277a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "915bc88dd2e2445cae18acca9830b170": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "91b14375c2784c63ae71350d0015d808": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "94ce25087ae44d6abfcc0122a6856c37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Dl Size...: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_377c335c948f4c11ac806d381e2dbee6",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0e0d890d0561404f91dbbe32c7a968d1",
       "value": 1
      }
     },
     "97d5e6641cda47d29fc5b8e6ebfedb68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "99283c9c5e2b405ba10e100f1ca39889": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c10c7e8975543b28496de7965e2654b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1607f2ecd0c64125a081503cc9eb2caa",
        "IPY_MODEL_ad61b5359af04ccebafd2b485dfb5065"
       ],
       "layout": "IPY_MODEL_ef7190ea813547028606283a17b1a8ba"
      }
     },
     "9c88f0004c864677b38d89ad1686035c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9c8bf84c78f94ea989e3dcf57705a246": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f6e68093dbd74cd4828b9985b181d274",
       "placeholder": "​",
       "style": "IPY_MODEL_7d62cecd8db54cb492ee8f11b4c1e29a",
       "value": " 1193/0 [00:00&lt;00:00, 4394.36 examples/s]"
      }
     },
     "9d825f2724af43b79a6fa1aabb479298": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f9b566492a9442f9b13547047e78498": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a40d47789da04c05b6ac13081930b181": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3e8606466c774b628ddec7d1d877c1a9",
       "placeholder": "​",
       "style": "IPY_MODEL_da64cb26752f478d894a9c921b3d7727",
       "value": " 51785/0 [00:09&lt;00:00, 5587.32 examples/s]"
      }
     },
     "a5cd4ad1711f4478b56711ebf2e4b74e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b046b2dc15e24cd990322e3f7eea50f2",
        "IPY_MODEL_4a6b4c6a3ae24f11adf416e62268d387"
       ],
       "layout": "IPY_MODEL_99283c9c5e2b405ba10e100f1ca39889"
      }
     },
     "ad61b5359af04ccebafd2b485dfb5065": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_186792f23e564f8bbf0099d63328c6b4",
       "placeholder": "​",
       "style": "IPY_MODEL_b811bbe8caaf41fcb78f7cbe026b8bf9",
       "value": " 0/1803 [00:00&lt;?, ? examples/s]"
      }
     },
     "b046b2dc15e24cd990322e3f7eea50f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f8275a203aa142f0b69360d0d3843bb4",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6c2c4480920a4533a78996327463a2b4",
       "value": 1
      }
     },
     "b06137696b774319b960f03ad45af6e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b6e57d6bd9f64c8c969e34c68dfae31c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bf5bc178960a4686bbb35afa9bade9a1",
        "IPY_MODEL_36efa5fe9bb5464e9a6edaa460abb58d"
       ],
       "layout": "IPY_MODEL_b8e9f0f21a604037843c20ffbf562690"
      }
     },
     "b811bbe8caaf41fcb78f7cbe026b8bf9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b8e9f0f21a604037843c20ffbf562690": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8f2f9964e4b4a2b87b159ac81f70aa7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "bf5bc178960a4686bbb35afa9bade9a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": " 38%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_16484967d5374168afbca17948a94e31",
       "max": 51785,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_db3e6516398e4e479cc101f889ad9cea",
       "value": 19838
      }
     },
     "c7ae463517d147d3aeda0c6a8739934b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cad5e524a43440b39c25e7902fee31a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_94ce25087ae44d6abfcc0122a6856c37",
        "IPY_MODEL_fcefc03e80f44fce8a4c2889b7d0a8d3"
       ],
       "layout": "IPY_MODEL_79b9d229ccb54716b368f4e572222933"
      }
     },
     "cecfa836b02c4cdebefd9c601386cf7a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d2b1004ba93f444eb9dadcbd29a0db2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d82d8c2fbed34fb6be93ea0bd2a383fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e715e304faf74221ba1479f4ff1a8847",
        "IPY_MODEL_3f892beaeb7942fe87dca1b44813098d"
       ],
       "layout": "IPY_MODEL_d2b1004ba93f444eb9dadcbd29a0db2f"
      }
     },
     "da64cb26752f478d894a9c921b3d7727": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "db3e6516398e4e479cc101f889ad9cea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "de497e2297a54a3d8dcb55b192d6718f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_27129d6afd1f4cf29b44e87687016eee",
        "IPY_MODEL_9c8bf84c78f94ea989e3dcf57705a246"
       ],
       "layout": "IPY_MODEL_97d5e6641cda47d29fc5b8e6ebfedb68"
      }
     },
     "e0739ade4c4a44ab82febedaa525a817": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9f9b566492a9442f9b13547047e78498",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b8f2f9964e4b4a2b87b159ac81f70aa7",
       "value": 1
      }
     },
     "e715e304faf74221ba1479f4ff1a8847": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "  0%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4459a3d62cf945338dcb31b61503a630",
       "max": 1193,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f5db4d1b1cc84a06abe54a3f457f441d",
       "value": 0
      }
     },
     "e84b3b232edb4df282436c2c4e02c7f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e0739ade4c4a44ab82febedaa525a817",
        "IPY_MODEL_a40d47789da04c05b6ac13081930b181"
       ],
       "layout": "IPY_MODEL_5318f903280b41a2b8da23b81709a776"
      }
     },
     "ecd08c8feb254d179d43189954695889": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef7190ea813547028606283a17b1a8ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f154c55ba0434a3194a3369d37cf5654": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7d3402aa4b0a4ba6839aa97664f649c9",
        "IPY_MODEL_827691b2955b4e4caec35c11e2dd0b5e"
       ],
       "layout": "IPY_MODEL_458eb96a7a7f415e97ce61aa558a3c64"
      }
     },
     "f37d5f48d763494a8674e9d7d58800db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f5db4d1b1cc84a06abe54a3f457f441d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f6e68093dbd74cd4828b9985b181d274": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8275a203aa142f0b69360d0d3843bb4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f923fd02533a480d9bc74be4f35c84f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f37d5f48d763494a8674e9d7d58800db",
       "placeholder": "​",
       "style": "IPY_MODEL_5a83ae990ed94f5989cf572b0a8af0be",
       "value": " 1/1 [00:07&lt;00:00,  7.54s/ file]"
      }
     },
     "fcefc03e80f44fce8a4c2889b7d0a8d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ecd08c8feb254d179d43189954695889",
       "placeholder": "​",
       "style": "IPY_MODEL_91b14375c2784c63ae71350d0015d808",
       "value": " 124/124 [00:07&lt;00:00, 16.39 MiB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
