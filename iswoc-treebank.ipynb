{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyconll\n",
      "  Downloading https://files.pythonhosted.org/packages/2c/6e/c325d0db05ac1b8d45645de903e4ba691d419e861c915c3d4ebfcaf8ac25/pyconll-2.2.1-py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.21 in /opt/conda/lib/python3.7/site-packages (from pyconll) (2.22.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.21->pyconll) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.21->pyconll) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.21->pyconll) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.21->pyconll) (3.0.4)\n",
      "Installing collected packages: pyconll\n",
      "Successfully installed pyconll-2.2.1\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/pyconll/pyconll\n",
    "# !pip install pyconll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "Error parsing \"None\" properly. Please check against CoNLL format spec.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-02479c35939b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mUD_ENGLISH_TRAIN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./out/apt2.conll'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyconll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUD_ENGLISH_TRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0maux_lemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyconll/load.py\u001b[0m in \u001b[0;36mload_from_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \"\"\"\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyconll/unit/conll.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, it)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpyconll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyconll/_parser.py\u001b[0m in \u001b[0;36miter_sentences\u001b[0;34m(lines_it)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msent_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyconll/_parser.py\u001b[0m in \u001b[0;36m_create_sentence\u001b[0;34m(sent_lines)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \"\"\"\n\u001b[1;32m     23\u001b[0m     \u001b[0msent_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyconll/unit/sentence.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m     77\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyconll/unit/token.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, empty)\u001b[0m\n\u001b[1;32m    537\u001b[0m         self.feats = _dict_empty_map(fields[5], Token.EMPTY,\n\u001b[1;32m    538\u001b[0m                                      \u001b[0mToken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPONENT_DELIMITER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m                                      Token.AV_SEPARATOR, Token.V_DELIMITER)\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unit_empty_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEMPTY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unit_empty_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEMPTY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyconll/unit/token.py\u001b[0m in \u001b[0;36m_dict_empty_map\u001b[0;34m(values, empty, delim, av_separator, v_delimiter)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     return _dict_empty_map_helper(values, empty, delim, av_separator,\n\u001b[0;32m---> 69\u001b[0;31m                                   v_delimiter, _dict_empty_map_parser)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyconll/unit/token.py\u001b[0m in \u001b[0;36m_dict_empty_map_helper\u001b[0;34m(values, empty, delim, av_separator, v_delimiter, parser)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_delimiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyconll/unit/token.py\u001b[0m in \u001b[0;36m_dict_empty_map_parser\u001b[0;34m(v, v_delimiter)\u001b[0m\n\u001b[1;32m     44\u001b[0m     error_msg = 'Error parsing \"{}\" properly. Please check against CoNLL format spec.'.format(\n\u001b[1;32m     45\u001b[0m         v)\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mParseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mParseError\u001b[0m: Error parsing \"None\" properly. Please check against CoNLL format spec."
     ]
    }
   ],
   "source": [
    "# import pyconll\n",
    "\n",
    "# UD_ENGLISH_TRAIN = './out/apt2.conll'\n",
    "\n",
    "# train = pyconll.load_from_file(UD_ENGLISH_TRAIN)\n",
    "\n",
    "# aux_lemmas = set()\n",
    "# for sentence in train:\n",
    "#     for token in sentence:\n",
    "#         if token.upos == 'AUX':\n",
    "#             aux_lemmas.add(token.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5778  53350 246962 out/apt.conll\n"
     ]
    }
   ],
   "source": [
    "!wc out/apt.conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CoNLL-X and CoNLL-U file readers and writers\n",
    "\"\"\"\n",
    "__author__ = \"Pierre Nugues\"\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def get_files(dir, suffix):\n",
    "    \"\"\"\n",
    "    Returns all the files in a folder ending with suffix\n",
    "    Recursive version\n",
    "    :param dir:\n",
    "    :param suffix:\n",
    "    :return: the list of file names\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for file in os.listdir(dir):\n",
    "        path = dir + '/' + file\n",
    "        if os.path.isdir(path):\n",
    "            files += get_files(path, suffix)\n",
    "        elif os.path.isfile(path) and file.endswith(suffix):\n",
    "            files.append(path)\n",
    "    return files\n",
    "\n",
    "\n",
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    root_values = ['0', 'ROOT', 'ROOT', 'ROOT', 'ROOT', 'ROOT', '0', 'ROOT', '0', 'ROOT']\n",
    "    start = [dict(zip(column_names, root_values))]\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split('\\t'))) for row in rows if row[0] != '#']\n",
    "        sentence = start + sentence\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences\n",
    "\n",
    "\n",
    "def save(file, formatted_corpus, column_names):\n",
    "    f_out = open(file, 'w')\n",
    "    for sentence in formatted_corpus:\n",
    "        for row in sentence[1:]:\n",
    "            # print(row, flush=True)\n",
    "            for col in column_names[:-1]:\n",
    "                if col in row:\n",
    "                    f_out.write(row[col] + '\\t')\n",
    "                else:\n",
    "                    f_out.write('_\\t')\n",
    "            col = column_names[-1]\n",
    "            if col in row:\n",
    "                f_out.write(row[col] + '\\n')\n",
    "            else:\n",
    "                f_out.write('_\\n')\n",
    "        f_out.write('\\n')\n",
    "    f_out.close()\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     column_names_2006 = ['id', 'form', 'lemma', 'cpostag', 'postag', 'feats', 'head', 'deprel', 'phead', 'pdeprel']\n",
    "\n",
    "#     train_file = '../../corpus/conllx/sv/swedish_talbanken05_train.conll'\n",
    "#     # train_file = 'test_x'\n",
    "#     test_file = '../../corpus/conllx/sv/swedish_talbanken05_test.conll'\n",
    "\n",
    "#     sentences = read_sentences(train_file)\n",
    "#     formatted_corpus = split_rows(sentences, column_names_2006)\n",
    "#     print(train_file, len(formatted_corpus))\n",
    "#     print(formatted_corpus[0])\n",
    "\n",
    "#     column_names_u = ['id', 'form', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel', 'deps', 'misc']\n",
    "\n",
    "#     files = get_files('../../corpus/ud-treebanks-v2.4/', 'train.conllu')\n",
    "#     for train_file in files:\n",
    "#         sentences = read_sentences(train_file)\n",
    "#         formatted_corpus = split_rows(sentences, column_names_u)\n",
    "#         print(train_file, len(formatted_corpus))\n",
    "#         print(formatted_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1\\tAn\\tan\\tR\\tR-\\tINFLn\\t5\\tadv\\t_\\t_\\n2\\tAntiochia\\tAntiochia\\tN\\tNe\\tNUMBs|GENDx|CASEx\\t1\\tobl\\t_\\t_\\n3\\tþare\\tse\\tP\\tPd\\tNUMBs|GENDf|CASEd\\t4\\tatr\\t_\\t_\\n4\\tceastre\\tceaster\\tN\\tNb\\tNUMBs|GENDf|CASEd\\t2\\tapos\\t_\\t_\\n5\\twæs\\twesan\\tV\\tV-\\tPERS3|NUMBs|TENSu|MOODi\\t0\\tpred\\t_\\t_\\n6\\tsum\\tsum\\tP\\tPy\\tNUMBs|GENDm|CASEn|DEGRp|STREs\\t7\\tatr\\t_\\t_\\n7\\tcyningc\\tcyning\\tN\\tNb\\tNUMBs|GENDm|CASEn\\t5\\tsub\\t_\\t_\\n8\\tAntiochus\\tAntiochus\\tN\\tNe\\tNUMBs|GENDm|CASEn\\t9\\txobj\\t_\\t_\\n9\\tgehaten\\tgehatan\\tV\\tV-\\tNUMBx|TENSu|MOODp|GENDx|CASEx|STREt\\t7\\tatr\\t_\\t_'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = read_sentences('./out/apt.conll')\n",
    "s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_names_2006 = ['id', 'form', 'lemma', 'cpostag', 'postag', 'feats', 'head', 'deprel', 'phead', 'pdeprel']\n",
    "column_names_2006 = ['id', 'form', 'lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = split_rows(s, column_names_2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0', 'form': 'ROOT', 'lemma': 'ROOT'},\n",
       " {'id': '1', 'form': 'HER', 'lemma': 'her'},\n",
       " {'id': '2', 'form': 'onginneð', 'lemma': 'onginnan'},\n",
       " {'id': '3', 'form': 'seo', 'lemma': 'se'},\n",
       " {'id': '4', 'form': 'gerecednes', 'lemma': 'gerecednys'},\n",
       " {'id': '5', 'form': 'be', 'lemma': 'be'},\n",
       " {'id': '6', 'form': 'Antioche', 'lemma': 'Antiochus'},\n",
       " {'id': '7', 'form': 'þam', 'lemma': 'se'},\n",
       " {'id': '8', 'form': 'ungesæligan', 'lemma': 'ungesælig'},\n",
       " {'id': '9', 'form': 'cingce', 'lemma': 'cyning'},\n",
       " {'id': '10', 'form': 'and', 'lemma': 'and'},\n",
       " {'id': '11', 'form': 'be', 'lemma': 'be'},\n",
       " {'id': '12', 'form': 'Apollonige', 'lemma': 'Apollonius'},\n",
       " {'id': '13', 'form': 'þam', 'lemma': 'se'},\n",
       " {'id': '14', 'form': 'tiriscan', 'lemma': 'tiriscan'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
